{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\plugins\\hparams\\summary.py:202: The name tf.make_tensor_proto is deprecated. Please use tf.compat.v1.make_tensor_proto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tracemalloc\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import heapq\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB, ComplementNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import gym\n",
    "from baselines.ppo2 import ppo2\n",
    "from baselines.ddpg import ddpg\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from baselines import deepq\n",
    "from baselines import bench\n",
    "from baselines import logger\n",
    "from baselines.common.tf_util import make_session\n",
    "from stable_baselines.deepq.policies import MlpPolicy, LnMlpPolicy\n",
    "from stable_baselines import DQN\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle as pkl\n",
    "\n",
    "import visualkeras\n",
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='navy'>*1. Loading Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When you visit the site, Dotdash Meredith and ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kylie Jenner reportedly doesn't want to talk a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Character on American television series Scanda...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From there, you transition to the leg press ma...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN —\\n\\nAn emotional Celine Dion returned to ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20239</th>\n",
       "      <td>Thousands of government workers are unsure whe...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240</th>\n",
       "      <td>During a time when the Republican Party’s pres...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>Completing the CAPTCHA proves you are a human ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20242</th>\n",
       "      <td>Yes, you can transfer your domain to any regis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20243</th>\n",
       "      <td>Account Suspended\\n\\nThis Account has been sus...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   real\n",
       "0      When you visit the site, Dotdash Meredith and ...   True\n",
       "1      Kylie Jenner reportedly doesn't want to talk a...   True\n",
       "2      Character on American television series Scanda...   True\n",
       "3      From there, you transition to the leg press ma...   True\n",
       "4      CNN —\\n\\nAn emotional Celine Dion returned to ...   True\n",
       "...                                                  ...    ...\n",
       "20239  Thousands of government workers are unsure whe...  False\n",
       "20240  During a time when the Republican Party’s pres...  False\n",
       "20241  Completing the CAPTCHA proves you are a human ...  False\n",
       "20242  Yes, you can transfer your domain to any regis...  False\n",
       "20243  Account Suspended\\n\\nThis Account has been sus...  False\n",
       "\n",
       "[17806 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakenewsnet = pd.read_csv('fakenewsnet.csv')\n",
    "\n",
    "X = fakenewsnet[['text','real']]\n",
    "\n",
    "X = X.dropna()\n",
    "\n",
    "y = X[['real']]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     12738\n",
       "False     5068\n",
       "Name: real, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['real'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='navy'>*2. Preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "ohe = count_vec.fit_transform((X['text']))\n",
    "ohe = np.array(ohe.todense())\n",
    "\n",
    "X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(ohe, y['real'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bellamy Young may be riveting as First Lady Mellie Grant on ABC’s Scandal, but her off-screen story is just as captivating.\\n\\n“I was adopted, so I was in foster care for six weeks,” the actress, 45, says in the latest issue of PEOPLE. “We only had two lines on my dad and a paragraph on my mom. It said she loved to sing, so my mom who raised me would find any way to let me perform.”\\n\\nYoung says she spent her youth in Asheville, North Carolina, learning ballet and tap dancing and performing at school and church.\\n\\nAfter graduating from Yale, Young – who grew up with the first name Amy – spent a few years doing theater in New York before making the move to Los Angeles in 2000 to pursue TV and film work.\\n\\n“When I went to join the Screen Actors Guild, there was already an Amy Young so I had to register under a different name,” says Young. “I tried to become Susanna or Violet or something fabulous, but it just didn’t feel like I could carry the ruse off.”\\n\\nSo the actress turned to her family for inspiration.\\n\\n“My first [adoptive] dad died when I was 15, and his best friend, Bill, did all the dad stuff with me, so I did a mushing of our names,” Young says. “I felt like I could get away with it because I’m Southern.”\\n\\nAfter years of hopping from project to project, Young was given the opportunity to audition for the role of Mellie on Scandal. The character only had a few lines in the pilot episode, but Young says she showed up at the first table read for the season excited to work.\\n\\n“[Creator Shonda Rhimes] came around afterward and told everyone what their arc would be for that first season. She got to me, and I was so happy. Then she told me she thought I’d be in about three episodes. She wanted to write a presidential divorce,” Young recalls.\\n\\n“I died inside when I heard that. But I kept a smile on my face and showed up to work every day. At some point, they decided it was fun to write stuff for me,” continues Young, who has also released an album of cover songs called Far Away So Close. “I’m having such a good time. I don’t want it to ever end.”\\n\\nFor more of Young’s story, pick up the latest issue of PEOPLE, on newsstands Friday\\n\\nRELATED VIDEO: Why Bellamy Young Said Olivia Pope Would Be ‘Distraught’ on Scandal Season Finale\\n\\nScandal – along with Rhimes’ other #TGIT hits Grey’s Anatomy and How to Get Away with Murder – premieres Sept. 24 on ABC.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['text'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='navy'>*3. Defining functions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*3.1 Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_disp(model_type, preds, y_test, cmap=plt.cm.Blues):\n",
    "    plt.figure(1)\n",
    "    conf_matr = confusion_matrix(y_test, preds)\n",
    "    y_label_names = y_test.unique()\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matr, display_labels=y_label_names)\n",
    "    disp.plot(cmap=cmap, xticks_rotation=\"vertical\")\n",
    "    disp.ax_.set_title((\"Confusion Matrix \" + model_type)) \n",
    "\n",
    "def draw_diagnostic(model_type, history):\n",
    "    plt.figure(1)\n",
    "    plt.title('Loss of ' + model_type)\n",
    "    plt.plot(history['loss'], color='red', label='train')\n",
    "    plt.plot(history['val_loss'], color='blue', label='test')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(['training', 'validation'])\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.title('Accuracy of ' + model_type)\n",
    "    plt.plot(history['acc'], color='red', label='train')\n",
    "    plt.plot(history['val_acc'], color='blue', label='test')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(['training', 'validation'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*3.2 Convolutional Neural Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 107359, 64)        11305856  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 107359, 64)        28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 53679, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3435456)           0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 3435457   \n",
      "=================================================================\n",
      "Total params: 14,770,049\n",
      "Trainable params: 14,770,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=885x1057>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "loss='binary_crossentropy'\n",
    "optimizer='adam'\n",
    "vocab_length_ohe = 176654\n",
    "max_seq_length_ohe = 107359\n",
    "\n",
    "def cnn_model(vocab_length, max_seq_length, input_dim = X_train_ohe.shape[1], activation = 'sigmoid'):\n",
    "    embedding_dim = 64\n",
    "   \n",
    "    cnn = Sequential()\n",
    "\n",
    "    cnn.add(Embedding(vocab_length, embedding_dim,  input_length=max_seq_length))\n",
    "\n",
    "    cnn.add(Conv1D(64 , 7, activation='relu', padding='same'))\n",
    "\n",
    "    cnn.add(MaxPooling1D(2))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    cnn.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    cnn.summary()\n",
    "    return cnn\n",
    "\n",
    "cnn = cnn_model(vocab_length_ohe,max_seq_length_ohe)\n",
    "visualkeras.layered_view(cnn, legend=True, font=ImageFont.truetype(\"arial.ttf\", 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsNetEnv_ohe(gym.Env,):\n",
    "    def __init__(self, text_per_episode=1, dataset=(X_train_ohe, np.array(y_train_ohe)), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=X_train_ohe[0].shape,\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "        self.text_per_episode = text_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.text_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='navy'>*4. Machine Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*4.1 Initial model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 58.179396867752075 seconds\n",
      "Current memory usage is 4.296436MB; Peak was 7.84606MB\n"
     ]
    }
   ],
   "source": [
    "nb_ohe_initial = ComplementNB()\n",
    "\n",
    "file_nb_ohe_initial = pathlib.Path(\"nb_ohe_initial.npy\")\n",
    "if not file_nb_ohe_initial.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_nb_ohe = time.time()\n",
    "\n",
    "    nb_ohe_initial.fit(X_train_ohe, y_train_ohe)\n",
    "\n",
    "    training_time_nb_ohe = time.time() - start_time_nb_ohe\n",
    "    current_nb_we, peak_nb_ohe = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_nb_ohe)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_nb_we / 10**6}MB; Peak was {peak_nb_ohe / 10**6}MB\")\n",
    "    current_nb_we, peak_nb_ohe = 0, 0\n",
    "\n",
    "    np.save('nb_ohe_initial.npy',nb_ohe_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ohe_initial = np.load('nb_ohe_initial.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7695115103874228\n"
     ]
    }
   ],
   "source": [
    "preds_nb_ohe_initial = nb_ohe_initial.predict(X_test_ohe)\n",
    "print('accuracy: '+str(accuracy_score(preds_nb_ohe_initial, y_test_ohe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*4.2 Hyperparameter Tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001,True\n",
      "0.001,False\n",
      "0.01,True\n",
      "0.01,False\n",
      "0.1,True\n",
      "0.1,False\n",
      "1,True\n",
      "1,False\n",
      "10,True\n",
      "10,False\n",
      "100,True\n",
      "100,False\n",
      "1000,True\n",
      "1000,False\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "fit_priors = [True, False]\n",
    "\n",
    "trained_models_nb = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    for fit_prior in fit_priors:\n",
    "            print(str(alpha)+','+str(fit_prior))\n",
    "            model = ComplementNB(alpha=alpha, fit_prior=fit_prior)\n",
    "            model.fit(X_train_ohe, y_train_ohe)\n",
    "            preds_nb_ohe = model.predict(X_test_ohe)\n",
    "            accuracy = accuracy_score(preds_nb_ohe, y_test_ohe)\n",
    "            trained_models_nb[str(alpha)+','+str(fit_prior)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models with different combinations of hyperparameters:\n",
      "\n",
      "\n",
      "0.001,True: acc = 0.774564851207187\n",
      "0.001,False: acc = 0.774564851207187\n",
      "0.01,True: acc = 0.7711959573273441\n",
      "0.01,False: acc = 0.7711959573273441\n",
      "0.1,True: acc = 0.7616507580011229\n",
      "0.1,False: acc = 0.7616507580011229\n",
      "1,True: acc = 0.7695115103874228\n",
      "1,False: acc = 0.7695115103874228\n",
      "10,True: acc = 0.7622122403144301\n",
      "10,False: acc = 0.7622122403144301\n",
      "100,True: acc = 0.7063447501403706\n",
      "100,False: acc = 0.7063447501403706\n",
      "1000,True: acc = 0.706064008983717\n",
      "1000,False: acc = 0.706064008983717\n"
     ]
    }
   ],
   "source": [
    "print(\"All models with different combinations of hyperparameters:\", end=\"\\n\\n\\n\")\n",
    "accuracies = {}\n",
    "for model, accuracy in trained_models_nb.items():\n",
    "    print(str(model)+':','acc = '+str(accuracy))\n",
    "    accuracies[model] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the highest accuracy is:\n",
      "\n",
      "('0.001,True', 0.774564851207187)\n"
     ]
    }
   ],
   "source": [
    "print(\"The model with the highest accuracy is:\", end=\"\\n\\n\")\n",
    "print(max(accuracies.items(), key = lambda k : k[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_nb = max(accuracies.items(), key = lambda k : k[1])[0].split(',')\n",
    "hyperparameters_nb\n",
    "\n",
    "np.save('hyperparameters_nb.npy',hyperparameters_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_nb = np.load('hyperparameters_nb.npy', allow_pickle='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_nb = float(hyperparameters_nb[0])\n",
    "fit_prior_nb = bool(hyperparameters_nb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_nb = max(accuracies.items(), key = lambda k : k[1])[0].split(',')\n",
    "hyperparameters_nb\n",
    "\n",
    "np.save('hyperparameters_nb.npy',hyperparameters_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_nb = np.load('hyperparameters_nb.npy', allow_pickle='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_nb = float(hyperparameters_nb[0])\n",
    "fit_prior_nb = bool(hyperparameters_nb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*4.3 Definitive model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 34.67273950576782 seconds\n",
      "Current memory usage is 4.443924MB; Peak was 7.993548MB\n"
     ]
    }
   ],
   "source": [
    "model_nb = ComplementNB(alpha=alpha_nb, fit_prior=fit_prior_nb)\n",
    "\n",
    "file_nb_ohe = pathlib.Path(\"nb_ohe.npy\")\n",
    "if not file_nb_ohe.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_nb_ohe = time.time()\n",
    "\n",
    "    model_nb.fit(X_train_ohe, y_train_ohe)\n",
    "\n",
    "    training_time_nb_ohe = time.time() - start_time_nb_ohe\n",
    "    current_nb_we, peak_nb_ohe = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_nb_ohe)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_nb_we / 10**6}MB; Peak was {peak_nb_ohe / 10**6}MB\")\n",
    "    current_nb_we, peak_nb_ohe = 0, 0\n",
    "\n",
    "    np.save('nb_ohe.npy',model_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*4.3.1 Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_nb_ohe = model_nb.predict(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"Naive Bayes\", preds_nb_ohe, y_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report Naive Bayes with One-Hot Encoding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.71      0.65      1046\n",
      "        True       0.87      0.80      0.83      2516\n",
      "\n",
      "    accuracy                           0.77      3562\n",
      "   macro avg       0.73      0.76      0.74      3562\n",
      "weighted avg       0.79      0.77      0.78      3562\n",
      "\n",
      "accuracy: 0.774564851207187\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report Naive Bayes\")\n",
    "print(classification_report(y_test_ohe, preds_nb_ohe))\n",
    "print('accuracy: '+str(accuracy_score(preds_nb_ohe, y_test_ohe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='navy'>*5. Deep Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*5.1 Initial model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length_ohe = 176654\n",
    "max_seq_length_ohe = 107359\n",
    "\n",
    "cnn_ohe_initial = cnn_model(vocab_length_ohe,max_seq_length_ohe)\n",
    "\n",
    "file_cnn_ohe_initial = pathlib.Path(\"cnn_ohe_initial.h5\")\n",
    "if not file_cnn_ohe_initial.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_cnn_ohe = time.time()\n",
    "\n",
    "    history_cnn_ohe_initial = cnn_ohe_initial.fit(X_train_ohe, y_train_ohe, validation_split=0.2, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    training_time_cnn_ohe = time.time() - start_time_cnn_ohe\n",
    "    current_cnn_ohe, peak_cnn_ohe = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_cnn_ohe)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_cnn_ohe / 10**6}MB; Peak was {peak_cnn_ohe / 10**6}MB\")\n",
    "\n",
    "    current_cnn_ohe, peak_cnn_ohe = 0, 0\n",
    "\n",
    "    cnn_ohe_initial.save(\"cnn_ohe_initial.h5\")\n",
    "\n",
    "    history_cnn_ohe_initial = history_cnn_ohe_initial.history\n",
    "    np.save('history_cnn_ohe_initial.npy',history_cnn_ohe_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "cnn_ohe_initial = tf.keras.models.load_model(\"cnn_ohe_initial.h5\")\n",
    "\n",
    "history_cnn_ohe_initial = np.load('history_cnn_ohe_initial.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8242560359348681\n"
     ]
    }
   ],
   "source": [
    "preds_cnn_ohe_initial = (cnn_ohe_initial.predict(X_test_ohe) > 0.5).astype(\"int32\")\n",
    "print('accuracy: '+str(accuracy_score(preds_cnn_ohe_initial, y_test_ohe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*5.2 Hyperparameter Tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy,rmsprop,5,64,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 26s 2ms/sample - loss: 1.3107 - acc: 0.7042 - val_loss: 1.4441 - val_acc: 0.7838\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 10s 903us/sample - loss: 1.0619 - acc: 0.8191 - val_loss: 1.2433 - val_acc: 0.7985\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 12s 1ms/sample - loss: 0.9563 - acc: 0.8631 - val_loss: 1.4023 - val_acc: 0.8185\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 9s 832us/sample - loss: 0.9204 - acc: 0.8887 - val_loss: 1.5251 - val_acc: 0.8192\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 10s 876us/sample - loss: 0.8461 - acc: 0.9097 - val_loss: 1.4610 - val_acc: 0.8098\n",
      "binary_crossentropy,rmsprop,5,64,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 10s 895us/sample - loss: 0.5344 - acc: 0.7862 - val_loss: 0.5554 - val_acc: 0.8105\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 9s 830us/sample - loss: 0.3823 - acc: 0.8563 - val_loss: 0.5176 - val_acc: 0.8354\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 9s 824us/sample - loss: 0.3029 - acc: 0.8907 - val_loss: 0.5734 - val_acc: 0.8305\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 10s 834us/sample - loss: 0.2413 - acc: 0.9132 - val_loss: 0.7574 - val_acc: 0.8322\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 9s 788us/sample - loss: 0.1920 - acc: 0.9325 - val_loss: 0.7361 - val_acc: 0.8217\n",
      "binary_crossentropy,rmsprop,5,128,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 9s 757us/sample - loss: 1.6211 - acc: 0.7102 - val_loss: 1.3175 - val_acc: 0.7603\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 8s 713us/sample - loss: 1.0515 - acc: 0.8234 - val_loss: 1.3091 - val_acc: 0.7761\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 7s 646us/sample - loss: 0.9386 - acc: 0.8594 - val_loss: 1.3732 - val_acc: 0.7905\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 8s 708us/sample - loss: 0.8856 - acc: 0.8844 - val_loss: 1.7335 - val_acc: 0.8034\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 8s 683us/sample - loss: 0.8470 - acc: 0.9053 - val_loss: 1.5848 - val_acc: 0.8087\n",
      "binary_crossentropy,rmsprop,5,128,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 7s 639us/sample - loss: 0.5393 - acc: 0.7773 - val_loss: 0.5506 - val_acc: 0.8164\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 7s 620us/sample - loss: 0.3840 - acc: 0.8586 - val_loss: 0.7124 - val_acc: 0.7750\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 7s 622us/sample - loss: 0.3051 - acc: 0.8849 - val_loss: 0.4913 - val_acc: 0.8361\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 7s 625us/sample - loss: 0.2417 - acc: 0.9135 - val_loss: 0.5177 - val_acc: 0.8385\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 7s 621us/sample - loss: 0.1872 - acc: 0.9334 - val_loss: 0.6310 - val_acc: 0.8333\n",
      "binary_crossentropy,rmsprop,10,64,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 704us/sample - loss: 2.4385 - acc: 0.6767 - val_loss: 1.3667 - val_acc: 0.7276\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 8s 709us/sample - loss: 1.2229 - acc: 0.8173 - val_loss: 1.3507 - val_acc: 0.7796\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 8s 743us/sample - loss: 1.0934 - acc: 0.8567 - val_loss: 1.5714 - val_acc: 0.7813\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 8s 732us/sample - loss: 1.0515 - acc: 0.8827 - val_loss: 1.4731 - val_acc: 0.7929\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 8s 728us/sample - loss: 0.9990 - acc: 0.9001 - val_loss: 1.6605 - val_acc: 0.8073\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 8s 731us/sample - loss: 0.9627 - acc: 0.9138 - val_loss: 1.6590 - val_acc: 0.8084\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 8s 723us/sample - loss: 0.9528 - acc: 0.9198 - val_loss: 1.7967 - val_acc: 0.8038\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 8s 722us/sample - loss: 0.9181 - acc: 0.9256 - val_loss: 1.8190 - val_acc: 0.8224\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 8s 713us/sample - loss: 0.9055 - acc: 0.9323 - val_loss: 1.8339 - val_acc: 0.8154\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 8s 719us/sample - loss: 0.8936 - acc: 0.9327 - val_loss: 1.9069 - val_acc: 0.8171\n",
      "binary_crossentropy,rmsprop,10,64,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 746us/sample - loss: 0.5273 - acc: 0.7993 - val_loss: 0.4909 - val_acc: 0.8213\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 8s 715us/sample - loss: 0.3736 - acc: 0.8599 - val_loss: 0.5017 - val_acc: 0.8371\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 8s 698us/sample - loss: 0.2909 - acc: 0.8894 - val_loss: 0.5049 - val_acc: 0.8368\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 8s 701us/sample - loss: 0.2286 - acc: 0.9128 - val_loss: 0.6327 - val_acc: 0.8392\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 8s 713us/sample - loss: 0.1874 - acc: 0.9311 - val_loss: 0.6960 - val_acc: 0.8385\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 8s 679us/sample - loss: 0.1588 - acc: 0.9432 - val_loss: 0.7383 - val_acc: 0.8266\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 8s 704us/sample - loss: 0.1275 - acc: 0.9544 - val_loss: 0.8046 - val_acc: 0.8171\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 8s 706us/sample - loss: 0.1163 - acc: 0.9617 - val_loss: 0.8534 - val_acc: 0.8256\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 8s 730us/sample - loss: 0.0955 - acc: 0.9677 - val_loss: 1.0687 - val_acc: 0.8273\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 9s 747us/sample - loss: 0.0897 - acc: 0.9721 - val_loss: 1.1097 - val_acc: 0.8277\n",
      "binary_crossentropy,rmsprop,10,128,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 676us/sample - loss: 1.4162 - acc: 0.7120 - val_loss: 1.2626 - val_acc: 0.7539\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 7s 653us/sample - loss: 1.0626 - acc: 0.8236 - val_loss: 1.3084 - val_acc: 0.7803\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 8s 660us/sample - loss: 0.9683 - acc: 0.8622 - val_loss: 1.6514 - val_acc: 0.8010\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 8s 670us/sample - loss: 0.9306 - acc: 0.8857 - val_loss: 1.4273 - val_acc: 0.7943\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 7s 652us/sample - loss: 0.8945 - acc: 0.9027 - val_loss: 1.6244 - val_acc: 0.8126\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 8s 671us/sample - loss: 0.8561 - acc: 0.9150 - val_loss: 1.5729 - val_acc: 0.8055\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 8s 676us/sample - loss: 0.8236 - acc: 0.9260 - val_loss: 1.6734 - val_acc: 0.8087\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.8191 - acc: 0.9333 - val_loss: 1.7199 - val_acc: 0.8112\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 8s 670us/sample - loss: 0.8120 - acc: 0.9371 - val_loss: 1.8677 - val_acc: 0.8150\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 8s 662us/sample - loss: 0.8091 - acc: 0.9390 - val_loss: 1.8769 - val_acc: 0.8157\n",
      "binary_crossentropy,rmsprop,10,128,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 680us/sample - loss: 0.5451 - acc: 0.7749 - val_loss: 0.8783 - val_acc: 0.6609\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 8s 672us/sample - loss: 0.3937 - acc: 0.8595 - val_loss: 0.4953 - val_acc: 0.8301\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 7s 649us/sample - loss: 0.2965 - acc: 0.8929 - val_loss: 0.5620 - val_acc: 0.8385\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 7s 653us/sample - loss: 0.2356 - acc: 0.9155 - val_loss: 0.5897 - val_acc: 0.8312\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 8s 679us/sample - loss: 0.1971 - acc: 0.9322 - val_loss: 0.6970 - val_acc: 0.8280\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 8s 658us/sample - loss: 0.1561 - acc: 0.9480 - val_loss: 0.7856 - val_acc: 0.8280\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 7s 648us/sample - loss: 0.1394 - acc: 0.9551 - val_loss: 0.8117 - val_acc: 0.8294\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 7s 647us/sample - loss: 0.1117 - acc: 0.9638 - val_loss: 0.8369 - val_acc: 0.8227\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.0992 - acc: 0.9679 - val_loss: 1.0333 - val_acc: 0.8273\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 8s 667us/sample - loss: 0.0862 - acc: 0.9717 - val_loss: 1.0374 - val_acc: 0.8199\n",
      "binary_crossentropy,rmsprop,20,64,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 8s 720us/sample - loss: 1.5292 - acc: 0.7451 - val_loss: 1.3332 - val_acc: 0.7936\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 8s 734us/sample - loss: 1.1545 - acc: 0.8307 - val_loss: 1.9166 - val_acc: 0.7890\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 741us/sample - loss: 1.1433 - acc: 0.8636 - val_loss: 1.7285 - val_acc: 0.8041\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 8s 701us/sample - loss: 1.1045 - acc: 0.8874 - val_loss: 1.4427 - val_acc: 0.7989\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 8s 684us/sample - loss: 1.0227 - acc: 0.9050 - val_loss: 1.7249 - val_acc: 0.8161\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 8s 686us/sample - loss: 0.9950 - acc: 0.9117 - val_loss: 1.6142 - val_acc: 0.8105\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.9982 - acc: 0.9177 - val_loss: 1.7563 - val_acc: 0.8027\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 8s 685us/sample - loss: 0.9415 - acc: 0.9279 - val_loss: 1.7272 - val_acc: 0.8112\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 8s 685us/sample - loss: 0.9201 - acc: 0.9290 - val_loss: 1.7059 - val_acc: 0.8112\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 8s 689us/sample - loss: 0.9146 - acc: 0.9326 - val_loss: 1.9572 - val_acc: 0.8119\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 8s 681us/sample - loss: 0.9121 - acc: 0.9343 - val_loss: 1.9700 - val_acc: 0.8168\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 8s 687us/sample - loss: 0.9089 - acc: 0.9366 - val_loss: 1.9763 - val_acc: 0.8263\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 8s 693us/sample - loss: 0.8997 - acc: 0.9386 - val_loss: 1.9460 - val_acc: 0.8059\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 8s 682us/sample - loss: 0.9028 - acc: 0.9387 - val_loss: 2.0409 - val_acc: 0.8227\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 8s 673us/sample - loss: 0.9045 - acc: 0.9389 - val_loss: 2.0440 - val_acc: 0.8168\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 8s 661us/sample - loss: 0.8997 - acc: 0.9385 - val_loss: 2.0110 - val_acc: 0.8185\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 8s 663us/sample - loss: 0.9025 - acc: 0.9397 - val_loss: 2.0718 - val_acc: 0.8196\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 8s 684us/sample - loss: 0.8918 - acc: 0.9405 - val_loss: 2.0785 - val_acc: 0.8168\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 8s 683us/sample - loss: 0.8931 - acc: 0.9397 - val_loss: 2.1289 - val_acc: 0.8150\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 9s 762us/sample - loss: 0.8998 - acc: 0.9395 - val_loss: 2.1122 - val_acc: 0.8140\n",
      "binary_crossentropy,rmsprop,20,64,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 9s 758us/sample - loss: 0.5313 - acc: 0.7988 - val_loss: 0.5094 - val_acc: 0.8171\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 8s 736us/sample - loss: 0.3679 - acc: 0.8618 - val_loss: 0.4921 - val_acc: 0.8389\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 744us/sample - loss: 0.2822 - acc: 0.8912 - val_loss: 0.5688 - val_acc: 0.8371\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 9s 773us/sample - loss: 0.2256 - acc: 0.9111 - val_loss: 0.6507 - val_acc: 0.8329\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 9s 759us/sample - loss: 0.1854 - acc: 0.9255 - val_loss: 0.7181 - val_acc: 0.8322\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 9s 749us/sample - loss: 0.1543 - acc: 0.9404 - val_loss: 0.8358 - val_acc: 0.8206\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 9s 762us/sample - loss: 0.1322 - acc: 0.9487 - val_loss: 0.9338 - val_acc: 0.8234\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 9s 781us/sample - loss: 0.1189 - acc: 0.9556 - val_loss: 0.9955 - val_acc: 0.8073\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 8s 729us/sample - loss: 0.1002 - acc: 0.9576 - val_loss: 1.1929 - val_acc: 0.7989\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 8s 742us/sample - loss: 0.0981 - acc: 0.9629 - val_loss: 1.3067 - val_acc: 0.8189\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 8s 740us/sample - loss: 0.0867 - acc: 0.9654 - val_loss: 1.4471 - val_acc: 0.8192\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 8s 740us/sample - loss: 0.0833 - acc: 0.9669 - val_loss: 1.3364 - val_acc: 0.8122\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 8s 739us/sample - loss: 0.0729 - acc: 0.9695 - val_loss: 1.6225 - val_acc: 0.8213\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 8s 737us/sample - loss: 0.0677 - acc: 0.9713 - val_loss: 1.6243 - val_acc: 0.7996\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 9s 755us/sample - loss: 0.0711 - acc: 0.9715 - val_loss: 1.7010 - val_acc: 0.7964\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 8s 744us/sample - loss: 0.0628 - acc: 0.9726 - val_loss: 1.8255 - val_acc: 0.7971\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 9s 753us/sample - loss: 0.0621 - acc: 0.9738 - val_loss: 1.9057 - val_acc: 0.7736\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 8s 732us/sample - loss: 0.0629 - acc: 0.9748 - val_loss: 1.8867 - val_acc: 0.7908\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 8s 719us/sample - loss: 0.0594 - acc: 0.9755 - val_loss: 1.9016 - val_acc: 0.8045\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 8s 728us/sample - loss: 0.0578 - acc: 0.9743 - val_loss: 2.2051 - val_acc: 0.8119\n",
      "binary_crossentropy,rmsprop,20,128,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 8s 715us/sample - loss: 1.4405 - acc: 0.6988 - val_loss: 1.0752 - val_acc: 0.7115\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 8s 667us/sample - loss: 1.0173 - acc: 0.8082 - val_loss: 1.2192 - val_acc: 0.7796\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 678us/sample - loss: 0.9306 - acc: 0.8700 - val_loss: 1.5732 - val_acc: 0.7999\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 8s 665us/sample - loss: 0.8657 - acc: 0.8935 - val_loss: 1.2087 - val_acc: 0.7792\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 8s 680us/sample - loss: 0.8320 - acc: 0.9125 - val_loss: 1.4033 - val_acc: 0.7985\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 8s 711us/sample - loss: 0.8220 - acc: 0.9186 - val_loss: 1.5872 - val_acc: 0.8115\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 8s 685us/sample - loss: 0.7974 - acc: 0.9260 - val_loss: 1.7423 - val_acc: 0.8147\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 8s 682us/sample - loss: 0.7722 - acc: 0.9337 - val_loss: 1.7924 - val_acc: 0.7971\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 8s 666us/sample - loss: 0.7747 - acc: 0.9348 - val_loss: 1.6889 - val_acc: 0.8122\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 8s 660us/sample - loss: 0.7522 - acc: 0.9413 - val_loss: 1.7276 - val_acc: 0.8069\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 8s 661us/sample - loss: 0.7354 - acc: 0.9452 - val_loss: 1.7245 - val_acc: 0.8038\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 8s 663us/sample - loss: 0.7318 - acc: 0.9451 - val_loss: 1.8450 - val_acc: 0.8048\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 8s 667us/sample - loss: 0.7213 - acc: 0.9467 - val_loss: 2.8570 - val_acc: 0.7108\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 7s 658us/sample - loss: 0.7277 - acc: 0.9460 - val_loss: 1.7929 - val_acc: 0.8129\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 8s 671us/sample - loss: 0.7116 - acc: 0.9486 - val_loss: 1.8957 - val_acc: 0.8178\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 8s 664us/sample - loss: 0.7254 - acc: 0.9485 - val_loss: 1.8971 - val_acc: 0.8164\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 8s 667us/sample - loss: 0.7202 - acc: 0.9486 - val_loss: 1.8801 - val_acc: 0.8175\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 8s 663us/sample - loss: 0.7208 - acc: 0.9487 - val_loss: 1.9762 - val_acc: 0.7936\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 8s 671us/sample - loss: 0.7326 - acc: 0.9461 - val_loss: 1.8730 - val_acc: 0.8154\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 8s 658us/sample - loss: 0.7112 - acc: 0.9488 - val_loss: 1.9510 - val_acc: 0.8020\n",
      "binary_crossentropy,rmsprop,20,128,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 8s 687us/sample - loss: 0.5531 - acc: 0.7603 - val_loss: 0.5091 - val_acc: 0.8220\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 8s 672us/sample - loss: 0.3941 - acc: 0.8520 - val_loss: 0.5367 - val_acc: 0.8069\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 661us/sample - loss: 0.3046 - acc: 0.8821 - val_loss: 0.4944 - val_acc: 0.8294\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 8s 664us/sample - loss: 0.2470 - acc: 0.9061 - val_loss: 0.5134 - val_acc: 0.8122\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 8s 685us/sample - loss: 0.1989 - acc: 0.9244 - val_loss: 0.5311 - val_acc: 0.8284\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 8s 700us/sample - loss: 0.1624 - acc: 0.9385 - val_loss: 0.6975 - val_acc: 0.8403\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 8s 666us/sample - loss: 0.1404 - acc: 0.9482 - val_loss: 0.6784 - val_acc: 0.8241\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 8s 671us/sample - loss: 0.1105 - acc: 0.9582 - val_loss: 0.7791 - val_acc: 0.8371\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 8s 664us/sample - loss: 0.0979 - acc: 0.9656 - val_loss: 0.8645 - val_acc: 0.8305\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 8s 666us/sample - loss: 0.0851 - acc: 0.9718 - val_loss: 0.8057 - val_acc: 0.8154\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 8s 662us/sample - loss: 0.0776 - acc: 0.9739 - val_loss: 1.0634 - val_acc: 0.8241\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 8s 667us/sample - loss: 0.0705 - acc: 0.9752 - val_loss: 0.9990 - val_acc: 0.8126\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.0631 - acc: 0.9767 - val_loss: 1.0655 - val_acc: 0.7855\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.0560 - acc: 0.9793 - val_loss: 1.4351 - val_acc: 0.8206\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 8s 663us/sample - loss: 0.0544 - acc: 0.9796 - val_loss: 1.2774 - val_acc: 0.8185\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 8s 677us/sample - loss: 0.0497 - acc: 0.9803 - val_loss: 1.4503 - val_acc: 0.8168\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 8s 672us/sample - loss: 0.0512 - acc: 0.9803 - val_loss: 1.3806 - val_acc: 0.7975\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.0461 - acc: 0.9817 - val_loss: 1.5229 - val_acc: 0.8059\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.0478 - acc: 0.9828 - val_loss: 1.6860 - val_acc: 0.8157\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 8s 668us/sample - loss: 0.0482 - acc: 0.9820 - val_loss: 1.6057 - val_acc: 0.8094\n",
      "binary_crossentropy,adam,5,64,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 8s 678us/sample - loss: 1.5491 - acc: 0.6834 - val_loss: 1.1345 - val_acc: 0.7080\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 0.9729 - acc: 0.7740 - val_loss: 1.2304 - val_acc: 0.7554\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 8s 660us/sample - loss: 0.8536 - acc: 0.8467 - val_loss: 1.2066 - val_acc: 0.7806\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 0.7845 - acc: 0.8880 - val_loss: 1.3081 - val_acc: 0.7898\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 8s 665us/sample - loss: 0.7679 - acc: 0.8918 - val_loss: 1.1125 - val_acc: 0.7908\n",
      "binary_crossentropy,adam,5,64,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 8s 676us/sample - loss: 0.5510 - acc: 0.7192 - val_loss: 0.5361 - val_acc: 0.7217\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 8s 660us/sample - loss: 0.3960 - acc: 0.7746 - val_loss: 0.4744 - val_acc: 0.8206\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 8s 661us/sample - loss: 0.2732 - acc: 0.8902 - val_loss: 0.4563 - val_acc: 0.8357\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.1777 - acc: 0.9330 - val_loss: 0.5241 - val_acc: 0.8277\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 8s 661us/sample - loss: 0.1381 - acc: 0.9527 - val_loss: 0.5770 - val_acc: 0.8259\n",
      "binary_crossentropy,adam,5,128,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 1.4381 - acc: 0.6735 - val_loss: 1.1738 - val_acc: 0.7364\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 7s 636us/sample - loss: 1.0165 - acc: 0.8140 - val_loss: 1.2683 - val_acc: 0.7792\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 7s 645us/sample - loss: 0.8370 - acc: 0.8622 - val_loss: 1.1953 - val_acc: 0.7961\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 7s 638us/sample - loss: 0.7487 - acc: 0.8858 - val_loss: 1.1917 - val_acc: 0.7764\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 7s 640us/sample - loss: 0.7278 - acc: 0.8990 - val_loss: 1.0641 - val_acc: 0.7862\n",
      "binary_crossentropy,adam,5,128,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/5\n",
      "11395/11395 [==============================] - 8s 666us/sample - loss: 0.5585 - acc: 0.7275 - val_loss: 0.5339 - val_acc: 0.7318\n",
      "Epoch 2/5\n",
      "11395/11395 [==============================] - 7s 632us/sample - loss: 0.4120 - acc: 0.8239 - val_loss: 0.4617 - val_acc: 0.8371\n",
      "Epoch 3/5\n",
      "11395/11395 [==============================] - 7s 632us/sample - loss: 0.2999 - acc: 0.8860 - val_loss: 0.5023 - val_acc: 0.8371\n",
      "Epoch 4/5\n",
      "11395/11395 [==============================] - 7s 636us/sample - loss: 0.2316 - acc: 0.9199 - val_loss: 0.5275 - val_acc: 0.8420\n",
      "Epoch 5/5\n",
      "11395/11395 [==============================] - 7s 637us/sample - loss: 0.1701 - acc: 0.9403 - val_loss: 0.5210 - val_acc: 0.8389\n",
      "binary_crossentropy,adam,10,64,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 692us/sample - loss: 1.5065 - acc: 0.7200 - val_loss: 1.1685 - val_acc: 0.6616\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 8s 660us/sample - loss: 1.1102 - acc: 0.8338 - val_loss: 1.2393 - val_acc: 0.7768\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.9781 - acc: 0.8464 - val_loss: 1.4438 - val_acc: 0.7750\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 7s 654us/sample - loss: 0.8947 - acc: 0.8832 - val_loss: 1.3815 - val_acc: 0.7922\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 8s 680us/sample - loss: 0.8420 - acc: 0.9107 - val_loss: 1.1713 - val_acc: 0.7761\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 7s 653us/sample - loss: 0.8095 - acc: 0.9195 - val_loss: 1.4368 - val_acc: 0.8013\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 7s 651us/sample - loss: 0.8098 - acc: 0.9279 - val_loss: 1.4708 - val_acc: 0.8041\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 0.7972 - acc: 0.9306 - val_loss: 1.5270 - val_acc: 0.8059\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 7s 655us/sample - loss: 0.7889 - acc: 0.9342 - val_loss: 1.3423 - val_acc: 0.7936\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.7851 - acc: 0.9359 - val_loss: 1.4435 - val_acc: 0.8017\n",
      "binary_crossentropy,adam,10,64,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 684us/sample - loss: 0.5537 - acc: 0.7565 - val_loss: 0.4923 - val_acc: 0.8203\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 7s 652us/sample - loss: 0.3789 - acc: 0.8599 - val_loss: 0.4624 - val_acc: 0.8410\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 8s 661us/sample - loss: 0.2703 - acc: 0.9008 - val_loss: 0.4915 - val_acc: 0.8354\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 7s 653us/sample - loss: 0.1970 - acc: 0.9342 - val_loss: 0.5026 - val_acc: 0.8319\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 7s 650us/sample - loss: 0.1400 - acc: 0.9536 - val_loss: 0.5342 - val_acc: 0.8350\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.1132 - acc: 0.9683 - val_loss: 0.5907 - val_acc: 0.8196\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 8s 662us/sample - loss: 0.0943 - acc: 0.9748 - val_loss: 0.6672 - val_acc: 0.8322\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 7s 652us/sample - loss: 0.0871 - acc: 0.9796 - val_loss: 0.5984 - val_acc: 0.8210\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 7s 648us/sample - loss: 0.0936 - acc: 0.9809 - val_loss: 0.6536 - val_acc: 0.8245\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 7s 650us/sample - loss: 0.0683 - acc: 0.9834 - val_loss: 0.6849 - val_acc: 0.8126\n",
      "binary_crossentropy,adam,10,128,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 2.4525 - acc: 0.7077 - val_loss: 1.2043 - val_acc: 0.7339\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 7s 634us/sample - loss: 1.0525 - acc: 0.8043 - val_loss: 1.0299 - val_acc: 0.7462\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 7s 631us/sample - loss: 0.8747 - acc: 0.8688 - val_loss: 1.0519 - val_acc: 0.7676\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 7s 637us/sample - loss: 0.8059 - acc: 0.8914 - val_loss: 1.2251 - val_acc: 0.8027\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 7s 635us/sample - loss: 0.7786 - acc: 0.8988 - val_loss: 1.1694 - val_acc: 0.7859\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 7s 636us/sample - loss: 0.8043 - acc: 0.8842 - val_loss: 1.3112 - val_acc: 0.8084\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 7s 639us/sample - loss: 0.6891 - acc: 0.9197 - val_loss: 1.1862 - val_acc: 0.7954\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 7s 634us/sample - loss: 0.6619 - acc: 0.9338 - val_loss: 1.3130 - val_acc: 0.8108\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 7s 634us/sample - loss: 0.6531 - acc: 0.9369 - val_loss: 1.3155 - val_acc: 0.8098\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 7s 636us/sample - loss: 0.6370 - acc: 0.9438 - val_loss: 1.3071 - val_acc: 0.8157\n",
      "binary_crossentropy,adam,10,128,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/10\n",
      "11395/11395 [==============================] - 8s 665us/sample - loss: 0.5677 - acc: 0.7434 - val_loss: 0.5142 - val_acc: 0.8199\n",
      "Epoch 2/10\n",
      "11395/11395 [==============================] - 7s 642us/sample - loss: 0.3987 - acc: 0.8555 - val_loss: 0.4810 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "11395/11395 [==============================] - 7s 641us/sample - loss: 0.3045 - acc: 0.8928 - val_loss: 0.4915 - val_acc: 0.8417\n",
      "Epoch 4/10\n",
      "11395/11395 [==============================] - 7s 639us/sample - loss: 0.2429 - acc: 0.9208 - val_loss: 0.5179 - val_acc: 0.8333\n",
      "Epoch 5/10\n",
      "11395/11395 [==============================] - 7s 633us/sample - loss: 0.2037 - acc: 0.9365 - val_loss: 0.5252 - val_acc: 0.8368\n",
      "Epoch 6/10\n",
      "11395/11395 [==============================] - 7s 642us/sample - loss: 0.1697 - acc: 0.9453 - val_loss: 0.5216 - val_acc: 0.8361\n",
      "Epoch 7/10\n",
      "11395/11395 [==============================] - 7s 635us/sample - loss: 0.1583 - acc: 0.9545 - val_loss: 0.5711 - val_acc: 0.8336\n",
      "Epoch 8/10\n",
      "11395/11395 [==============================] - 7s 632us/sample - loss: 0.1297 - acc: 0.9629 - val_loss: 0.5543 - val_acc: 0.8301\n",
      "Epoch 9/10\n",
      "11395/11395 [==============================] - 7s 637us/sample - loss: 0.1182 - acc: 0.9683 - val_loss: 0.6122 - val_acc: 0.8336\n",
      "Epoch 10/10\n",
      "11395/11395 [==============================] - 7s 636us/sample - loss: 0.1202 - acc: 0.9703 - val_loss: 0.6328 - val_acc: 0.8305\n",
      "binary_crossentropy,adam,20,64,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 8s 695us/sample - loss: 1.2820 - acc: 0.6952 - val_loss: 1.2483 - val_acc: 0.7483\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.9558 - acc: 0.7964 - val_loss: 1.1632 - val_acc: 0.7452\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 7s 658us/sample - loss: 0.8833 - acc: 0.8402 - val_loss: 1.2164 - val_acc: 0.7852\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 8s 658us/sample - loss: 0.7744 - acc: 0.8871 - val_loss: 1.0591 - val_acc: 0.7711\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 7s 654us/sample - loss: 0.7309 - acc: 0.9048 - val_loss: 1.2211 - val_acc: 0.8020\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 0.6883 - acc: 0.9237 - val_loss: 1.2590 - val_acc: 0.8055\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 7s 658us/sample - loss: 0.6555 - acc: 0.9316 - val_loss: 1.3963 - val_acc: 0.8147\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 0.6271 - acc: 0.9400 - val_loss: 1.3227 - val_acc: 0.8101\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.6155 - acc: 0.9450 - val_loss: 1.3022 - val_acc: 0.8034\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.6089 - acc: 0.9466 - val_loss: 1.2750 - val_acc: 0.8017\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 7s 654us/sample - loss: 0.6098 - acc: 0.9477 - val_loss: 1.3734 - val_acc: 0.8077\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 7s 655us/sample - loss: 0.6045 - acc: 0.9452 - val_loss: 1.3210 - val_acc: 0.8062\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 7s 658us/sample - loss: 0.6049 - acc: 0.9491 - val_loss: 1.2782 - val_acc: 0.7532\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.6745 - acc: 0.9125 - val_loss: 1.4002 - val_acc: 0.7950\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 7s 653us/sample - loss: 0.5937 - acc: 0.9394 - val_loss: 1.4337 - val_acc: 0.7968\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 7s 655us/sample - loss: 0.6323 - acc: 0.9148 - val_loss: 1.3329 - val_acc: 0.7852\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.5588 - acc: 0.9449 - val_loss: 1.4461 - val_acc: 0.8080\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.5443 - acc: 0.9481 - val_loss: 1.4833 - val_acc: 0.8062\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 0.5415 - acc: 0.9489 - val_loss: 1.4106 - val_acc: 0.8003\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 8s 694us/sample - loss: 0.5502 - acc: 0.9482 - val_loss: 1.3740 - val_acc: 0.8059\n",
      "binary_crossentropy,adam,20,64,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 9s 758us/sample - loss: 0.5515 - acc: 0.7281 - val_loss: 0.5029 - val_acc: 0.8175\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 8s 734us/sample - loss: 0.3775 - acc: 0.8599 - val_loss: 0.4630 - val_acc: 0.8357\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 716us/sample - loss: 0.2808 - acc: 0.8995 - val_loss: 0.5217 - val_acc: 0.8333\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 8s 724us/sample - loss: 0.2134 - acc: 0.9273 - val_loss: 0.5143 - val_acc: 0.8319\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 8s 719us/sample - loss: 0.1799 - acc: 0.9459 - val_loss: 0.5800 - val_acc: 0.7915\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 8s 711us/sample - loss: 0.1600 - acc: 0.9526 - val_loss: 0.6636 - val_acc: 0.8326\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 8s 701us/sample - loss: 0.1299 - acc: 0.9657 - val_loss: 0.6371 - val_acc: 0.8326\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 8s 711us/sample - loss: 0.1296 - acc: 0.9682 - val_loss: 0.6617 - val_acc: 0.8336\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 8s 706us/sample - loss: 0.1106 - acc: 0.9734 - val_loss: 0.7235 - val_acc: 0.8294\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 8s 691us/sample - loss: 0.1092 - acc: 0.9753 - val_loss: 0.7246 - val_acc: 0.8241\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 8s 678us/sample - loss: 0.0979 - acc: 0.9763 - val_loss: 0.8374 - val_acc: 0.8308\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 8s 685us/sample - loss: 0.0963 - acc: 0.9799 - val_loss: 0.7545 - val_acc: 0.8213\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 8s 689us/sample - loss: 0.0726 - acc: 0.9825 - val_loss: 0.8880 - val_acc: 0.8263\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 8s 696us/sample - loss: 0.0636 - acc: 0.9826 - val_loss: 0.8627 - val_acc: 0.8210\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 8s 685us/sample - loss: 0.0776 - acc: 0.9823 - val_loss: 0.8263 - val_acc: 0.8270\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.0515 - acc: 0.9838 - val_loss: 0.9034 - val_acc: 0.8231\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 7s 655us/sample - loss: 0.0568 - acc: 0.9844 - val_loss: 0.8325 - val_acc: 0.8178\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 8s 681us/sample - loss: 0.0601 - acc: 0.9840 - val_loss: 0.9712 - val_acc: 0.8256\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 8s 682us/sample - loss: 0.0561 - acc: 0.9848 - val_loss: 1.0489 - val_acc: 0.8217\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 8s 709us/sample - loss: 0.0575 - acc: 0.9846 - val_loss: 0.9004 - val_acc: 0.8119\n",
      "binary_crossentropy,adam,20,128,relu\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 8s 704us/sample - loss: 1.9243 - acc: 0.6970 - val_loss: 1.0993 - val_acc: 0.5753\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 1.0391 - acc: 0.7809 - val_loss: 1.3015 - val_acc: 0.7764\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 663us/sample - loss: 0.8677 - acc: 0.8298 - val_loss: 1.2532 - val_acc: 0.7810\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 8s 667us/sample - loss: 0.7812 - acc: 0.8840 - val_loss: 1.2152 - val_acc: 0.7792\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 7s 646us/sample - loss: 0.7370 - acc: 0.9073 - val_loss: 1.2934 - val_acc: 0.7898\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.7093 - acc: 0.9207 - val_loss: 1.3006 - val_acc: 0.7933\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 7s 647us/sample - loss: 0.6906 - acc: 0.9280 - val_loss: 1.3001 - val_acc: 0.7968\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 7s 645us/sample - loss: 0.6783 - acc: 0.9341 - val_loss: 1.3156 - val_acc: 0.7989\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 8s 659us/sample - loss: 0.6688 - acc: 0.9373 - val_loss: 1.3157 - val_acc: 0.7996\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 8s 660us/sample - loss: 0.6622 - acc: 0.9387 - val_loss: 1.3455 - val_acc: 0.8017\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 7s 643us/sample - loss: 0.6483 - acc: 0.9421 - val_loss: 1.3499 - val_acc: 0.7968\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 8s 664us/sample - loss: 0.6425 - acc: 0.9438 - val_loss: 1.3785 - val_acc: 0.8034\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 7s 658us/sample - loss: 0.6404 - acc: 0.9456 - val_loss: 1.3954 - val_acc: 0.8027\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.6401 - acc: 0.9466 - val_loss: 1.3862 - val_acc: 0.8006\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 8s 661us/sample - loss: 0.6352 - acc: 0.9468 - val_loss: 1.3990 - val_acc: 0.8038\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 8s 674us/sample - loss: 0.6301 - acc: 0.9482 - val_loss: 1.4141 - val_acc: 0.8041\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 7s 648us/sample - loss: 0.6283 - acc: 0.9480 - val_loss: 1.4363 - val_acc: 0.8041\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 7s 638us/sample - loss: 0.6268 - acc: 0.9498 - val_loss: 1.4024 - val_acc: 0.8024\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 7s 650us/sample - loss: 0.6240 - acc: 0.9509 - val_loss: 1.4057 - val_acc: 0.8031\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 8s 662us/sample - loss: 0.6135 - acc: 0.9498 - val_loss: 1.3885 - val_acc: 0.8024\n",
      "binary_crossentropy,adam,20,128,sigmoid\n",
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 8s 688us/sample - loss: 0.5414 - acc: 0.8104 - val_loss: 0.5231 - val_acc: 0.8298\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 8s 660us/sample - loss: 0.3335 - acc: 0.8844 - val_loss: 0.5367 - val_acc: 0.8266\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 666us/sample - loss: 0.2418 - acc: 0.9203 - val_loss: 0.6176 - val_acc: 0.8277\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 7s 644us/sample - loss: 0.1993 - acc: 0.9384 - val_loss: 0.5309 - val_acc: 0.8389\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 7s 633us/sample - loss: 0.1430 - acc: 0.9588 - val_loss: 0.5831 - val_acc: 0.8308\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 7s 654us/sample - loss: 0.1370 - acc: 0.9662 - val_loss: 0.6679 - val_acc: 0.7778\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.1313 - acc: 0.9703 - val_loss: 0.6009 - val_acc: 0.8266\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.1114 - acc: 0.9765 - val_loss: 0.7720 - val_acc: 0.8294\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.0957 - acc: 0.9792 - val_loss: 0.6827 - val_acc: 0.8041\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 7s 658us/sample - loss: 0.0884 - acc: 0.9811 - val_loss: 0.6623 - val_acc: 0.8270\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.0729 - acc: 0.9830 - val_loss: 0.6668 - val_acc: 0.8171\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 8s 691us/sample - loss: 0.0608 - acc: 0.9845 - val_loss: 0.7338 - val_acc: 0.8238\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 7s 656us/sample - loss: 0.0562 - acc: 0.9846 - val_loss: 0.8070 - val_acc: 0.8224\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 7s 639us/sample - loss: 0.0672 - acc: 0.9845 - val_loss: 0.7651 - val_acc: 0.8112\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 7s 612us/sample - loss: 0.0606 - acc: 0.9845 - val_loss: 0.7349 - val_acc: 0.8185\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 7s 617us/sample - loss: 0.0530 - acc: 0.9853 - val_loss: 0.7957 - val_acc: 0.8273\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 7s 615us/sample - loss: 0.0512 - acc: 0.9851 - val_loss: 0.7867 - val_acc: 0.8101\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 7s 657us/sample - loss: 0.0453 - acc: 0.9865 - val_loss: 0.8035 - val_acc: 0.8161\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 7s 637us/sample - loss: 0.0451 - acc: 0.9864 - val_loss: 0.8484 - val_acc: 0.8164\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 7s 630us/sample - loss: 0.0454 - acc: 0.9859 - val_loss: 0.8959 - val_acc: 0.8199\n"
     ]
    }
   ],
   "source": [
    "losses = ['binary_crossentropy']\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "epochs = [5, 10, 20]\n",
    "batch_sizes = [64, 128]\n",
    "activations = ['relu','sigmoid']\n",
    "\n",
    "trained_models_cnn = {}\n",
    "\n",
    "for loss in losses:\n",
    "    for optimizer in optimizers:\n",
    "        for epoch in epochs:\n",
    "            for batch_size in batch_sizes:\n",
    "                for activation in activations:\n",
    "                    print(str(loss)+','+str(optimizer)+','+str(epoch)+','+str(batch_size)+','+str(activation))\n",
    "                    model = cnn_model(vocab_length_ohe,max_seq_length_ohe, activation=activation)\n",
    "                    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "                    history = model.fit(X_train_ohe, y_train_ohe, validation_split=0.2, epochs=epoch, batch_size=batch_size)\n",
    "                    trained_models_cnn[str(loss)+','+str(optimizer)+','+str(epoch)+','+str(batch_size)+','+str(activation)] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models with different combinations of hyperparameters:\n",
      "\n",
      "\n",
      "binary_crossentropy,rmsprop,5,64,relu: acc = 0.7041685 loss = 1.310653672693277\n",
      "binary_crossentropy,rmsprop,5,64,sigmoid: acc = 0.78622204 loss = 0.5344496959419092\n",
      "binary_crossentropy,rmsprop,5,128,relu: acc = 0.7102238 loss = 1.6210763339569507\n",
      "binary_crossentropy,rmsprop,5,128,sigmoid: acc = 0.77727073 loss = 0.5392677955273841\n",
      "binary_crossentropy,rmsprop,10,64,relu: acc = 0.6767003 loss = 2.438486913695258\n",
      "binary_crossentropy,rmsprop,10,64,sigmoid: acc = 0.7992979 loss = 0.5273280823313128\n",
      "binary_crossentropy,rmsprop,10,128,relu: acc = 0.7119789 loss = 1.4162283308414996\n",
      "binary_crossentropy,rmsprop,10,128,sigmoid: acc = 0.7749013 loss = 0.5451256470284791\n",
      "binary_crossentropy,rmsprop,20,64,relu: acc = 0.7450636 loss = 1.529224556662917\n",
      "binary_crossentropy,rmsprop,20,64,sigmoid: acc = 0.7987714 loss = 0.5312922155925086\n",
      "binary_crossentropy,rmsprop,20,128,relu: acc = 0.6988153 loss = 1.440461957302989\n",
      "binary_crossentropy,rmsprop,20,128,sigmoid: acc = 0.7603335 loss = 0.5531114322828483\n",
      "binary_crossentropy,adam,5,64,relu: acc = 0.6833699 loss = 1.5490964241329124\n",
      "binary_crossentropy,adam,5,64,sigmoid: acc = 0.7191751 loss = 0.5509800294189403\n",
      "binary_crossentropy,adam,5,128,relu: acc = 0.6734533 loss = 1.4381476265445725\n",
      "binary_crossentropy,adam,5,128,sigmoid: acc = 0.72751206 loss = 0.5584619503002409\n",
      "binary_crossentropy,adam,10,64,relu: acc = 0.7199649 loss = 1.50646550532213\n",
      "binary_crossentropy,adam,10,64,sigmoid: acc = 0.7564721 loss = 0.553741400985406\n",
      "binary_crossentropy,adam,10,128,relu: acc = 0.7076788 loss = 2.452548786002641\n",
      "binary_crossentropy,adam,10,128,sigmoid: acc = 0.7433962 loss = 0.5676623411806805\n",
      "binary_crossentropy,adam,20,64,relu: acc = 0.6952172 loss = 1.2820250206947745\n",
      "binary_crossentropy,adam,20,64,sigmoid: acc = 0.72812635 loss = 0.5514632742268415\n",
      "binary_crossentropy,adam,20,128,relu: acc = 0.69697237 loss = 1.9243026219841262\n",
      "binary_crossentropy,adam,20,128,sigmoid: acc = 0.81044316 loss = 0.541416314973963\n"
     ]
    }
   ],
   "source": [
    "print(\"All models with different combinations of hyperparameters:\", end=\"\\n\\n\\n\")\n",
    "accuracies = {}\n",
    "for model, history in trained_models_cnn.items():\n",
    "    print(str(model)+':','acc = '+str(history.history['acc'][0]),'loss = '+str(history.history['loss'][0]))\n",
    "    accuracies[model] = history.history['acc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the highest accuracy is:\n",
      "\n",
      "('binary_crossentropy,adam,20,128,sigmoid', 0.81044316)\n"
     ]
    }
   ],
   "source": [
    "print(\"The model with the highest accuracy is:\", end=\"\\n\\n\")\n",
    "print(max(accuracies.items(), key = lambda k : k[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['binary_crossentropy', 'adam', '20', '128', 'sigmoid']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters_cnn = max(accuracies.items(), key = lambda k : k[1])[0].split(',')\n",
    "hyperparameters_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('hyperparameters_cnn.npy',hyperparameters_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_cnn = np.load('hyperparameters_cnn.npy', allow_pickle='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cnn = hyperparameters_cnn[0]\n",
    "optimizer_cnn = hyperparameters_cnn[1]\n",
    "epochs_cnn = int(hyperparameters_cnn[2])\n",
    "batch_size_cnn = int(hyperparameters_cnn[3])\n",
    "activation_cnn = hyperparameters_cnn[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*5.3 Definitive model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 8s 669us/sample - loss: 0.5619 - acc: 0.7450 - val_loss: 0.5080 - val_acc: 0.8210\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 7s 625us/sample - loss: 0.3965 - acc: 0.8591 - val_loss: 0.4649 - val_acc: 0.8403\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 8s 665us/sample - loss: 0.2865 - acc: 0.9023 - val_loss: 0.4741 - val_acc: 0.8399\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 8s 672us/sample - loss: 0.2162 - acc: 0.9314 - val_loss: 0.5209 - val_acc: 0.8347\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 8s 662us/sample - loss: 0.1688 - acc: 0.9469 - val_loss: 0.5806 - val_acc: 0.8354\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 7s 645us/sample - loss: 0.1392 - acc: 0.9595 - val_loss: 0.5174 - val_acc: 0.8245\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 7s 596us/sample - loss: 0.1183 - acc: 0.9685 - val_loss: 0.5699 - val_acc: 0.8270\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 7s 603us/sample - loss: 0.1015 - acc: 0.9736 - val_loss: 0.6091 - val_acc: 0.8368\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 7s 596us/sample - loss: 0.0858 - acc: 0.9778 - val_loss: 0.6311 - val_acc: 0.8301\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 7s 608us/sample - loss: 0.0872 - acc: 0.9760 - val_loss: 0.7426 - val_acc: 0.8326\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 7s 595us/sample - loss: 0.0751 - acc: 0.9813 - val_loss: 0.7522 - val_acc: 0.8301\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 7s 593us/sample - loss: 0.0753 - acc: 0.9820 - val_loss: 0.6991 - val_acc: 0.8241\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 7s 597us/sample - loss: 0.0643 - acc: 0.9827 - val_loss: 0.7556 - val_acc: 0.8280\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 7s 593us/sample - loss: 0.0604 - acc: 0.9817 - val_loss: 0.7361 - val_acc: 0.8231\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 7s 599us/sample - loss: 0.0532 - acc: 0.9835 - val_loss: 0.7953 - val_acc: 0.8213\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 7s 594us/sample - loss: 0.0512 - acc: 0.9835 - val_loss: 0.8847 - val_acc: 0.8249\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 7s 593us/sample - loss: 0.0528 - acc: 0.9843 - val_loss: 0.8579 - val_acc: 0.8231\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 7s 592us/sample - loss: 0.0473 - acc: 0.9844 - val_loss: 0.8527 - val_acc: 0.8234\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 7s 600us/sample - loss: 0.0443 - acc: 0.9848 - val_loss: 0.9632 - val_acc: 0.8252\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 7s 593us/sample - loss: 0.0483 - acc: 0.9854 - val_loss: 0.8855 - val_acc: 0.8168\n",
      "Training time: 141.15374660491943 seconds\n",
      "Current memory usage is 2.71926MB; Peak was 225.393106MB\n"
     ]
    }
   ],
   "source": [
    "vocab_length_ohe = 176654\n",
    "max_seq_length_ohe = 107359\n",
    "\n",
    "cnn_ohe = cnn_model(vocab_length_ohe,max_seq_length_ohe, activation=activation_cnn)\n",
    "\n",
    "file_cnn_ohe = pathlib.Path(\"cnn_ohe.h5\")\n",
    "if not file_cnn_ohe.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_cnn_ohe = time.time()\n",
    "    cnn.compile(loss=loss_cnn, optimizer=optimizer_cnn, metrics=['accuracy'])\n",
    "    history_cnn_ohe = cnn_ohe.fit(X_train_ohe, y_train_ohe, validation_split=0.2, batch_size=batch_size_cnn, epochs=epochs_cnn)\n",
    "\n",
    "    training_time_cnn_ohe = time.time() - start_time_cnn_ohe\n",
    "    current_cnn_ohe, peak_cnn_ohe = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_cnn_ohe)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_cnn_ohe / 10**6}MB; Peak was {peak_cnn_ohe / 10**6}MB\")\n",
    "\n",
    "    current_cnn_ohe, peak_cnn_ohe = 0, 0\n",
    "\n",
    "    cnn_ohe.save(\"cnn_ohe.h5\")\n",
    "\n",
    "    history_cnn_ohe = history_cnn_ohe.history\n",
    "    np.save('history_cnn_ohe.npy',history_cnn_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_ohe = tf.keras.models.load_model(\"cnn_ohe.h5\")\n",
    "\n",
    "history_cnn_ohe = np.load('history_cnn_ohe.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*5.3.1 Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cnn_ohe = (cnn_ohe.predict(X_test_ohe) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"CNN\", preds_cnn_ohe, y_test_ohe, cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report CNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.63      0.67      1046\n",
      "        True       0.86      0.90      0.87      2516\n",
      "\n",
      "    accuracy                           0.82      3562\n",
      "   macro avg       0.79      0.77      0.77      3562\n",
      "weighted avg       0.81      0.82      0.82      3562\n",
      "\n",
      "accuracy: 0.8189219539584504\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report CNN\")\n",
    "print(classification_report(y_test_ohe, preds_cnn_ohe))\n",
    "print('accuracy: '+str(accuracy_score(preds_cnn_ohe, y_test_ohe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_diagnostic(\"CNN\", history_cnn_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='navy'>*6. Deep Reinforcement Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*6.1 Initial model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/dqn_ohe_initial\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1811988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1811988>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1811988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1811988>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26A8908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26A8908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26A8908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26A8908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BE27CE88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BE27CE88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BE27CE88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BE27CE88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C18199C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1801888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1768748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1768748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1768748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1768748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BBBEF948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BBBEF948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BBBEF948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8BBBEF948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C183D348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C183D348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C183D348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C183D348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8A310D508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8A310D508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8A310D508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8A310D508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1809E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6D9A088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6D9A088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6D9A088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6D9A088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1950348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1950348>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1950348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C1950348>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17F4C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17F4C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17F4C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17F4C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1796F08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1796F08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1796F08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C1796F08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C19DE648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C19DE648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C19DE648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C19DE648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B66697C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B66697C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B66697C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B66697C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B3E10608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B3E10608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B3E10608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B3E10608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26B8108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26B8108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26B8108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C26B8108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C17C5688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C17C5688>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C17C5688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8C17C5688>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6AFDB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6AFDB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6AFDB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B6AFDB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B35899C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B35899C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B35899C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8B35899C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C11DC148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17BAB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17BAB48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17BAB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8C17BAB48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "DQN Training Time: 728.3215103149414\n",
      "Current memory usage is 58.171082MB; Peak was 154.371762MB\n"
     ]
    }
   ],
   "source": [
    "logger.configure(dir='./logs/dqn_ohe_initial', format_strs=['stdout', 'tensorboard'])\n",
    "env = FakeNewsNetEnv_ohe(text_per_episode=1)\n",
    "env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "dqn_ohe_initial = DQN(MlpPolicy, env, verbose=2, learning_rate=0.0001, batch_size=32)\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time_dqn_ohe_initial = time.time()\n",
    "dqn_ohe_initial.learn(total_timesteps = len(X_train_ohe)//2)\n",
    "print(\"DQN Training Time:\", time.time() - start_time_dqn_ohe_initial)\n",
    "current_dqn_ohe_initial, peak_dqn_ohe_initial = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "print(f\"Current memory usage is {current_dqn_ohe_initial / 10**6}MB; Peak was {peak_dqn_ohe_initial / 10**6}MB\")\n",
    "current_dqn_ohe_initial, peak_dqn_ohe_initial = 0, 0\n",
    "dqn_ohe_initial.save('dqn_ohe_initial.npy')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8183604716451431\n"
     ]
    }
   ],
   "source": [
    "preds_dqn_ohe_initial = dqn_ohe_initial.predict(X_test_ohe)[0]\n",
    "print('accuracy: '+str(accuracy_score(preds_dqn_ohe_initial, y_test_ohe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*6.2 Hyperparameter Tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.0001,128,7122\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CA5C808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CA5C808>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CA5C808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CA5C808>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04919CA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04919CA48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04919CA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04919CA48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA5CF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CB7B888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CB7B888>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CB7B888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CB7B888>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA4FD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA64448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB45248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB45248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB45248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB45248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC385C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC385C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC385C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC385C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAADC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAADC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAADC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAADC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAB3C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAA048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAA048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAA048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBAA048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CACA208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CACA208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CACA208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CACA208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CC25248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CC25248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CC25248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CC25248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC31608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC31608>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC31608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E88CC31608>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88C2F0508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88C2F0508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88C2F0508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88C2F0508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CB77C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDBFC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDBFC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDBFC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDBFC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDB988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDB988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDB988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CBDB988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAF7648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAF7648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAF7648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CAF7648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.0001,128,14244\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046160108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046160108>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046160108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046160108>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159E88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159E88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159E88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159E88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046159BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046160A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0461BD8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0461BD8C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0461BD8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0461BD8C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461F5AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461F5AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461F5AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461F5AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046219E88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046219E88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046219E88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046219E88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA6EB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA6EB48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA6EB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CA6EB48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461945C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461945C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461945C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461945C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046194E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046194E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046194E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046194E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462611C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462611C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462611C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462611C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0462E45C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0462E45C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0462E45C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0462E45C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046166448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046166448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046166448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046166448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0461BD448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CCA9DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CCA9DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CCA9DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CCA9DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F045E99388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F045E99388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F045E99388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F045E99388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046169A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046169A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046169A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046169A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F04635D208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F04635D208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F04635D208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F04635D208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462AC288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462AC288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462AC288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462AC288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046252688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462E48C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462E48C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462E48C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462E48C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04633A9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.0001,128,28488\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046EBCCC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046EBCCC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046EBCCC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046EBCCC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCCC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCA88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCA88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCA88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EBCA88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EC1688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EC1688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EC1688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EC1688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463C3D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463C3D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463C3D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463C3D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046FBE3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046FBE3C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046FBE3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F046FBE3C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0462B4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0469D2FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD19C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD19C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD19C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD19C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDB988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDB988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDB988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDB988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0470C2EC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0470C2EC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0470C2EC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0470C2EC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04703DB88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04703DB88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04703DB88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04703DB88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463F3148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463F3148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463F3148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0463F3148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD13CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD13CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD13CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88CD13CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FBE548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04700EF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04700EF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04700EF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04700EF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F047126408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F047126408>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F047126408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F047126408>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046ED5808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046ED5808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046ED5808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046ED5808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047154448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047154448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047154448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047154448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047080DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047080DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047080DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F047080DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04641F688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04641F688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04641F688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F04641F688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EDB0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EDB0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EDB0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046EDB0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0470E2548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0470E2548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0470E2548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0470E2548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28399    |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.01,128,7122\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895038648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895038648>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895038648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895038648>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046F8B148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046F8B148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046F8B148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046F8B148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895056A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895056A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895056A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895056A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDDBC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDDBC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDDBC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F046FDDBC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895132B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895132B08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895132B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895132B08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A0FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A04C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A04C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A04C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8930A04C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895066B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950C0348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950C0348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950C0348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950C0348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89504AEC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89504AEC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89504AEC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89504AEC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895212208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895212208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895212208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895212208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895095D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895095D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895095D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895095D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895076CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895212B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950D2F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950D2F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950D2F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950D2F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0464AA748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0464AA748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0464AA748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0464AA748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89531E508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89531E508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89531E508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89531E508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950CF6C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950CF6C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950CF6C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8950CF6C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8951CE408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8951CE408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8951CE408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8951CE408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0471AD648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.01,128,14244\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895B2D588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895B2D588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895B2D588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895B2D588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BACC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BACC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BACC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BACC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BA4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BA4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BA4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8958BA4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B2D988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B36808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B36808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B36808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B36808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09A08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09A08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09A08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09A08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BE13C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BE13C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BE13C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BE13C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD9448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895206CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895206CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895206CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895206CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895C09248>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BF6748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BF6748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BF6748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BF6748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C09448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B9B2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B9B2C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B9B2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B9B2C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B3FD48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B3FD48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B3FD48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895B3FD48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895D04A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895D04A08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895D04A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E895D04A08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895323F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BD6448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BFF688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BFF688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BFF688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BFF688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C8B648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C8B648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C8B648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C8B648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895CE78C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895CE78C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895CE78C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895CE78C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.01,128,28488\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E896377E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E896377E48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E896377E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E896377E48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4A08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895BB4A08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D00EC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D00EC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D00EC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D00EC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274560C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274560C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274560C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274560C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C7ED08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C7ED08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C7ED08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C7ED08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0275214C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0275214C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0275214C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0275214C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896377D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896367FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896367FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896367FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896367FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C2F808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C2F808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C2F808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895C2F808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274B1548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274B1548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274B1548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0274B1548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D92688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D92688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D92688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895D92688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0274D5108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0274D5108>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0274D5108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0274D5108>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B02C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B02C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B02C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B02C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275A7D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275A7D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275A7D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275A7D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02748D248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02748D248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02748D248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02748D248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275B0348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027570348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027570348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027570348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027570348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D7248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D7248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D7248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D7248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0276B9808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0276B9808>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0276B9808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F0276B9808>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027466608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027466608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027466608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027466608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276AAA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276AAA48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276AAA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276AAA48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275DF808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275DF808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275DF808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275DF808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895E12F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895E12F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895E12F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E895E12F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276E95C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276E95C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276E95C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0276E95C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027465508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027465508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027465508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027465508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14300    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 14299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14600    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 14599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16400    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 16399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17900    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 17899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 19699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21500    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 21499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 22699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28399    |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,100,128,7122\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A0D4B48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A0D4B48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89518B688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A2271C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A2271C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A2271C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A2271C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0D4AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F9488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F9488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F9488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F9488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A139148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A139148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A139148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A139148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DB2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DB2C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DB2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DB2C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A137D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A137D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A137D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A137D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A227A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A227A88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A227A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A227A88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A198108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A198108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A198108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A198108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DCE48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DCE48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DCE48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A0DCE48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A16DF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A16DF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A16DF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A16DF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1CB9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1CB9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1CB9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1CB9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D0C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D0C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D0C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F0275D0C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A328D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A328D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A328D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A328D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A135C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A135C88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A135C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02A135C88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A2589C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A2589C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A2589C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A2589C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027520608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027520608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027520608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027520608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A135D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A135D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A135D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A135D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A25DF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A25DF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A25DF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A25DF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A1F91C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,100,128,14244\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AC26808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AC26808>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AC26808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AC26808>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02A9AFF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC267C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC267C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC267C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC267C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC81748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC81748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC81748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC81748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ADA8F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ADA8F48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ADA8F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ADA8F48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC32908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC32908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC32908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC32908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE6EC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE6EC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE6EC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE6EC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC26788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE8808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE8808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE8808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACE8808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD4AC08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD4AC08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD4AC08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD4AC08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD1BF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD1BF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD1BF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD1BF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AD74988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AD74988>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AD74988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02AD74988>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD59588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ADDB4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACB5BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACB5BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACB5BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02ACB5BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ACC9F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ACC9F88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ACC9F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02ACC9F88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AC48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AC48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AC48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD7AC48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F027CC9D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC88088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC88088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC88088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AC88088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD74408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD74408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD74408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02AD74408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,100,128,28488\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02B9A34C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02B9A34C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02B9A34C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02B9A34C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDC48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDC48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDC48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDC48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BD588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9A3D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9BC2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9BC2C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9BC2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9BC2C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA9A408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA9A408>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA9A408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA9A408>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDA48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B4BDA48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B2C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B2C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B2C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B2C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA9A108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA8D0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA8D0C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA8D0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BA8D0C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23188>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23188>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23188>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA23188>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B9988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B9988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B9988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B9988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA8DAC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA8DAC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA8DAC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA8DAC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA16E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA16E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA16E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA16E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAC8788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAC8788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAC8788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAC8788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BC34048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BC34048>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BC34048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F02BC34048>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9D2488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9D2488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9D2488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9D2488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAD6208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAD6208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAD6208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BAD6208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B1D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B1D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B1D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02B9B1D48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BBFC9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BBFC9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BBFC9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BBFC9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001F02BA01BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15200    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16100    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16700    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17900    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18400    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19600    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20100    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20800    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20900    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21400    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 21399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22100    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22300    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22600    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22700    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23500    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23900    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24200    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24700    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25200    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25500    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25700    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26200    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26400    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26500    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26600    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26700    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26900    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27200    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27400    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27500    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27600    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27700    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27800    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27900    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28100    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28200    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28300    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28400    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28399    |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "policies = [MlpPolicy]\n",
    "learning_rates = [0.0001, 0.01,100]\n",
    "batch_sizes = [128]\n",
    "total_timesteps = [len(X_train_ohe)//2, len(X_train_ohe), len(X_train_ohe)*2]\n",
    "\n",
    "trained_models_dqn = {}\n",
    "\n",
    "for policy in policies:\n",
    "    for learning_rate in learning_rates:\n",
    "        for batch_size in batch_sizes:\n",
    "            for total_timestep in total_timesteps:\n",
    "                print(str(policy)+','+str(learning_rate)+','+str(batch_size)+','+str(total_timestep))\n",
    "                env = FakeNewsNetEnv_ohe(text_per_episode=1)\n",
    "                model = DQN(policy, env, verbose=2, learning_rate=learning_rate, batch_size=batch_size)\n",
    "                model.learn(total_timesteps = total_timestep)\n",
    "                env.close()\n",
    "                preds_dqn_ohe = model.predict(X_test_ohe)[0]\n",
    "                accuracy = accuracy_score(preds_dqn_ohe, y_test_ohe)\n",
    "                trained_models_dqn[str(policy)+','+str(learning_rate)+','+str(batch_size)+','+str(total_timestep)] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models with different combinations of hyperparameters:\n",
      "\n",
      "\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.0001,128,7122: acc = 0.8239752947782145\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.0001,128,14244: acc = 0.823694553621561\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.0001,128,28488: acc = 0.8408197641774284\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.01,128,7122: acc = 0.8029197080291971\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.01,128,14244: acc = 0.7304884896125772\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.01,128,28488: acc = 0.813307130825379\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,100,128,7122: acc = 0.29421673217293653\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,100,128,14244: acc = 0.7063447501403706\n",
      "<class 'stable_baselines.deepq.policies.MlpPolicy'>,100,128,28488: acc = 0.7063447501403706\n"
     ]
    }
   ],
   "source": [
    "print(\"All models with different combinations of hyperparameters:\", end=\"\\n\\n\\n\")\n",
    "accuracies = {}\n",
    "for model, accuracy in trained_models_dqn.items():\n",
    "    print(str(model)+':','acc = '+str(accuracy))\n",
    "    accuracies[model] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the highest accuracy is:\n",
      "\n",
      "(\"<class 'stable_baselines.deepq.policies.MlpPolicy'>,0.0001,128,28488\", 0.8408197641774284)\n"
     ]
    }
   ],
   "source": [
    "print(\"The model with the highest accuracy is:\", end=\"\\n\\n\")\n",
    "print(max(accuracies.items(), key = lambda k : k[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_dqn = max(accuracies.items(), key = lambda k : k[1])[0].split(',')\n",
    "hyperparameters_dqn\n",
    "np.save('hyperparameters_dqn.npy',hyperparameters_dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_dqn = np.load('hyperparameters_dqn.npy', allow_pickle='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dqn = hyperparameters_dqn[0]\n",
    "learning_rate_dqn = float(hyperparameters_dqn[1])\n",
    "batch_size_dqn = int(hyperparameters_dqn[2])\n",
    "total_timesteps_dqn = int(hyperparameters_dqn[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*6.3 Definitive model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/dqn_ohe\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8938F2D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8938F2D88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8938F2D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8938F2D88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F2D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893169248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893169248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893169248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893169248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F28C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F28C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F28C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938F28C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938889C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938889C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938889C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8938889C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939300C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939300C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939300C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939300C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893A10F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893A10F88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893A10F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893A10F88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8931EC288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8931EC288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8931EC288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8931EC288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893957CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893957CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893957CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893957CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939AD308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939AD308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939AD308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939AD308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939C1BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893930E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893930E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893930E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893930E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893985448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893985448>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893985448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893985448>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396CD88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396CD88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396CD88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396CD88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8932107C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8932107C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8932107C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8932107C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89398E9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89398E9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89398E9C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89398E9C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A4B488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A4B488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A4B488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A4B488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A424C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A424C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A424C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A424C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893908C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893908C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893908C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893908C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893BF2C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893BF2C08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893BF2C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E893BF2C08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893950908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893950908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893950908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893950908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8939ED3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BF2C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BF2C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BF2C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BF2C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893C67048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893C67048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893C67048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893C67048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396C608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396C608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396C608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E89396C608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28399    |\n",
      "--------------------------------------\n",
      "DQN Training Time: 10252.086066961288\n",
      "Current memory usage is 462.090524MB; Peak was 846.875195MB\n"
     ]
    }
   ],
   "source": [
    "logger.configure(dir='./logs/dqn_ohe', format_strs=['stdout', 'tensorboard'])\n",
    "env = FakeNewsNetEnv_ohe(text_per_episode=1)\n",
    "env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "dqn_ohe = DQN(MlpPolicy, env, verbose=2, learning_rate=learning_rate_dqn, batch_size=batch_size_dqn)\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time_dqn_ohe = time.time()\n",
    "dqn_ohe.learn(total_timesteps = total_timesteps_dqn)\n",
    "print(\"DQN Training Time:\", time.time() - start_time_dqn_ohe)\n",
    "current_dqn_ohe, peak_dqn_ohe = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "print(f\"Current memory usage is {current_dqn_ohe / 10**6}MB; Peak was {peak_dqn_ohe / 10**6}MB\")\n",
    "current_dqn_ohe, peak_dqn_ohe = 0, 0\n",
    "dqn_ohe.save('dqn_ohe.npy')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*6.3.1 Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dqn_ohe = dqn_ohe.predict(X_test_ohe)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report DQN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.61      0.68      1046\n",
      "        True       0.85      0.92      0.89      2516\n",
      "\n",
      "    accuracy                           0.83      3562\n",
      "   macro avg       0.81      0.77      0.78      3562\n",
      "weighted avg       0.83      0.83      0.82      3562\n",
      "\n",
      "accuracy: 0.8309938236945537\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report DQN\")\n",
    "print(classification_report(y_test_ohe, preds_dqn_ohe))\n",
    "print('accuracy: '+str(accuracy_score(preds_dqn_ohe, y_test_ohe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"DQN\", preds_dqn_ohe, y_test_ohe, cmap=plt.cm.Greens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir \"C:\\Users\\Meesv\\OneDrive\\Tilburg University\\Master\\Master Thesis\\2 Thesis\\Code\\logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='navy'>*7. Dimensionality reduction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*7.1 Text Summarization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_summarizer(text):\n",
    "    sentence_list = nltk.sent_tokenize(text)\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    word_frequencies = {}\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_list:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "    \n",
    "    summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_summarized_text = pathlib.Path(\"text_summarized.pkl\")\n",
    "if not file_summarized_text.exists ():\n",
    "    summaries = X['text'].apply(text_summarizer)\n",
    "    summaries.to_pickle(\"text_summarized.pkl\")\n",
    "    summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        When you visit the site, Dotdash Meredith and ...\n",
       "1        'When the show was announced in April, the net...\n",
       "2        [1]\\n\\nBackground [ edit ]\\n\\nShe lived in Cal...\n",
       "3        From there, you transition to the leg press ma...\n",
       "4        For you, it’s, ‘Do we still go to Celine’s sho...\n",
       "                               ...                        \n",
       "20239    The Food and Drug Administration, however, wil...\n",
       "20240    I just can’t.”\\n\\nDonald Trump claimed that Ju...\n",
       "20241    If you are at an office or shared network, you...\n",
       "20242    Since domain transfers are a manual process, i...\n",
       "20243    Contact your hosting provider for more informa...\n",
       "Name: text, Length: 17806, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = pd.read_pickle(\"text_summarized.pkl\")\n",
    "\n",
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "ohe_sum = count_vec.fit_transform(summaries)\n",
    "ohe_sum = np.array(ohe_sum.todense())\n",
    "\n",
    "X_train_ohe_sum, X_test_ohe_sum, y_train_ohe_sum, y_test_ohe_sum = train_test_split(ohe_sum, y['real'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*7.1.1 Machine Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 18.951168298721313 seconds\n",
      "Current memory usage is 2.021956MB; Peak was 3.752372MB\n"
     ]
    }
   ],
   "source": [
    "nb_ohe_sum = ComplementNB(alpha=alpha_nb, fit_prior=fit_prior_nb)\n",
    "\n",
    "file_nb_ohe_sum = pathlib.Path(\"nb_ohe_sum.npy\")\n",
    "if not file_nb_ohe_sum.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_ohe_sum = time.time()\n",
    "\n",
    "    nb_ohe_sum.fit(X_train_ohe_sum, y_train_ohe_sum)\n",
    "\n",
    "    training_time_ohe_sum = time.time() - start_time_ohe_sum\n",
    "    current_ohe_sum, peak_ohe_sum = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_ohe_sum)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_ohe_sum / 10**6}MB; Peak was {peak_ohe_sum / 10**6}MB\")\n",
    "    current_ohe_sum, peak_ohe_sum = 0, 0\n",
    "\n",
    "    np.save('nb_ohe_sum.npy', nb_ohe_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ohe_sum = np.load('nb_ohe_sum.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_nb_ohe_sum = nb_ohe_sum.predict(X_test_ohe_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"NB summarized \", preds_nb_ohe_sum, y_test_ohe_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report CNN summarized\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.63      0.65      1046\n",
      "        True       0.85      0.87      0.86      2516\n",
      "\n",
      "    accuracy                           0.80      3562\n",
      "   macro avg       0.76      0.75      0.76      3562\n",
      "weighted avg       0.80      0.80      0.80      3562\n",
      "\n",
      "accuracy: 0.80235822571589\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report CNN summarized\")\n",
    "print(classification_report(y_test_ohe_sum, preds_nb_ohe_sum))\n",
    "print('accuracy: '+str(accuracy_score(preds_nb_ohe_sum, y_test_ohe_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*7.1.2 Deep Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11395 samples, validate on 2849 samples\n",
      "Epoch 1/20\n",
      "11395/11395 [==============================] - 4s 382us/sample - loss: 0.5156 - acc: 0.7759 - val_loss: 0.4542 - val_acc: 0.8168\n",
      "Epoch 2/20\n",
      "11395/11395 [==============================] - 4s 309us/sample - loss: 0.3588 - acc: 0.8576 - val_loss: 0.4233 - val_acc: 0.8284\n",
      "Epoch 3/20\n",
      "11395/11395 [==============================] - 3s 303us/sample - loss: 0.2691 - acc: 0.9043 - val_loss: 0.4250 - val_acc: 0.8291\n",
      "Epoch 4/20\n",
      "11395/11395 [==============================] - 4s 316us/sample - loss: 0.2063 - acc: 0.9323 - val_loss: 0.4361 - val_acc: 0.8206\n",
      "Epoch 5/20\n",
      "11395/11395 [==============================] - 3s 307us/sample - loss: 0.1622 - acc: 0.9501 - val_loss: 0.4597 - val_acc: 0.8263\n",
      "Epoch 6/20\n",
      "11395/11395 [==============================] - 4s 311us/sample - loss: 0.1319 - acc: 0.9619 - val_loss: 0.4798 - val_acc: 0.8245\n",
      "Epoch 7/20\n",
      "11395/11395 [==============================] - 4s 310us/sample - loss: 0.1087 - acc: 0.9704 - val_loss: 0.4986 - val_acc: 0.8154\n",
      "Epoch 8/20\n",
      "11395/11395 [==============================] - 3s 305us/sample - loss: 0.0922 - acc: 0.9731 - val_loss: 0.5249 - val_acc: 0.8157\n",
      "Epoch 9/20\n",
      "11395/11395 [==============================] - 3s 305us/sample - loss: 0.0802 - acc: 0.9773 - val_loss: 0.5507 - val_acc: 0.8171\n",
      "Epoch 10/20\n",
      "11395/11395 [==============================] - 4s 308us/sample - loss: 0.0716 - acc: 0.9777 - val_loss: 0.5740 - val_acc: 0.8108\n",
      "Epoch 11/20\n",
      "11395/11395 [==============================] - 3s 298us/sample - loss: 0.0653 - acc: 0.9790 - val_loss: 0.5872 - val_acc: 0.8094\n",
      "Epoch 12/20\n",
      "11395/11395 [==============================] - 4s 313us/sample - loss: 0.0619 - acc: 0.9791 - val_loss: 0.6168 - val_acc: 0.8101\n",
      "Epoch 13/20\n",
      "11395/11395 [==============================] - 3s 303us/sample - loss: 0.0583 - acc: 0.9804 - val_loss: 0.6271 - val_acc: 0.8045\n",
      "Epoch 14/20\n",
      "11395/11395 [==============================] - 3s 301us/sample - loss: 0.0553 - acc: 0.9796 - val_loss: 0.6409 - val_acc: 0.8062\n",
      "Epoch 15/20\n",
      "11395/11395 [==============================] - 3s 306us/sample - loss: 0.0530 - acc: 0.9805 - val_loss: 0.6658 - val_acc: 0.8069\n",
      "Epoch 16/20\n",
      "11395/11395 [==============================] - 3s 307us/sample - loss: 0.0527 - acc: 0.9803 - val_loss: 0.6933 - val_acc: 0.8077\n",
      "Epoch 17/20\n",
      "11395/11395 [==============================] - 4s 312us/sample - loss: 0.0502 - acc: 0.9813 - val_loss: 0.6810 - val_acc: 0.8024\n",
      "Epoch 18/20\n",
      "11395/11395 [==============================] - 3s 304us/sample - loss: 0.0510 - acc: 0.9805 - val_loss: 0.6921 - val_acc: 0.7957\n",
      "Epoch 19/20\n",
      "11395/11395 [==============================] - 3s 297us/sample - loss: 0.0491 - acc: 0.9816 - val_loss: 0.7116 - val_acc: 0.7964\n",
      "Epoch 20/20\n",
      "11395/11395 [==============================] - 3s 290us/sample - loss: 0.0481 - acc: 0.9822 - val_loss: 0.7373 - val_acc: 0.8066\n",
      "Training time: 72.55667042732239 seconds\n",
      "Current memory usage is 2.865537MB; Peak was 107.580493MB\n"
     ]
    }
   ],
   "source": [
    "vocab_length_ohe_sum = 176654\n",
    "max_seq_length_ohe_sum = 107359\n",
    "\n",
    "cnn_ohe_sum = cnn_model(vocab_length_ohe_sum,max_seq_length_ohe_sum, input_dim = X_train_ohe_sum.shape[1], activation=activation_cnn)\n",
    "\n",
    "file_cnn_ohe_sum = pathlib.Path(\"cnn_ohe_sum.h5\")\n",
    "if not file_cnn_ohe_sum.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_cnn_ohe_sum = time.time()\n",
    "    cnn_ohe_sum.compile(loss=loss_cnn, optimizer=optimizer_cnn, metrics=['accuracy'])\n",
    "    history_cnn_ohe_sum = cnn_ohe_sum.fit(X_train_ohe_sum, y_train_ohe_sum, validation_split=0.2, batch_size=batch_size_cnn, epochs=epochs_cnn)\n",
    "\n",
    "    training_time_cnn_ohe_sum = time.time() - start_time_cnn_ohe_sum\n",
    "    current_cnn_ohe_sum, peak_cnn_ohe_sum = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_cnn_ohe_sum)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_cnn_ohe_sum / 10**6}MB; Peak was {peak_cnn_ohe_sum / 10**6}MB\")\n",
    "\n",
    "    current_cnn_ohe_sum, peak_cnn_ohe_sum = 0, 0\n",
    "\n",
    "    cnn_ohe_sum.save(\"cnn_ohe_sum.h5\")\n",
    "\n",
    "    history_cnn_ohe_sum = history_cnn_ohe_sum.history\n",
    "    np.save('history_cnn_ohe_sum.npy',history_cnn_ohe_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_ohe_sum = tf.keras.models.load_model(\"cnn_ohe_sum.h5\")\n",
    "\n",
    "history_cnn_ohe_sum = np.load('history_cnn_ohe_sum.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cnn_ohe_sum = (cnn_ohe_sum.predict(X_test_ohe_sum) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"CNN summarized\", preds_cnn_ohe_sum, y_test_ohe_sum, cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report CNN summarized\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.56      0.62      1046\n",
      "        True       0.83      0.90      0.86      2516\n",
      "\n",
      "    accuracy                           0.80      3562\n",
      "   macro avg       0.76      0.73      0.74      3562\n",
      "weighted avg       0.79      0.80      0.79      3562\n",
      "\n",
      "accuracy: 0.7978663672094329\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report CNN summarized\")\n",
    "print(classification_report(y_test_ohe_sum, preds_cnn_ohe_sum))\n",
    "print('accuracy: '+str(accuracy_score(preds_cnn_ohe_sum, y_test_ohe_sum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmGklEQVR4nO3dd3QUVRsG8GfTeyOkUZJQQ0RCDwSQJiV0ECkCEgERRYqI0qWI9KKAgIWqKIhIkyYgTVronaAIhJIQQNIh9X5/3G8XNn2TTSabfX7nzMnu7J3Zd3YC++ZWlRBCgIiIiMiImCgdABEREVFRYwJERERERocJEBERERkdJkBERERkdJgAERERkdFhAkRERERGhwkQERERGR0mQERERGR0mAARERGR0WECRJSFRYsWQaVSoXr16kqHUmLdvn0b7du3h4uLC1QqFUaOHJlj+aSkJCxZsgSNGzeGs7MzLCwsUKZMGfTo0QOHDh3SlDt48CBUKhVUKhWOHz+e6TwhISGws7PT2tesWTOoVCq0bds2yzhVKhXmzZuXvws1YurPbvXq1UX6vqtXr4ZKpcLt27eL9H3JsDABIsrCypUrAQBXrlzByZMnFY6mZProo49w8uRJrFy5EsePH8dHH32UbdnHjx+jUaNGGDVqFKpXr47Vq1dj//79mD9/PkxNTdGyZUtcuHAh03GffvqpTjHt2bMHf/75p87XQlnz9PTE8ePH0b59e6VDIcrETOkAiIqb06dP48KFC2jfvj127NiBFStWIDAwUOmwspSYmAgbGxulw8iXy5cvo379+ujSpUuuZd9++21cuHABe/bsQYsWLbRe69WrF0aNGgVnZ2et/W3btsXu3buxfft2dOzYMdf3qFKlClJTU/Hpp5/i1KlTUKlUOl0PvZCWlobU1FRYWlqiQYMGSodDlCXWABFlsGLFCgDArFmzEBQUhPXr1yMxMTFTufv372Pw4MEoV64cLCws4OXlhe7du+Phw4eaMtHR0fj4449RoUIFWFpaws3NDe3atcP169cBvGiuOXjwoNa5s2o6UDfdXLp0Ca1bt4a9vT1atmwJANi7dy86d+6MsmXLwsrKCpUqVcJ7772Hx48fZ4r7+vXr6N27N9zd3WFpaYny5cvj7bffRlJSEm7fvg0zMzPMnDkz03GHDx+GSqXCxo0bc/z8wsPD0bdvX7i5ucHS0hLVqlXD/PnzkZ6ernXN//zzD3bt2qVprsquueLMmTPYtWsXBg4cmCn5UatXrx7Kly+vtS8kJAT+/v4YN24c0tLScowZAMzNzfHFF1/gzJkz2LBhQ67ls7Js2TIEBATAzs4O9vb28PPzw/jx4zWvT5kyJcvEKqsmGx8fH3To0AG///47atWqBWtra1SrVg2///675phq1arB1tYW9evXx+nTpzNdv52dHa5fv442bdrA1tYWnp6emDVrFgDgxIkTaNy4MWxtbVGlShWsWbNG6/hHjx7hgw8+gL+/P+zs7ODm5oYWLVrgyJEjWuXUv6tz5szB9OnT4evrC0tLSxw4cCDL32P1/c5qe/n6T58+jU6dOsHFxQVWVlaoVasWfvnll0yf3YkTJ9CoUSNYWVnBy8sL48aNQ0pKSs43igisASLS8uzZM/z888+oV68eqlevjgEDBmDQoEHYuHEj+vfvryl3//591KtXDykpKRg/fjxq1KiBJ0+eYM+ePXj69Cnc3d0RFxeHxo0b4/bt2xgzZgwCAwMRHx+Pw4cPIyIiAn5+fjrHl5ycjE6dOuG9997D2LFjkZqaCgC4efMmGjZsiEGDBsHR0RG3b9/GggUL0LhxY1y6dAnm5uYAgAsXLqBx48ZwdXXFtGnTULlyZURERGDbtm1ITk6Gj48POnXqhOXLl+PTTz+Fqamp5r2XLFkCLy8vdO3aNdv4Hj16hKCgICQnJ+Pzzz+Hj48Pfv/9d4wePRo3b97E0qVLUbt2bRw/fhxdu3ZFxYoVNX1rPD09szznH3/8AQB5qil6mampKWbOnInOnTtjzZo1GDBgQK7H9OzZE/PmzcPEiRPxxhtvaD63vFi/fj0++OADDBs2DPPmzYOJiQn++ecfXL16Vae4X3bhwgWMGzcOEyZMgKOjI6ZOnYpu3bph3Lhx2L9/P2bMmAGVSoUxY8agQ4cOuHXrFqytrTXHp6SkoFu3bhgyZAg++eQT/PTTTxg3bhxiY2OxadMmjBkzBmXLlsXixYsREhKC6tWro06dOgCA//77DwAwefJkeHh4ID4+Hps3b0azZs2wf/9+NGvWTCvWRYsWoUqVKpg3bx4cHBxQuXLlLK8pY7+sZ8+eoV+/fkhLS4OLiwsA4MCBA2jbti0CAwOxfPlyODo6Yv369ejZsycSExMREhICALh69SpatmwJHx8frF69GjY2Nli6dCl++umnfH/mZEQEEWmsXbtWABDLly8XQggRFxcn7OzsRJMmTbTKDRgwQJibm4urV69me65p06YJAGLv3r3Zljlw4IAAIA4cOKC1/9atWwKAWLVqlWZf//79BQCxcuXKHK8hPT1dpKSkiDt37ggAYuvWrZrXWrRoIZycnERUVFSuMW3evFmz7/79+8LMzExMnTo1x/ceO3asACBOnjyptf/9998XKpVKhIWFafZ5e3uL9u3b53g+IYQYMmSIACCuX7+ea9mX49+4caMQQojGjRuLsmXLimfPngkh5Odoa2urdUzTpk3FK6+8IoQQYt++fQKAWLx4sRDixb2YO3duju/74YcfCicnpxzLTJ48WWT13+6qVasEAHHr1i3NPm9vb2FtbS3u3bun2Xf+/HkBQHh6eoqEhATN/i1btggAYtu2bZp96t+XTZs2afalpKSI0qVLCwDi7Nmzmv1PnjwRpqamYtSoUdnGnpqaKlJSUkTLli1F165dNfvVn0/FihVFcnKy1jFZ/R5nPGfnzp2FnZ2dOHPmjGa/n5+fqFWrlkhJSdEq36FDB+Hp6SnS0tKEEEL07NlTWFtbi8jISK1z+vn5Zfo8iTJiExjRS1asWAFra2v06tULAGBnZ4c333wTR44cwd9//60pt2vXLjRv3hzVqlXL9ly7du1ClSpV8Prrr+s1xjfeeCPTvqioKAwZMgTlypWDmZkZzM3N4e3tDQC4du0aANlf6NChQ+jRowdKly6d7fmbNWuGgIAAfP3115p9y5cvh0qlwuDBg3OM7c8//4S/vz/q16+vtT8kJARCCEU6GM+ePRv37t3DV199lafyLVu2ROvWrTFt2jTExcXl+X3q16+P6Oho9O7dG1u3bs2y+VFXNWvWRJkyZTTP1b9vzZo10+r7pd5/584dreNVKhXatWuneW5mZoZKlSrB09MTtWrV0ux3cXGBm5tbpuOXL1+O2rVrw8rKSvN7tX//fs3v1Ms6deqkU40ZAHz44YfYsWMHNm7ciNq1awMA/vnnH1y/fh19+vQBAKSmpmq2du3aISIiAmFhYQBkTVHLli3h7u6uOaepqSl69uypUxxknJgAEf3fP//8g8OHD6N9+/YQQiA6OhrR0dHo3r07gBcjwwDZ1FO2bNkcz5eXMrqysbGBg4OD1r709HS0bt0av/32Gz799FPs378foaGhOHHiBADZxAAAT58+RVpaWp5iGj58OPbv34+wsDCkpKTgu+++Q/fu3eHh4ZHjcU+ePMmyKcvLy0vzuq7UfXtu3bql87EAEBQUhC5dumDWrFl4+vRpno6ZPXs2Hj9+rNPQ9379+mHlypW4c+cO3njjDbi5uSEwMBB79+7NV9wANE1CahYWFjnuf/78udZ+GxsbWFlZZSqb8Xj1/pePX7BgAd5//30EBgZi06ZNOHHiBE6dOoW2bdtqfqdell0TZnamT5+O5cuX45tvvtGafkDdh2706NEwNzfX2j744AMA0CSXT548yfJ3MrffUyKACRCRxsqVKyGEwK+//gpnZ2fNph7Cu2bNGk1n2tKlS+PevXs5ni8vZdRfTklJSVr7s6s9yKoD7eXLl3HhwgXMnTsXw4YNQ7NmzVCvXj2UKlVKq5yLiwtMTU1zjQkA3nrrLZQqVQpff/01Nm7ciMjISAwdOjTX40qVKoWIiIhM+x88eAAAcHV1zfUcGbVp0wYAsGXLFp2PVZs5cybi4uIwY8aMPJWvWbMmevfujQULFmh1as/NO++8g2PHjiEmJgY7duyAEAIdOnTQ1Kzoer+V9OOPP6JZs2ZYtmwZ2rdvj8DAQNStWzfbWjFdRs2tXr0akyZNwpQpUzL1zVL/jowbNw6nTp3KcqtZsyYA+fsWGRmZ6fxZ7SPKiAkQEeSw3TVr1qBixYo4cOBApu3jjz9GREQEdu3aBQAIDg7GgQMHNFXxWQkODsaNGzdybPbx8fEBAFy8eFFr/7Zt2/Icu/qLx9LSUmv/N998o/Xc2toaTZs2xcaNG3P9wrWyssLgwYOxZs0aLFiwADVr1kSjRo1yjaVly5a4evUqzp49q7V/7dq1UKlUaN68eV4uSUvt2rURHByMFStWZPtZnj59GuHh4dmew8/PDwMGDMDixYtzLPey6dOnIzk5GVOnTtU5ZltbWwQHB2PChAlITk7GlStXAGR/v7dv367zexQ2lUqV6Xfq4sWLWU4uqYvdu3fj3XffxYABAzB58uRMr1etWhWVK1fGhQsXULdu3Sw3e3t7AEDz5s2xf/9+rSQ1LS0t36P4yLhwFBgRZH+dBw8eYPbs2ZlGtwBA9erVsWTJEqxYsQIdOnTAtGnTsGvXLrz22msYP348Xn31VURHR2P37t0YNWoU/Pz8MHLkSGzYsAGdO3fG2LFjUb9+fTx79gyHDh1Chw4d0Lx5c3h4eOD111/HzJkz4ezsDG9vb+zfvx+//fZbnmP38/NDxYoVMXbsWAgh4OLigu3bt2fZ9KIeGRYYGIixY8eiUqVKePjwIbZt24ZvvvlG88UCAB988AHmzJmDM2fO4Pvvv89TLB999BHWrl2L9u3bY9q0afD29saOHTuwdOlSvP/++6hSpUqer+tla9euRdu2bREcHIwBAwYgODgYzs7OiIiIwPbt2/Hzzz/jzJkzmYbCv2zKlClYt24dDhw4AFtb21zf09fXF++//36e+w69++67sLa2RqNGjeDp6YnIyEjMnDkTjo6OqFevHgCgXbt2cHFxwcCBAzFt2jSYmZlh9erVuHv3bt4+iCLUoUMHfP7555g8eTKaNm2KsLAwTJs2Db6+vprRh7q6desW3nzzTVSoUAHvvPOOpplWrVatWrC0tMQ333yD4OBgtGnTBiEhIShTpgz+++8/XLt2DWfPntVMxTBx4kRs27YNLVq0wGeffQYbGxt8/fXXSEhIKPD1kxFQtAs2UTHRpUsXYWFhkePoqF69egkzMzPNiJO7d++KAQMGCA8PD2Fubi68vLxEjx49xMOHDzXHPH36VIwYMUKUL19emJubCzc3N9G+fXutEU0RERGie/fuwsXFRTg6Ooq+ffuK06dPZzkKLOPoJbWrV6+KVq1aCXt7e+Hs7CzefPNNER4eLgCIyZMnZyr75ptvilKlSgkLCwtRvnx5ERISIp4/f57pvM2aNRMuLi4iMTExLx+jEEKIO3fuiLfeekuUKlVKmJubi6pVq4q5c+dqRu6o5XUUmNqzZ8/EokWLRMOGDYWDg4MwMzMTXl5eolu3bmLHjh2achlHgb1s/PjxAkCOo8Be9ujRI+Hg4JCnUWBr1qwRzZs3F+7u7sLCwkLz+3Dx4kWtcqGhoSIoKEjY2tqKMmXKiMmTJ4vvv/8+y1FgWX0+AMTQoUO19mU1Ui2735fsrjXj+yUlJYnRo0eLMmXKCCsrK1G7dm2xZcsW0b9/f+Ht7Z3je2d8Tf17rL432W0vX/+FCxdEjx49hJubmzA3NxceHh6iRYsWmhGaakePHhUNGjQQlpaWwsPDQ3zyySfi22+/5SgwypVKCCGKOukiouIvKioK3t7eGDZsGObMmaN0OEREesUmMCLScu/ePfz777+YO3cuTExMMGLECKVDIiLSO3aCJiIt33//PZo1a4YrV65g3bp1WvPQEBGVFGwCIyIiIqPDGiAiIiIyOkyAiIiIyOgwASIiIiKjw1FgWUhPT8eDBw9gb2+v0/TuREREpBwhBOLi4uDl5QUTk5zreJgAZeHBgwcoV66c0mEQERFRPty9ezfXhZ+ZAGVBvRzA3bt3M628TURERMVTbGwsypUrp7WsT3aYAGVB3ezl4ODABIiIiMjA5KX7CjtBExERkdFhAkRERERGhwkQERERGR32ASqAtLQ0pKSkKB0G6YG5uTlMTU2VDoOIiIoIE6B8EEIgMjIS0dHRSodCeuTk5AQPDw/O/UREZASYAOWDOvlxc3ODjY0NvzANnBACiYmJiIqKAgB4enoqHBERERU2JkA6SktL0yQ/pUqVUjoc0hNra2sAQFRUFNzc3NgcRkRUwrETtI7UfX5sbGwUjoT0TX1P2a+LiKjkYwKUT2z2Knl4T4mIjAcTICIiIjI6TIAoX3x8fPDll1/mufzBgwehUqk4co6IiIoFdoI2Is2aNUPNmjV1Slyyc+rUKdja2ua5fFBQECIiIuDo6Fjg9yYiIiooJkCkIYRAWloazMxy/7UoXbq0Tue2sLCAh4dHfkMjIiJDJwSQlAQkJMhNpQLKlVMsHDaBGYmQkBAcOnQIX331FVQqFVQqFVavXg2VSoU9e/agbt26sLS0xJEjR3Dz5k107twZ7u7usLOzQ7169bBv3z6t82VsAlOpVPj+++/RtWtX2NjYoHLlyti2bZvm9YxNYKtXr4aTkxP27NmDatWqwc7ODm3btkVERITmmNTUVAwfPhxOTk4oVaoUxowZg/79+6NLly6F+VERERm3lBTg4UPg77+B8+eBo0eBvXuBLVuAdeuAb78FFi4EvvgCGD8eGDECGDQI6N0b6NQJeP11oGFDoEYNoGJFwMMDcHAAzMwAa2vA1RXw9gb69FH0MlkDpA9CAImJyry3jY3MonPx1Vdf4caNG6hevTqmTZsGALhy5QoA4NNPP8W8efNQoUIFODk54d69e2jXrh2mT58OKysrrFmzBh07dkRYWBjKly+f7XtMnToVc+bMwdy5c7F48WL06dMHd+7cgYuLS5blExMTMW/ePPzwww8wMTFB3759MXr0aKxbtw4AMHv2bKxbtw6rVq1CtWrV8NVXX2HLli1o3ry5rp8SEZH+PH8OPH2a+xYXJ/+PdnB4sdnbaz/P+JqtbZ7+T8+TtDQZx3//AU+e5P1nXJx+3j8nFhaAwvOtMQHSh8REwM5OmfeOj5f/YHLh6OgICwsL2NjYaJqirl+/DgCYNm0aWrVqpSlbqlQpBAQEaJ5Pnz4dmzdvxrZt2/Dhhx9m+x4hISHo3bs3AGDGjBlYvHgxQkND0bZt2yzLp6SkYPny5ahYsSIA4MMPP9QkZwCwePFijBs3Dl27dgUALFmyBDt37sz1WomMXnq6/DJ7+BB4/BiwstL+orW1BUyKUQNAaioQEwNER8ufLz9+/lzWHJiaZr/l9npOZRIS8pbMvLw9f154n4WJSdZJUlb7zM3lfc4ukSnIoBOV6kVCZmMjf7685WVfTmXy0NWisCkfASmubt26Ws8TEhIwdepU/P7773jw4AFSU1Px7NkzhIeH53ieGjVqaB7b2trC3t5es7xEVmxsbDTJDyCXoFCXj4mJwcOHD1G/fn3N66ampqhTpw7S09N1uj6iEiEtTX6pPXyovUVGZt4XFSXLZ0elkn+0ZVcLkVMNRVZfwvHx2klLVolMTq8lJBTFJ6hfJiaAkxPg7Pxiy/jcwQF49gyIjX2xxcVpP395S0+Xm/rz0RcHB6BUKcDFJe8/nZwUr6EpbEyA9MHGRv4HoNR7F1DG0VyffPIJ9uzZg3nz5qFSpUqwtrZG9+7dkZycnON5zM3NtZ6rVKock5WsygshMu17WcbXiRQhhNzS0zP/zGpfTmXS02UikDGJyZjkPHoky+rCxUX2t0hOfvElm5oq3zsuTm737xfss1Cp5Pn0wcZGfvE6Or74aWUlkzn1lpqq/TyvW3bH2dhoJy153ezt9VuLpu5KkZdESb2lpMh7nFMi4+wsk1TKhAmQPqhUeWqGUpqFhQXScvqr8P+OHDmCkJAQTdNTfHw8bt++XcjRaXN0dIS7uztCQ0PRpEkTAHIdtnPnzqFmzZpFGguVUMnJsqYkp5oU9ab+61ydtCjJ1RVwd8968/B48bh0adnP4mXqUTjZfaHm9KWb8TV1rY06+TEzy5y8qH/mZZ+6NslYqb9HbG0BLshcJJgAGREfHx+cPHkSt2/fhp2dXba1M5UqVcJvv/2Gjh07QqVSYdKkSYo0Ow0bNgwzZ85EpUqV4Ofnh8WLF+Pp06dcsoKyl5SUcy3Ky8+fPlUmRpVK1hy8/NPBIXMCk9VWunTBkgSVStaoWFkBbm4Fu460NJkUPX8u47e21l/nXaIiwATIiIwePRr9+/eHv78/nj17hlWrVmVZbuHChRgwYACCgoLg6uqKMWPGIDY2toijBcaMGYPIyEi8/fbbMDU1xeDBg9GmTRuu1G6IHj2SzTzPn8stKUm/jxMSZFKja78JMzOZCGRXi6LenJxksvJy4pIxicnqZ8Z9JSlBMDWVnwuRgVIJdqrIJDY2Fo6OjoiJiYGDg4PWa8+fP8etW7fg6+sLKysrhSI0Tunp6ahWrRp69OiBzz//XO/n573Vo6Qk4K+/gF27gN27gf9PuVAkzM1zbhp6eXN2Ll6joYioQHL6/s6INUBUbN25cwd//PEHmjZtiqSkJCxZsgS3bt3CW2+9pXRolJVbt14kPH/+qT2yRz3qSN38YmUFWFrq77m19YuaHCenklXTQkSFggkQFVsmJiZYvXo1Ro8eDSEEqlevjn379qFatWpKh0aAHN576JBMeHbtAm7c0H7d3R1o21ZurVrJUSlERMUEEyAqtsqVK4ejR48qHQapCSGnxlcnPAcPak8IZ2oKBAUBwcEy6QkIYPMSERVbTICIKHsJCcCBAy+atv79V/v1MmVeJDyvvy6HNBMRGQAmQET0ghDAtWsvEp7Dh+V8OWrm5kCTJi+SnldeYX8bIjJITICIjFl6OvDPP8C5c7Lj8u7dQMYlT3x8XiQ8LVoot+4dEZEeMQEiMhaJicClS8D588CFC/LnxYuZ12GytASaNXuR9FSpwloeIipxmAARlUSRkTLBUW8XLshRWlnN6G1lBdSoATRoIBOepk31ssYcEVFxxgSIyJClpcnEJmOy8/Bh1uXd3YGaNV9sAQFA5cpyRmQiIiPC//Uoz3x8fDBy5EiMHDkSgFypffPmzejSpUuW5W/fvg1fX98CL2Cqr/MYvLi4F01Y6u3yZTkfT0YmJrLpKmOy4+FRlBETERVbTIAo3yIiIuDs7KzXc4aEhCA6OhpbtmzR7CtXrhwiIiLg6uqq1/cyGNevAx9/LEdmZbVyja2tTG4CAl4kO9WrsxmLiCgHTIAo3zyKqDbB1NS0yN6rWImJAT7/HPjqKyA1Ve4rU0a7RqdmTaBiRU44SESkI/6vaSS++eYblClTBukZOsF26tQJ/fv3x82bN9G5c2e4u7vDzs4O9erVw759+3I8p0ql0qqpCQ0NRa1atWBlZYW6devi3LlzWuXT0tIwcOBA+Pr6wtraGlWrVsVXX32leX3KlClYs2YNtm7dCpVKBZVKhYMHD+L27dtQqVQ4f/68puyhQ4dQv359WFpawtPTE2PHjkWqOkkA0KxZMwwfPhyffvopXFxc4OHhgSlTpuj+wSkhPR1YuVI2Yc2fL5Ofjh2BsDDg3j3g99+B6dOBN9+U/XeY/BAR6Yw1QHoghBxhrAQbm7yNUH7zzTcxfPhwHDhwAC1btgQAPH36FHv27MH27dsRHx+Pdu3aYfr06bCyssKaNWvQsWNHhIWFoXz58rmePyEhAR06dECLFi3w448/4tatWxgxYoRWmfT0dJQtWxa//PILXF1dcezYMQwePBienp7o0aMHRo8ejWvXriE2NharVq0CALi4uODBgwda57l//z7atWuHkJAQrF27FtevX8e7774LKysrrSRnzZo1GDVqFE6ePInjx48jJCQEjRo1QqtWrXL/wJRy4gQwfDhw6pR8XrUq8OWXcnQWERHpDRMgPUhMVG5uuPh42QUkNy4uLmjbti1++uknTQK0ceNGuLi4oGXLljA1NUVAQICm/PTp07F582Zs27YNH374Ya7nX7duHdLS0rBy5UrY2NjglVdewb179/D+++9rypibm2Pq1Kma576+vjh27Bh++eUX9OjRA3Z2drC2tkZSUlKOTV5Lly5FuXLlsGTJEqhUKvj5+eHBgwcYM2YMPvvsM5j8v0akRo0amDx5MgCgcuXKWLJkCfbv3188E6CICGDsWGDtWvnc3h6YPBkYNgywsFA2NiKiEoh150akT58+2LRpE5KSkgDIpKVXr14wNTVFQkICPv30U/j7+8PJyQl2dna4fv06wjPOCpyNa9euISAgADYvdbxt2LBhpnLLly9H3bp1Ubp0adjZ2eG7777L83u8/F4NGzaE6qWqr0aNGiE+Ph737t3T7KtRo4bWcZ6enoiKitLpvQpdUhIwZ45s7lInPwMGyEVHP/6YyQ8RUSFhDZAe2NjImhil3juvOnbsiPT0dOzYsQP16tXDkSNHsGDBAgDAJ598gj179mDevHmoVKkSrK2t0b17dyS/vA5UDkRWo5My+OWXX/DRRx9h/vz5aNiwIezt7TF37lycPHky7xfx//dSZWj3U7//y/vNzc21yqhUqkx9oBS1YwcwcqRcigIAAgOBRYuA+vUVDYuIyBgwAdIDlSpvzVBKs7a2Rrdu3bBu3Tr8888/qFKlCurUqQMAOHLkCEJCQtC1a1cAQHx8PG7fvp3nc/v7++OHH37As2fPYG1tDQA4ceKEVpkjR44gKCgIH3zwgWbfzZs3tcpYWFggLS0t1/fatGmTViJ07Ngx2Nvbo0yZMnmOWTFhYcBHH8lh7YCcm2f2bKBvX3ZoJiIqIvzf1sj06dMHO3bswMqVK9G3b1/N/kqVKuG3337D+fPnceHCBbz11ls61Za89dZbMDExwcCBA3H16lXs3LkT8+bN0ypTqVIlnD59Gnv27MGNGzcwadIknFJ39v0/Hx8fXLx4EWFhYXj8+DFSUlIyvdcHH3yAu3fvYtiwYbh+/Tq2bt2KyZMnY9SoUZr+P8VSbCzwySfAq6/K5MfcXD4PCwPefpvJDxFREeL/uEamRYsWcHFxQVhYGN566y3N/oULF8LZ2RlBQUHo2LEj2rRpg9q1a+f5vHZ2dti+fTuuXr2KWrVqYcKECZg9e7ZWmSFDhqBbt27o2bMnAgMD8eTJE63aIAB49913UbVqVU0/oaNHj2Z6rzJlymDnzp0IDQ1FQEAAhgwZgoEDB2LixIk6fhpFJD0dWLNG9vOZNw9ISQHatZOzOM+ZAzg4KB0hEZHRUYm8dN4wMrGxsXB0dERMTAwcMnw5PX/+HLdu3YKvry+srKwUipAKQ6Hc29BQOZIrNFQ+r1wZWLgQaN9eP+cnIiKNnL6/M2INEFFhiIwE3nlHdmwODZXzJMyZI2t9mPwQESmOnaCJ9Ck5WY7kmjZNLl4KAP37AzNnAp6eysZGREQaTICI9GXXLjms/cYN+bxuXWDxYqBBA0XDIiKizNgERlRQSUnAu+/Kjs03bgBubnItr5MnmfwQERVTrAHKJ/YdL3nydU8jI4Fu3YDjx+Uw9hEj5BIWjo76D5CIiPSGCZCO1LMLJyYmaib8o5Ih8f8r2macQTpbp04BXbsC9+/LhGf9ei5aSkRkIJgA6cjU1BROTk6aNaVsbGwyLctAhkUIgcTERERFRcHJyQmmpqa5H/Tjj8CgQbL5y88P2LpVzvNDREQGgQlQPqhXKi92C2tSgTg5OeW4Cj0AIC1NrtqunuW6Qwdg3TpOZkhEZGCYAOWDSqWCp6cn3NzcslyqgQyPubl57jU/T58CvXoBf/whn0+YIIe7cwkLIiKDwwSoAExNTfPWXEKG79o1oFMnuXK7jQ2wahXQo4fSURERUT4xASLKzfbtQJ8+cmJDb29gyxagZk2loyIiogJg3T1RdoQAZswAOneWyU/TpnLkF5MfIiKDxxogoqwkJMi1vDZulM8/+AD48ksgr0PkiYioWGMCRJTR7dtAly7AhQsy4VmyBBg8WOmoiIhIj5gAEb3s0CGge3fg8WO5pMWmTUDjxkpHRUREesY+QESA7O+zdCnw+usy+aldGzh9mskPEVEJxQSIKDkZeO89YOhQIDUVeOst4MgRoFw5pSMjIqJCwiYwMm4PHwJvvAEcPQqoVMDs2cDo0fIxERGVWEyAyHidPi0XM713Ty5m+vPPQHCw0lEREVERULwJbOnSpfD19YWVlRXq1KmDI0eO5Fj+66+/RrVq1WBtbY2qVati7dq1Wq+vXr0aKpUq0/b8+fPCvAwyNOvWAU2ayOSnalUgNJTJDxGREVG0BmjDhg0YOXIkli5dikaNGuGbb75BcHAwrl69ivLly2cqv2zZMowbNw7fffcd6tWrh9DQULz77rtwdnZGx44dNeUcHBwQFhamdayVlVWhXw8ZgLQ0YNw4YO5c+bxdO+Cnn2QNEBERGQ2VEEIo9eaBgYGoXbs2li1bptlXrVo1dOnSBTNnzsxUPigoCI0aNcJc9ZcXgJEjR+L06dP466+/AMgaoJEjRyI6OjrfccXGxsLR0RExMTFw4CrfJcfTp7KD8+7d8vm4ccDnnwNcz42IqETQ5ftbsSaw5ORknDlzBq1bt9ba37p1axw7dizLY5KSkjLV5FhbWyM0NFRrVfb4+Hh4e3ujbNmy6NChA86dO5djLElJSYiNjdXaqIR58ABo0EAmP9bWsr/PjBlMfoiIjJRiCdDjx4+RlpYGd3d3rf3u7u6IjIzM8pg2bdrg+++/x5kzZyCEwOnTp7Fy5UqkpKTg8ePHAAA/Pz+sXr0a27Ztw88//wwrKys0atQIf//9d7axzJw5E46OjpqtHIc/lyzPnsmZnW/ckEPb//oL6NVL6aiIiEhBineCVmUYbiyEyLRPbdKkSQgODkaDBg1gbm6Ozp07IyQkBABg+v+/5Bs0aIC+ffsiICAATZo0wS+//IIqVapg8eLF2cYwbtw4xMTEaLa7d+/q5+JIeULIZSxOnQJcXIADB+Qkh0REZNQUS4BcXV1hamqaqbYnKioqU62QmrW1NVauXInExETcvn0b4eHh8PHxgb29PVxdXbM8xsTEBPXq1cuxBsjS0hIODg5aG5UQ8+cDP/4om7o2bgQqVlQ6IiIiKgYUS4AsLCxQp04d7N27V2v/3r17ERQUlOOx5ubmKFu2LExNTbF+/Xp06NABJiZZX4oQAufPn4enp6feYicDsWsX8Omn8vHChUCLFsrGQ0RExYaiw+BHjRqFfv36oW7dumjYsCG+/fZbhIeHY8iQIQBk09T9+/c1c/3cuHEDoaGhCAwMxNOnT7FgwQJcvnwZa9as0Zxz6tSpaNCgASpXrozY2FgsWrQI58+fx9dff63INZJCwsKA3r1lE9igQcCHHyodERERFSOKJkA9e/bEkydPMG3aNERERKB69erYuXMnvL29AQAREREIDw/XlE9LS8P8+fMRFhYGc3NzNG/eHMeOHYOPj4+mTHR0NAYPHozIyEg4OjqiVq1aOHz4MOrXr1/Ul0dKiY4GOnUCYmKARo2Ar7/m0hZERKRF0XmAiivOA2TA0tKADh3kcPdy5WTn52z6lBERUcliEPMAERWKsWNfzPWzdSuTHyIiyhITICo51q4F5s2Tj1evBmrVUjQcIiIqvpgAUckQGirn+wGACROAHj2UjYeIiIo1JkBk+B48kDM9JyXJzs/TpikdERERFXNMgMiwPX8OdO0KREQAr7wC/PADkM2cUERERGr8piDDpV7mIjRULnOxdSvAUXtERJQHTIDIcM2fL2t8TE2BX37hMhdERJRnTIDIMO3eDYwZIx8vXAi0bKlsPEREZFCYAJHhCQsDevUC0tOBgQO5zAUREemMCRAZFi5zQUREesAEiAxHWppc4PTGDbnMxaZNgKWl0lEREZEBYgJEhuPlZS62bOEyF0RElG9MgMgw/PDDi2UuVq0CatdWNh4iIjJoTICo+AsNBd59Vz4ePx7o2VPZeIiIyOAxAaLi7eVlLjp2BD7/XOmIiIioBGACRMXXy8tc+PsDP/7IZS6IiEgv+G1CxdPLy1w4OwPbtnGZCyIi0hsmQFQ8LVjwYpmLjRu5zAUREekVEyAqfnbvBj79VD5esIDLXBARkd4xAaLiJeMyF8OGKR0RERGVQEyAqPiIjgY6d5bLXAQFcZkLIiIqNEyAqHgQAujbV9YAlS0L/PYbl7kgIqJCwwSIioddu4AdO2TSs3Url7kgIqJCxQSIlJeeDkyYIB8PH85lLoiIqNAxASLl/forcP48YG8PjBmjdDRERGQEmACRslJTgc8+k49HjwZKlVI2HiIiMgpMgEhZP/wgOz6XKgWMHKl0NEREZCSYAJFykpKAKVPk43HjuNQFEREVGSZApJxvvwXCwwEvL+CDD5SOhoiIjAgTIFJGQgLwxRfy8aRJgLW1svEQEZFRYQJEyli8GHj4EKhQARgwQOloiIjIyDABoqIXHQ3Mni0fT50KWFgoGg4RERkfJkBU9ObPl0mQvz/Qu7fS0RARkRFiAkRFKyoKWLhQPp4+HTA1VTYeIiIySkyAqGjNnCk7QNetC3TponQ0RERkpJgAUdG5exdYtkw+/uILQKVSNh4iIjJaTICo6Hz+uZz8sGlToFUrpaMhIiIjxgSIisbffwMrV8rHrP0hIiKFMQGiojF5MpCWBrRvDzRqpHQ0RERk5JgAUeG7eBFYv14+nj5d2ViIiIjABIiKwqRJgBBAjx5AzZpKR0NERMQEiArZiRPAtm2AiQkwbZrS0RAREQFgAkSFbeJE+bN/f6BqVWVjISIi+j8mQFR49u+Xm7m57ARNRERUTDABosIhBDBhgnw8ZAjg7a1sPERERC9hAkSF4/ffgZMnAWtrYPx4paMhIiLSwgSI9C89/UXtz4gRgIeHsvEQERFlwASI9G/DBuDSJcDREfjkE6WjISIiyoQJEOlXSgrw2Wfy8ejRgIuLsvEQERFlgQkQ6deaNcA//wClS8vmLyIiomKICRDpz/PnwNSp8vH48YC9vbLxEBERZYMJEOnP8uXAvXtA2bJy6DsREVExxQSI9CM+HpgxQz7+7DPAykrZeIiIiHLABIj046uvgEePgEqVgJAQpaMhIiLKERMgKrinT4G5c+XjadPk0hdERETFGBMgKri5c4GYGODVV4GePZWOhoiIKFdMgKhgIiNl8xcATJ8OmPBXioiIij9+W1HBzJgBJCYCgYFAx45KR0NERJQnTIAo/+7ckUPfAeCLLwCVStl4iIiI8ogJEOXftGly6YsWLYCWLZWOhoiIKM+YAFH+hIUBq1fLx198oWgoREREumICRPnz2WdAerrs99OggdLREBER6YQJEOnu/Hngl1/k4+nTFQ2FiIgoP5gAke4mTpQ/e/cGatRQNhYiIqJ8YAJEujl2DNixAzA1fbHyOxERkYFhAkR5JwQwfrx8/M47QOXKysZDRESUT0yAKO/27QMOHQIsLGQnaCIiIgPFBIjybtYs+fP994Fy5ZSNhYiIqACYAFHePHkCHDwoH48YoWgoREREBcUEiPLm99/lvD8BAYCvr9LREBERFYjiCdDSpUvh6+sLKysr1KlTB0eOHMmx/Ndff41q1arB2toaVatWxdq1azOV2bRpE/z9/WFpaQl/f39s3ry5sMI3Hlu2yJ9duigZBRERkV4omgBt2LABI0eOxIQJE3Du3Dk0adIEwcHBCA8Pz7L8smXLMG7cOEyZMgVXrlzB1KlTMXToUGzfvl1T5vjx4+jZsyf69euHCxcuoF+/fujRowdOnjxZVJdV8iQmAnv2yMedOysbCxERkR6ohBBCqTcPDAxE7dq1sWzZMs2+atWqoUuXLpg5c2am8kFBQWjUqBHmzp2r2Tdy5EicPn0af/31FwCgZ8+eiI2Nxa5duzRl2rZtC2dnZ/z88895iis2NhaOjo6IiYmBg4NDfi+v5Ni2TSY+5csDt29z1XciIiqWdPn+VqwGKDk5GWfOnEHr1q219rdu3RrHjh3L8pikpCRYWVlp7bO2tkZoaChSUlIAyBqgjOds06ZNtuekPHi5+YvJDxERlQCKJUCPHz9GWloa3N3dtfa7u7sjMjIyy2PatGmD77//HmfOnIEQAqdPn8bKlSuRkpKCx48fAwAiIyN1OicgE6vY2Fitjf4vLQ1QNzGy/w8REZUQineCVmWoURBCZNqnNmnSJAQHB6NBgwYwNzdH586dERISAgAwNTXN1zkBYObMmXB0dNRs5TjHzQvHjgGPHwPOzkCTJkpHQ0REpBeKJUCurq4wNTXNVDMTFRWVqQZHzdraGitXrkRiYiJu376N8PBw+Pj4wN7eHq6urgAADw8Pnc4JAOPGjUNMTIxmu3v3bgGvrgRRN3916ACYmSkaChERkb4olgBZWFigTp062Lt3r9b+vXv3IigoKMdjzc3NUbZsWZiammL9+vXo0KEDTEzkpTRs2DDTOf/4448cz2lpaQkHBwetjSDX/uLwdyIiKoEU/ZN+1KhR6NevH+rWrYuGDRvi22+/RXh4OIYMGQJA1szcv39fM9fPjRs3EBoaisDAQDx9+hQLFizA5cuXsWbNGs05R4wYgddeew2zZ89G586dsXXrVuzbt08zSox0cPky8O+/gJUV0KaN0tEQERHpjaIJUM+ePfHkyRNMmzYNERERqF69Onbu3Alvb28AQEREhNacQGlpaZg/fz7CwsJgbm6O5s2b49ixY/Dx8dGUCQoKwvr16zFx4kRMmjQJFStWxIYNGxAYGFjUl2f4tm6VP19/HbC1VTYWIiIiPdJ5HiAfHx8MGDAAISEhKF++fGHFpSjOA/R/desCZ84A338PDByodDREREQ5KtR5gD7++GNs3boVFSpUQKtWrbB+/XokJSXlO1gqpu7elcmPSgV07Kh0NERERHqlcwI0bNgwnDlzBmfOnIG/vz+GDx8OT09PfPjhhzh79mxhxEhKUDd/NWoEuLkpGwsREZGe5XsUWEBAAL766ivcv38fkydPxvfff4969eohICAAK1euhIIrbJA+qBMgrv1FREQlUL47QaekpGDz5s1YtWoV9u7diwYNGmDgwIF48OABJkyYgH379uGnn37SZ6xUVJ4+BQ4elI+ZABERUQmkcwJ09uxZrFq1Cj///DNMTU3Rr18/LFy4EH5+fpoyrVu3xmuvvabXQKkI7dwJpKYCr7wCVK6sdDRERER6p3MCVK9ePbRq1QrLli1Dly5dYG5unqmMv78/evXqpZcASQGc/JCIiEo4nYfB37lzRzNPT0ll1MPgnz8HSpcG4uOB0FCgXj2lIyIiIsqTQh0GHxUVhZMnT2baf/LkSZw+fVrX01Fx8+efMvkpUwaoU0fpaIiIiAqFzgnQ0KFDs1ws9P79+xg6dKhegiIFqZu/OncGTBRbKo6IiKhQ6fwNd/XqVdSuXTvT/lq1auHq1at6CYoUkp4ObNsmH7P/DxERlWA6J0CWlpZ4+PBhpv0REREwM1N0aTEqqJMngYcPAQcHoGlTpaMhIiIqNDonQK1atcK4ceMQExOj2RcdHY3x48ejVatWeg2Oipi6+at9e8DCQtFQiIiICpPOVTbz58/Ha6+9Bm9vb9SqVQsAcP78ebi7u+OHH37Qe4BURIQANm+Wj9n8RUREJZzOw+ABICEhAevWrcOFCxdgbW2NGjVqoHfv3lnOCWSIjHIY/LVrgL+/rPl59Eg2gxERERkQXb6/89Vpx9bWFoMHD85XcFRMqdf+atGCyQ8REZV4+e61fPXqVYSHhyM5OVlrf6dOnQocFCmAsz8TEZER0TkB+vfff9G1a1dcunQJKpVKs+q7SqUCAKSlpek3Qip8Dx7IEWAAwASWiIiMgM6jwEaMGAFfX188fPgQNjY2uHLlCg4fPoy6devioHoFcTIs6rl/GjQAPD2VjYWIiKgI6FwDdPz4cfz5558oXbo0TExMYGJigsaNG2PmzJkYPnw4zp07VxhxUmFS9//p3FnZOIiIiIqIzjVAaWlpsLOzAwC4urriwYMHAABvb2+EhYXpNzoqfLGxwP798jH7/xARkZHQuQaoevXquHjxIipUqIDAwEDMmTMHFhYW+Pbbb1GhQoXCiJEK065dQEoKULUq4OendDRERERFQucEaOLEiUhISAAATJ8+HR06dECTJk1QqlQpbNiwQe8BUiHj6C8iIjJC+ZoIMaP//vsPzs7OmpFghs5oJkJMTgZKl5bNYMeOAQ0bKh0RERFRvuny/a1TH6DU1FSYmZnh8uXLWvtdXFxKTPJjVA4elMmPuzsQGKh0NEREREVGpwTIzMwM3t7enOunpFA3f3XuDJjo3B+eiIjIYOn8rTdx4kSMGzcO//33X2HEQ0UlPf3F8Hf2/yEiIiOjcyfoRYsW4Z9//oGXlxe8vb1ha2ur9frZs2f1FhwVojNn5AzQdnZy/S8iIiIjonMC1IW1BSWDuvkrOBiwtFQ0FCIioqKmcwI0efLkwoiDihqHvxMRkRFjz1dj9PffwNWrgJkZ0K6d0tEQEREVOZ1rgExMTHIc8s4RYgZA3fm5WTPAyUnJSIiIiBShcwK0efNmrecpKSk4d+4c1qxZg6lTp+otMCpEbP4iIiIjp5eZoAHgp59+woYNG7BVXbtgwEr0TNAPHwKenoAQQHg4UK6c0hERERHpRaHNBJ2TwMBA7Nu3T1+no8KyfbtMfurWZfJDRERGSy8J0LNnz7B48WKULVtWH6ejwqSuoevcWdk4iIiIFKRzH6CMi54KIRAXFwcbGxv8+OOPeg2O9Cw+Hti7Vz5m/x8iIjJiOidACxcu1EqATExMULp0aQQGBsLZ2VmvwZGe7dkDJCUBFSsCr7yidDRERESK0TkBCgkJKYQwqEi8PPorh6kMiIiISjqd+wCtWrUKGzduzLR/48aNWLNmjV6CokKQkgLs2CEfs/8PEREZOZ0ToFmzZsHV1TXTfjc3N8yYMUMvQVEhOHIEePoUcHUFgoKUjoaIiEhROidAd+7cga+vb6b93t7eCA8P10tQVAjUzV+dOgGmpoqGQkREpDSdEyA3NzdcvHgx0/4LFy6gVKlSegmK9EwIzv5MRET0Ep0ToF69emH48OE4cOAA0tLSkJaWhj///BMjRoxAr169CiNGKqjz54G7dwEbG+D115WOhoiISHE6jwKbPn067ty5g5YtW8LMTB6enp6Ot99+m32Aiit17U+bNoC1taKhEBERFQc6J0AWFhbYsGEDpk+fjvPnz8Pa2hqvvvoqvL29CyM+0gc2fxEREWnROQFSq1y5MipXrqzPWKgw3LoFXLwoOz63b690NERERMWCzn2AunfvjlmzZmXaP3fuXLz55pt6CYr0SL32V5MmADupExERAchHAnTo0CG0z6ImoW3btjh8+LBegiI9YvMXERFRJjonQPHx8bCwsMi039zcHLGxsXoJivTk8WM5ASLA2Z+JiIheonMCVL16dWzYsCHT/vXr18Pf318vQZGe/P47kJ4O1KwJ+PgoHQ0REVGxoXMn6EmTJuGNN97AzZs30aJFCwDA/v378dNPP+HXX3/Ve4BUAOr+P6z9ISIi0qJzAtSpUyds2bIFM2bMwK+//gpra2sEBATgzz//hIODQ2HESPmRmAjs2SMfs/8PERGRFpUQQhTkBNHR0Vi3bh1WrFiBCxcuIC0tTV+xKSY2NhaOjo6IiYkx3KRu61aZ+Hh7y6HwKpXSERERERUqXb6/de4DpPbnn3+ib9++8PLywpIlS9CuXTucPn06v6cjfXt59BeTHyIiIi06NYHdu3cPq1evxsqVK5GQkIAePXogJSUFmzZtYgfo4iQ1Fdi+XT5m/x8iIqJM8lwD1K5dO/j7++Pq1atYvHgxHjx4gMWLFxdmbJRfx44BT54Azs5yAkQiIiLSkucaoD/++APDhw/H+++/zyUwijt181fHjoBZvlc7ISIiKrHyXAN05MgRxMXFoW7duggMDMSSJUvw6NGjwoyN8kMIzv5MRESUizwnQA0bNsR3332HiIgIvPfee1i/fj3KlCmD9PR07N27F3FxcYUZJ+XV5cty1JeVFdC6tdLREBERFUs6jwKzsbHBgAED8Ndff+HSpUv4+OOPMWvWLLi5uaFTp06FESPpQl3706oVYGuraChERETFVb6HwQNA1apVMWfOHNy7dw8///yzvmKigmDzFxERUa4KPBFiSWSwEyGGh8uJD01MgMhIoHRppSMiIiIqMkUyESIVQ7//Ln8GBTH5ISIiygEToJJEPRP3/xepJSIioqwxASpJLl6UPwMClI2DiIiomGMCVFKkpQFXrsjHr76qbCxERETFHBOgkuKff4DnzwEbG6BCBaWjISIiKtaYAJUU6uav6tUBU1NlYyEiIirmmACVFJcuyZ9s/iIiIsoVE6CSQl0DVKOGsnEQEREZACZAJQUTICIiojxTPAFaunQpfH19YWVlhTp16uDIkSM5ll+3bh0CAgJgY2MDT09PvPPOO3jy5Inm9dWrV0OlUmXanj9/XtiXopy4OLkAKsAmMCIiojxQNAHasGEDRo4ciQkTJuDcuXNo0qQJgoODER4enmX5v/76C2+//TYGDhyIK1euYOPGjTh16hQGDRqkVc7BwQERERFam5WVVVFckjIuX5Y/vbyAUqWUjYWIiMgAKJoALViwAAMHDsSgQYNQrVo1fPnllyhXrhyWLVuWZfkTJ07Ax8cHw4cPh6+vLxo3boz33nsPp9UzIP+fSqWCh4eH1laisfmLiIhIJ4olQMnJyThz5gxat26ttb9169Y4duxYlscEBQXh3r172LlzJ4QQePjwIX799Ve0b99eq1x8fDy8vb1RtmxZdOjQAefOncsxlqSkJMTGxmptBoUjwIiIiHSiWAL0+PFjpKWlwd3dXWu/u7s7IiMjszwmKCgI69atQ8+ePWFhYQEPDw84OTlh8eLFmjJ+fn5YvXo1tm3bhp9//hlWVlZo1KgR/v7772xjmTlzJhwdHTVbuXLl9HORRYU1QERERDpRvBO0SqXSei6EyLRP7erVqxg+fDg+++wznDlzBrt378atW7cwZMgQTZkGDRqgb9++CAgIQJMmTfDLL7+gSpUqWklSRuPGjUNMTIxmu3v3rn4urigIwQSIiIhIR2ZKvbGrqytMTU0z1fZERUVlqhVSmzlzJho1aoRPPvkEAFCjRg3Y2tqiSZMmmD59Ojw9PTMdY2Jignr16uVYA2RpaQlLS8sCXI2C7t0DYmIAMzPAz0/paIiIiAyCYjVAFhYWqFOnDvbu3au1f+/evQgKCsrymMTERJiYaIds+v9lH4QQWR4jhMD58+ezTI5KBHXtj58fYGGhbCxEREQGQrEaIAAYNWoU+vXrh7p166Jhw4b49ttvER4ermnSGjduHO7fv4+1a9cCADp27Ih3330Xy5YtQ5s2bRAREYGRI0eifv368PLyAgBMnToVDRo0QOXKlREbG4tFixbh/Pnz+PrrrxW7zkLF5i8iIiKdKZoA9ezZE0+ePMG0adMQERGB6tWrY+fOnfD29gYAREREaM0JFBISgri4OCxZsgQff/wxnJyc0KJFC8yePVtTJjo6GoMHD0ZkZCQcHR1Rq1YtHD58GPXr1y/y6ysSHAFGRESkM5XIru3IiMXGxsLR0RExMTFwcHBQOpycVa8OXLkC7NgBtGundDRERESK0eX7W/FRYFQASUnA9evyMZvAiIiI8owJkCG7fh1ISwOcnIAyZZSOhoiIyGAwATJkL3eAzmbuJCIiIsqMCZAh4wgwIiKifGECZMg4AoyIiChfmAAZMtYAERER5QsTIEP1+DEQESEfV6+ubCxEREQGhgmQoVI3f1WoANjZKRsLERGRgWECZKjY/EVERJRvTIAMFRMgIiKifGMCZKg4AoyIiCjfmAAZorQ04PJl+Zg1QERERDpjAmSIbt4Enj0DrK2BihWVjoaIiMjgMAEyROrmr1deAUxNlY2FiIjIADEBMkTsAE1ERFQgTIAMERMgIiKiAmECZIg4AoyIiKhAmAAZmvh42QkaYAJERESUT0yADI16+LunJ1C6tLKxEBERGSgmQIaGzV9EREQFxgTI0LADNBERUYExATI0TICIiIgKjAmQIRGCTWBERER6wATIkNy/Dzx9Kmd/rlZN6WiIiIgMFhMgQ6Ju/vLzAywtlY2FiIjIgDEBMiRs/iIiItILM6UDIB3ooQO0EEBiIhAXJ+dUjI/XfpzxecbHtrbAJ58ADRro6ZqIiIgUwATIkOSSAP37L/Dll8DDh9knNgkJMgkqiN9+A/r2BWbNAsqUKdi5iIiIlMAEyFAkJwPXr8vHWTSB7d4N9O4NREfn7XQqFWBn92Kzt8/b44MHgdWrgR9/lInQ+PHAqFGAtbW+LpSIiKjwqYQoaH1AyRMbGwtHR0fExMTAwcFB6XCkixeBgADA0VGOBFOpAMjanJkzgYkT5eP69YE+fXJPaKytAZN89gA7fRoYMQI4dkw+9/EB5s0DunXThEVERFTkdPn+Zg2QoXi5+ev/WUZcHBASImtiAODdd4HFiwt/gFjdusBffwHr1wOffgrcvg107w40ayab4AICCvf98+vePZn0eXjkP/kjIqKSgQmQocgwAiwsDOjaFbh2DTA3B5YsAQYPLrpwVCrZ5NapEzBnjtwOHgRq15ZxfP454OpadPFkJy4O2LABWLECOHFC7rOwAMqVA7y9X2zly794XK6cLENERCUXm8CyUCybwIKDZUef5cux3es99O0LxMYCXl7Ar78CDRsqG96dO7I26Jdf5HMnJ2DKFOCDD2SCVpSEAI4elUnPL7/IUW/Ai1qf9PScj1epAE/PzInRy5u9feFeAxER6U6X728mQFkolglQmTJIfxCBaQPuYOrKcgCAxo2BjRtlk05xcfiw7B90/rx87ucnm8XatCn8946MBNasAVauBG7ceLG/alVg4ECgXz9ZK3X/vkzY7twBwsNfPFZvz5/n/l7OzpmTo4oVgbZtASurwrtGIiLKHhOgAip2CdCTJ4hxrYC++BG/oyMA4MMPgfnzi2dTTVqaTELGjwceP5b7OnSQ8Vapot/3SkkBdu6U77djh3xvQM5X1LOnTHwaNsx752whgEePsk6M1AnTf/9lf3yVKsDy5UDz5gW/NiIi0g0ToAIqbgnQ1dWh6PKOE/5GFVhaAt98A/Tvr3RUuYuOln2BFi0CUlNlU9iIEXLEmqNjwc59/bpMetaulfMeqQUFAQMGAD16FF4zVVxc1gnSgQMvYgkJAebOLR79oIiIjAUToAIqTgnQpk1ASJ9kxCdZoLx1FH474oY6dRQNSWdhYXKuoJ075XM3N2DGDJkkmJrm/Tzx8bJPz8qVso+Pmpsb8PbbMvFRco3Y6GhZ67V8uaxJKlVK1nq9/TanByAiKgq6fH9zMHAxlZYmv0y7dwfikyzQHH/i9JAVBpf8ALIPzo4dcqtaFYiKAgYNknMW/fVXzscKIecbGjRIdkweOFAmPyYmsllt82Y5vH3uXGWTH0B2/F66VMb36qvAkycyyWvZUrtPEhERKY8JUDH0339A+/ZygkMA+NhjHf5Aa5RuWEnZwAqoXTs5ndGCBbIJ7OxZoEkToFcv2aT0socPZVLj7w80aiRHdMXHA5Ury8/l7l1g+3agS5eiH2WWm4YNgTNn5FIh1tayaaxGDdkcmJSkdHRERASwCSxLSjaBXbgg5/e5dUt+ea74Lh29B9vLsdzXr8sqlBIgKgqYNAn47jtZy2NtLYfR164NrFoF/P677DcEADY2wJtvyiauJk0Mqznp33/lVAB79sjnfn6yD9drrykbFxFRScQ+QAWkVAL000+yqefZM8DXVzbvBNj+I6s9rKxkFYgunWYMwPnzsmP04cOZXwsMlElPr15AMeiLnm9CyMkYR4580Ul64EA5eaSLi6KhERGVKOwDZGBSU4GPP5ZreD17BrRuLdfbCgjAiyUwXnmlxCU/AFCzppxB+pdf5BByd3fgo4/kxNcnTshZpQ05+QFkjVWvXnLW7vfek/tWrJC1QT/+KBMkIiIqWkyAFPbokUx4FiyQz8eNk6OlNDUDL68BVkKpVLKJKyxMTma4YAFQvbrSUemfs7McIfbXXzKfffRITs7YujXwzz9KR0dEZFyYACnozBmgTh3ZSdbWVi5pMWNGhoqeDGuAkeFr1Eh2AJ8xQ7Zs7tsnE74vvgCSk5WOjojIODABUsjq1fKL8O5d2cXn5EngjTeyKGgENUDGyMJC1vZdvgy0aiVHh02cCNSqlfvUAEREVHBMgIpYcrJcxuKdd+SXXocOQGiobBLJJCEBuHlTPmYCVCJVrChHiK1bB5QuDVy9Kke6DR4MPH2qdHQFk5wspzcIDQV27ZIj/4iIiguOAstCYY0Ci4yUfV3Uf+FPngx89tmLVcozCQ2VQ6Hc3eXBVKL99x8wZgzw/ffyuZubXEi2V6/iM/RfCLkUSESE/JWMiMj8WP38yRPtYy0sgN695ai/WrWUiZ+ISjZdvr/NiigmAnDkiEx+HByAH34AOnXK5QA2fxkVFxc5L9Lbb8vRYteuAW+9JVe4X7oUqFChcN5XCDkS8b//8pbYJCbm/dxmZoCHh+zr9M8/8lrWrJG1XCNGAJ07yzJEREWN//UUoTfflGtDtW+fx/kMmQAZpSZN5PxIc+YA06fLJrJXXpETKjo6yqall7ekpMz7cnst435d2dvLpUk8PWWCk/Gx+qeLy4sazhMngK++kp39jxyRW/nyskl40CA5So6IqKiwCSwLxWYx1ObN5SQ5q1cbxvLvpHd//w0MGQL8+Wfhv5dKJZvdskpkMu6ztc3/+9y/L2u0vvnmRTOZjY2s+Ro+XPk13YjIcHEm6AIqFgmQEICrq2yXOHuWnSaMmHom6X37ZHORhQVgaSl/Ztyy2p/XfXZ2Rdsc9eyZnP38q69ezPYAyHmRRowA2rbNoX8cEVEWmAAVULFIgO7fB8qWlZMCxcfLThREJZAQsqLzq6+AbdtezIxdpQowbJis/LS3VzREIjIQXAqjJFD/SVylCpMfKtFUKtnau2WL7Cj90UdyoMCNGzIBKlsWGDVKLixLRKQvTICKK3aAJiNUoYJcCuX+fWDJEpn/x8YCCxcClSoBXbrImdNZb01EBcUEqLhiAkRGzM4OGDpUTgWwcyfQpo1MerZuBVq0kIvorlgh+xEREeUHE6DiimuAEcHEBAgOBnbvlrNkv/++HDF28aIcOl+uHDBhgqwxIiLSBTtBZ0HxTtDJyfJP4JQU4PZtwNu76GMgKqaePpW1P0uWAHfuvNjv7Jz1sP2Mjx0di8/M2kSkXxwFVkCKJ0CXLsmmLwcHIDqa/1sTZSE1VY4a++or4PDhvB9nZZX1PEcZn5cunfO0AOnpcrm++Hi5PEh8fP4ex8fLiVHfeUfOjG1pWfDPhshYcSkMQ/dy8xeTH6IsmZkB3brJLToaePAg56U8IiNluefPZcXq7ds5n9/ERCZBnp6yQjZj8pKQoL9ruXVLNvO5uAB9+wIDB7L7H1FhYwJUHLEDNJFOnJzk5u+fc7lnz2QilFOSFBEBPHwoa3gePpRbTkxM5DxFdnZy0/WxlZVc7mTVKtmXadEiudWpIxOh3r3ltRGRfrEJLAuKN4G1awfs2gUsWybXQSCiIpWWBjx+/CIpSkjIPomxstJPRW1aGvDHH8DKlXK0W0qK3G9lBbzxhkyGmjbl7NhEOWEfoAJSPAEqVw64d08uHd+oUdG/PxEp6tEjYN062dn78uUX+ytUAAYMkLNjly2rXHxKS0/X7kOV3z5YCQlA9eqy2bFjR8DaWukro4JiAlRAiiZA//0HlColH0dHyyErRGSUhABOnZKJ0M8/yy9uQNYCtWkjk6FOneRabsWVEEBiYsGTlZcfJybqP04HB6B7d5kMsaat8B06JBP6cuX0e14mQAWkaAJ06BDQrBng4yN7RhIRQX7p//qrbCI7dOjFfldXoF8/mQxVr164MTx/Dty9K6cfUG8RES8Sk+wSl8L6lnm5/1VWzZO59cGysJD9r378UXtKhbJlgT595Of6yiuFE7uxSkoCJk4E5s+XS+Ds3avfZJMJUAEpmgAtWSIXQOrYUY7xJSLK4J9/ZCK0erVMQNTq15d9hXr1kjUauoqOlolAeLh2kqPecusQnht1AqJLZ3FbW/mzMPtfpacDR48CP/wA/PILEBPz4rWaNWUi1Lu3HBFI+XfpkqxhU4/zGTQIWLxYv8tdMgEqIEUToMGDge++k9PbTp9etO9NRAYlNVXWYKxYAWzfLp8Dsi/Lm2/KZKhJE5kkqEe1vZzQZEx0YmNzf08bGzk3q3orU0a21OeWzNjYGEaz0vPnwI4dslZox44XndFNTIDXX5df4F27ymuivElPB778Ehg3Ts7zW7o08P33svlW35gAFZCiCVCDBsDJk8CGDUCPHkX73kRksKKiZA3GihVyDTU1Hx85Z1J4uPzyyY2rK1C+vHaSo97Kl5ddFI1lerInT4CNG+XneuzYi/02NjIJ6tcPaNky5wkzjd3du7LT/oED8nmHDjL5cXcvnPdjAlRAiiVA6emy3johQS58VK1a0b03EZUIQsi/oVasANavl31w1ExMZI1NxqTm5ce2tsrFXpzdvClH5v3wg2yCVPPwkM1jffsCtWoZT3KYFz/9BHzwgWxStLEBFi4E3n23cD8jJkAFpFgCdPMmUKmSnAs/Pp5/VhBRgSQkAAcPyqYob2/AywswN1c6KsMmBBAaKpvI1q+X80Wp+fvLRKhPH5lMGqunT2Xis369fB4YKBPHypUL/72ZABWQYgnQ5s1yXv/atYEzZ4rufYmISGcpKbIP1g8/yMkrk5JevNa0qWwi69XLuGrV9u8HQkLkVHampsCkSbJLa1H9Pa/L97fiXdKWLl0KX19fWFlZoU6dOjhy5EiO5detW4eAgADY2NjA09MT77zzDp48eaJVZtOmTfD394elpSX8/f2xefPmwrwE/Xl5DTAiIirWzM1ln5YNG2QH8xUr5CwmgJyqYNAgOc/NxIkFH0FX3D1/DowaJTuK37sna3uOHgUmTy6+jRmKJkAbNmzAyJEjMWHCBJw7dw5NmjRBcHAwwsPDsyz/119/4e2338bAgQNx5coVbNy4EadOncKgQYM0ZY4fP46ePXuiX79+uHDhAvr164cePXrg5MmTRXVZ+cc1wIiIDJKjo5yL6cABOaJu5kzZo+HpU+CLL2QT5ODBQFiY0pHq34ULQN26so8PIFdwOndONn0Va0JB9evXF0OGDNHa5+fnJ8aOHZtl+blz54oKFSpo7Vu0aJEoW7as5nmPHj1E27Zttcq0adNG9OrVK89xxcTECAAiJiYmz8foReXKQgBC7N1btO9LRER6l5oqxKZNQgQGyv/aASFUKiG6dBHi6FGloyu41FQhZs8WwtxcXpubmxC//65sTLp8fytWA5ScnIwzZ86gdevWWvtbt26NYy+PN3xJUFAQ7t27h507d0IIgYcPH+LXX39F+/btNWWOHz+e6Zxt2rTJ9pzFRmLii6EFbAIjIjJ4pqayW+fx48Dhw3J+WyGALVvkMo+NGsnH6elKR6q7O3eAFi2AMWNkX6jOneW6dS99HRd7iiVAjx8/RlpaGtwzTAbg7u6OyMjILI8JCgrCunXr0LNnT1hYWMDDwwNOTk5YvHixpkxkZKRO5wSApKQkxMbGam1F7soV+S/Dza3wJkggIqIip1LJCSm3bZMznAwcKJfhOHZMzidUrRrw7beyH01xJwSwdq3sqXH4sOzg/f33cgxP6dJKR6cbxTtBqzJMCCCEyLRP7erVqxg+fDg+++wznDlzBrt378atW7cwZMiQfJ8TAGbOnAlHR0fNVk7fq7PlBfv/EBGVeNWqyYTh9m05M7KTE3DjBvDee7Kf0PTpck3s4ujJEzk/b//+ctbwoCDZ/2fgQMOc/0ixBMjV1RWmpqaZamaioqIy1eCozZw5E40aNcInn3yCGjVqoE2bNli6dClWrlyJiP8viOPh4aHTOQFg3LhxiImJ0Wx3794t4NXlA0eAEREZDU9PYMYMOUP3woVy3qCoKDlsvHx5YMQImSQVF3/8Ib+efv1VjuqaPl2OdKtYUenI8k+xBMjCwgJ16tTB3r17tfbv3bsXQUFBWR6TmJgIkwyLyZiamgKQtTwA0LBhw0zn/OOPP7I9JwBYWlrCwcFBaytyrAEiIjI69vbAyJGyC+iPPwIBAXICy0WL5Ciy3r2Bs2eVi+/ZM2D4cKBNG7nwbtWqsk9TUc7tU2gKuUN2jtavXy/Mzc3FihUrxNWrV8XIkSOFra2tuH37thBCiLFjx4p+/fppyq9atUqYmZmJpUuXips3b4q//vpL1K1bV9SvX19T5ujRo8LU1FTMmjVLXLt2TcyaNUuYmZmJEydO5DmuIh8Flp4uRKlSshv9mTNF855ERFTspKcL8ccfQrRq9WLkGCBEixZC7NolXy8qZ84IUa3aixiGDhUiIaHo3j8/dPn+Vnwm6KVLl2LOnDmIiIhA9erVsXDhQrz22msAgJCQENy+fRsHDx7UlF+8eDGWL1+OW7duwcnJCS1atMDs2bNRpkwZTZlff/0VEydOxL///ouKFSviiy++QLdu3fIcU5HPBB0RIeeoNzGRS2BYWxf+exIRUbF2/jwwb55cUiItTe579VVg9Gg5w7SFRd7PJYQcbBwf/2KLi8v+cVQUsGYNkJoq1ztbtQpo27ZQLlOvuBRGARV5ArRnj/zN8vPTXsaZiIiMXng48OWXcqRYQoLcV6YM8Pbbcqj9y8lLTolNfr7tu3UDvvkGcHXV6yUVGl2+vw29Ba9kYP8fIiLKRvnywIIFsoP08uWyf9D9+3K26fyws3ux2dtn/7hePaBTJ8Mc4ZUXTICKA44AIyKiXDg7y6Hzo0YB69bJtbZsbDInLzklNjY2srcFMQEqHlgDREREeWRpKdcdGzBA6UgMG/NApaWkyKlBASZARERERYQJkNJu3JBJkL29nAaUiIiICh0TIKWpm79efbXk9jQjIiIqZpgAKY39f4iIiIocEyClcQQYERFRkWMCpDTWABERERU5JkBKevoUUK88zxogIiKiIsMESEmXL8uf5csDjo7KxkJERGREmAApic1fREREimACpCQmQERERIpgAqQkjgAjIiJSBBMgpaSnv0iAWANERERUpJgAKeX2bSA+HrCwAKpUUToaIiIio8IESCnq2h9/f8DMTNlYiIiIjAwTIKWwAzQREZFimAAphQkQERGRYpgAKYUjwIiIiBTDBEgJiYnA33/Lx6wBIiIiKnJMgJRw9aocBl+6NODurnQ0RERERocJkBJebv5SqZSNhYiIyAgxAVICO0ATEREpigmQEpgAERERKYoJUFET4kUCxBFgREREimACVNQePgQePwZMTOQs0ERERFTkmAAVNXXtT+XKgI2NsrEQEREZKSZARY0TIBIRESmOCVBRYwdoIiIixTEBKmpMgIiIiBTHBKgopabKWaABNoEREREpiAlQUbpxA0hOBuzsAB8fpaMhIiIyWmZKB2BUIiKAUqWAKlXkMHgiIiJSBBOgotSyJfDoERAfr3QkRERERo3VEEVNpQLs7ZWOgoiIyKgxASIiIiKjwwSIiIiIjA4TICIiIjI6TICIiIjI6DABIiIiIqPDBIiIiIiMDhMgIiIiMjpMgIiIiMjoMAEiIiIio8MEiIiIiIwOEyAiIiIyOkyAiIiIyOgwASIiIiKjY6Z0AMWREAIAEBsbq3AkRERElFfq723193hOmABlIS4uDgBQrlw5hSMhIiIiXcXFxcHR0THHMiqRlzTJyKSnp+PBgwewt7eHSqXS67ljY2NRrlw53L17Fw4ODno9d3HDay25jOl6ea0llzFdr7FcqxACcXFx8PLygolJzr18WAOUBRMTE5QtW7ZQ38PBwaFE/xK+jNdachnT9fJaSy5jul5juNbcan7U2AmaiIiIjA4TICIiIjI6TICKmKWlJSZPngxLS0ulQyl0vNaSy5iul9dachnT9RrTteYVO0ETERGR0WENEBERERkdJkBERERkdJgAERERkdFhAkRERERGhwlQIVi6dCl8fX1hZWWFOnXq4MiRIzmWP3ToEOrUqQMrKytUqFABy5cvL6JI82/mzJmoV68e7O3t4ebmhi5duiAsLCzHYw4ePAiVSpVpu379ehFFnT9TpkzJFLOHh0eOxxjiPVXz8fHJ8j4NHTo0y/KGdF8PHz6Mjh07wsvLCyqVClu2bNF6XQiBKVOmwMvLC9bW1mjWrBmuXLmS63k3bdoEf39/WFpawt/fH5s3by6kK9BNTtebkpKCMWPG4NVXX4WtrS28vLzw9ttv48GDBzmec/Xq1Vne7+fPnxfy1eQst3sbEhKSKeYGDRrket7ieG9zu9as7o9KpcLcuXOzPWdxva+FiQmQnm3YsAEjR47EhAkTcO7cOTRp0gTBwcEIDw/PsvytW7fQrl07NGnSBOfOncP48eMxfPhwbNq0qYgj182hQ4cwdOhQnDhxAnv37kVqaipat26NhISEXI8NCwtDRESEZqtcuXIRRFwwr7zyilbMly5dyrasod5TtVOnTmld6969ewEAb775Zo7HGcJ9TUhIQEBAAJYsWZLl63PmzMGCBQuwZMkSnDp1Ch4eHmjVqpVmfcCsHD9+HD179kS/fv1w4cIF9OvXDz169MDJkycL6zLyLKfrTUxMxNmzZzFp0iScPXsWv/32G27cuIFOnTrlel4HBwetex0REQErK6vCuIQ8y+3eAkDbtm21Yt65c2eO5yyu9za3a814b1auXAmVSoU33ngjx/MWx/taqATpVf369cWQIUO09vn5+YmxY8dmWf7TTz8Vfn5+Wvvee+890aBBg0KLsTBERUUJAOLQoUPZljlw4IAAIJ4+fVp0genB5MmTRUBAQJ7Ll5R7qjZixAhRsWJFkZ6enuXrhnpfAYjNmzdrnqenpwsPDw8xa9Yszb7nz58LR0dHsXz58mzP06NHD9G2bVutfW3atBG9evXSe8wFkfF6sxIaGioAiDt37mRbZtWqVcLR0VG/welZVtfav39/0blzZ53OYwj3Ni/3tXPnzqJFixY5ljGE+6pvrAHSo+TkZJw5cwatW7fW2t+6dWscO3Ysy2OOHz+eqXybNm1w+vRppKSkFFqs+hYTEwMAcHFxybVsrVq14OnpiZYtW+LAgQOFHZpe/P333/Dy8oKvry969eqFf//9N9uyJeWeAvJ3+scff8SAAQNyXRjYEO/ry27duoXIyEite2dpaYmmTZtm++8XyP5+53RMcRUTEwOVSgUnJ6ccy8XHx8Pb2xtly5ZFhw4dcO7cuaIJsIAOHjwINzc3VKlSBe+++y6ioqJyLF8S7u3Dhw+xY8cODBw4MNeyhnpf84sJkB49fvwYaWlpcHd319rv7u6OyMjILI+JjIzMsnxqaioeP35caLHqkxACo0aNQuPGjVG9evVsy3l6euLbb7/Fpk2b8Ntvv6Fq1apo2bIlDh8+XITR6i4wMBBr167Fnj178N133yEyMhJBQUF48uRJluVLwj1V27JlC6KjoxESEpJtGUO9rxmp/43q8u9XfZyuxxRHz58/x9ixY/HWW2/luFimn58fVq9ejW3btuHnn3+GlZUVGjVqhL///rsIo9VdcHAw1q1bhz///BPz58/HqVOn0KJFCyQlJWV7TEm4t2vWrIG9vT26deuWYzlDva8FwdXgC0HGv5SFEDn+9ZxV+az2F1cffvghLl68iL/++ivHclWrVkXVqlU1zxs2bIi7d+9i3rx5eO211wo7zHwLDg7WPH711VfRsGFDVKxYEWvWrMGoUaOyPMbQ76naihUrEBwcDC8vr2zLGOp9zY6u/37ze0xxkpKSgl69eiE9PR1Lly7NsWyDBg20Og83atQItWvXxuLFi7Fo0aLCDjXfevbsqXlcvXp11K1bF97e3tixY0eOyYGh39uVK1eiT58+ufblMdT7WhCsAdIjV1dXmJqaZvrrICoqKtNfEWoeHh5ZljczM0OpUqUKLVZ9GTZsGLZt24YDBw6gbNmyOh/foEEDg/sLw9bWFq+++mq2cRv6PVW7c+cO9u3bh0GDBul8rCHeV/XIPl3+/aqP0/WY4iQlJQU9evTArVu3sHfv3hxrf7JiYmKCevXqGdz99vT0hLe3d45xG/q9PXLkCMLCwvL1b9hQ76sumADpkYWFBerUqaMZNaO2d+9eBAUFZXlMw4YNM5X/448/ULduXZibmxdarAUlhMCHH36I3377DX/++Sd8fX3zdZ5z587B09NTz9EVrqSkJFy7di3buA31nma0atUquLm5oX379jofa4j31dfXFx4eHlr3Ljk5GYcOHcr23y+Q/f3O6ZjiQp38/P3339i3b1++EnQhBM6fP29w9/vJkye4e/dujnEb8r0FZA1unTp1EBAQoPOxhnpfdaJU7+uSav369cLc3FysWLFCXL16VYwcOVLY2tqK27dvCyGEGDt2rOjXr5+m/L///itsbGzERx99JK5evSpWrFghzM3Nxa+//qrUJeTJ+++/LxwdHcXBgwdFRESEZktMTNSUyXitCxcuFJs3bxY3btwQly9fFmPHjhUAxKZNm5S4hDz7+OOPxcGDB8W///4rTpw4ITp06CDs7e1L3D19WVpamihfvrwYM2ZMptcM+b7GxcWJc+fOiXPnzgkAYsGCBeLcuXOaUU+zZs0Sjo6O4rfffhOXLl0SvXv3Fp6eniI2NlZzjn79+mmN6jx69KgwNTUVs2bNEteuXROzZs0SZmZm4sSJE0V+fRnldL0pKSmiU6dOomzZsuL8+fNa/46TkpI058h4vVOmTBG7d+8WN2/eFOfOnRPvvPOOMDMzEydPnlTiEjVyuta4uDjx8ccfi2PHjolbt26JAwcOiIYNG4oyZcoY5L3N7fdYCCFiYmKEjY2NWLZsWZbnMJT7WpiYABWCr7/+Wnh7ewsLCwtRu3ZtraHh/fv3F02bNtUqf/DgQVGrVi1hYWEhfHx8sv2FLU4AZLmtWrVKUybjtc6ePVtUrFhRWFlZCWdnZ9G4cWOxY8eOog9eRz179hSenp7C3NxceHl5iW7duokrV65oXi8p9/Rle/bsEQBEWFhYptcM+b6qh+xn3Pr37y+EkEPhJ0+eLDw8PISlpaV47bXXxKVLl7TO0bRpU015tY0bN4qqVasKc3Nz4efnV2ySv5yu99atW9n+Oz5w4IDmHBmvd+TIkaJ8+fLCwsJClC5dWrRu3VocO3as6C8ug5yuNTExUbRu3VqULl1amJubi/Lly4v+/fuL8PBwrXMYyr3N7fdYCCG++eYbYW1tLaKjo7M8h6Hc18KkEuL/vTOJiIiIjAT7ABEREZHRYQJERERERocJEBERERkdJkBERERkdJgAERERkdFhAkRERERGhwkQERERGR0mQERE2VCpVNiyZYvSYRBRIWACRETFUkhICFQqVaatbdu2SodGRCWAmdIBEBFlp23btli1apXWPktLS4WiIaKShDVARFRsWVpawsPDQ2tzdnYGIJunli1bhuDgYFhbW8PX1xcbN27UOv7SpUto0aIFrK2tUapUKQwePBjx8fFaZVauXIlXXnkFlpaW8PT0xIcffqj1+uPHj9G1a1fY2NigcuXK2LZtm+a1p0+fok+fPihdujSsra1RuXLlTAkbERVPTICIyGBNmjQJb7zxBi5cuIC+ffuid+/euHbtGgAgMTERbdu2hbOzM06dOoWNGzdi3759WgnOsmXLMHToUAwePBiXLl3Ctm3bUKlSJa33mDp1Knr06IGLFy+iXbt26NOnD/777z/N+1+9ehW7du3CtWvXsGzZMri6uhbdB0BE+af0aqxERFnp37+/MDU1Fba2tlrbtGnThBBCABBDhgzROiYwMFC8//77Qgghvv32W+Hs7Czi4+M1r+/YsUOYmJiIyMhIIYQQXl5eYsKECdnGAEBMnDhR8zw+Pl6oVCqxa9cuIYQQHTt2FO+8845+LpiIihT7ABFRsdW8eXMsW7ZMa5+Li4vmccOGDbVea9iwIc6fPw8AuHbtGgICAmBra6t5vVGjRkhPT0dYWBhUKhUePHiAli1b5hhDjRo1NI9tbW1hb2+PqKgoAMD777+PN954A2fPnkXr1q3RpUsXBAUF5etaiahoMQEiomLL1tY2U5NUblQqFQBACKF5nFUZa2vrPJ3P3Nw807Hp6ekAgODgYNy5cwc7duzAvn370LJlSwwdOhTz5s3TKWYiKnrsA0REBuvEiROZnvv5+QEA/P39cf78eSQkJGheP3r0KExMTFClShXY29vDx8cH+/fvL1AMpUuXRkhICH788Ud8+eWX+Pbbbwt0PiIqGqwBIqJiKykpCZGRkVr7zMzMNB2NN27ciLp166Jx48ZYt24dQkNDsWLFCgBAnz59MHnyZPTv3x9TpkzBo0ePMGzYMPTr1w/u7u4AgClTpmDIkCFwc3NDcHAw4uLicPToUQwbNixP8X322WeoU6cOXnnlFSQlJeH3339HtWrV9PgJEFFhYQJERMXW7t274enpqbWvatWquH79OgA5Qmv9+vX44IMP4OHhgXXr1sHf3x8AYGNjgz179mDEiBGoV68ebGxs8MYbb2DBggWac/Xv3x/Pnz/HwoULMXr0aLi6uqJ79+55js/CwgLjxo3D7du3YW1tjSZNmmD9+vV6uHIiKmwqIYRQOggiIl2pVCps3rwZXbp0UToUIjJA7ANERERERocJEBERERkd9gEiIoPE1nsiKgjWABEREZHRYQJERERERocJEBERERkdJkBERERkdJgAERERkdFhAkRERERGhwkQERERGR0mQERERGR0mAARERGR0fkfAPMYrct8dqMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_diagnostic(\"CNN summarized\", history_cnn_ohe_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*7.1.3 Deep Reinforcement Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsNetEnv_ohe_sum(gym.Env,):\n",
    "    def __init__(self, text_per_episode=1, dataset=(X_train_ohe_sum, np.array(y_train_ohe_sum)), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=X_train_ohe_sum[0].shape,\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "        self.text_per_episode = text_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.text_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/dqn_ohe_sum\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8868B2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8868B2088>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8868B2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E8868B2088>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B22C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B22C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B22C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B22C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805853C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805853C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805853C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805853C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880366F08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880366F08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880366F08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880366F08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805DB6C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805DB6C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805DB6C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805DB6C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8807AFE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8807AFE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8807AFE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8807AFE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893295C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893295C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893295C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893295C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880601788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880601788>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880601788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880601788>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E894E67348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E894E67348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E894E67348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E894E67348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896391808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896391808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896391808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E896391808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BBE948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BBE948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BBE948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BBE948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8868B2408>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A192C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A192C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A192C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893A192C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880612A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880612A48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880612A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E880612A48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8802ABF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8802ABF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8802ABF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8802ABF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88079DFC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88079DFC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88079DFC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88079DFC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880593308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880593308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880593308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880593308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8806121C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8806121C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8806121C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8806121C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880822FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880822FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880822FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880822FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BD8AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BD8AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BD8AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E893BD8AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E89639E048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E89639E048>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E89639E048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E89639E048>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8963B4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8963B4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8963B4B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8963B4B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88013DEC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88013DEC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88013DEC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E88013DEC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805A9948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805A9948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805A9948>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E8805A9948>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880615688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880788348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880788348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880788348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E880788348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16900    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 16899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25800    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26400    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26900    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 26899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27600    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 27599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28100    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28200    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28300    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 28299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28399    |\n",
      "--------------------------------------\n",
      "DQN_we Training Time: 3895.188794851303\n",
      "Current memory usage is 115.540175MB; Peak was 296.542047MB\n"
     ]
    }
   ],
   "source": [
    "logger.configure(dir='./logs/dqn_ohe_sum', format_strs=['stdout', 'tensorboard'])\n",
    "env = FakeNewsNetEnv_ohe_sum(text_per_episode=1)\n",
    "env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "dqn_ohe_sum = DQN(MlpPolicy, env, verbose = 2, learning_rate = learning_rate_dqn, batch_size = batch_size_dqn)\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time_ohe_sum = time.time()\n",
    "dqn_ohe_sum.learn(total_timesteps = total_timesteps_dqn)\n",
    "print(\"DQN_we Training Time:\", time.time() - start_time_ohe_sum)\n",
    "current_dqn_ohe_sum, peak_dqn_ohe_sum = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "print(f\"Current memory usage is {current_dqn_ohe_sum / 10**6}MB; Peak was {peak_dqn_ohe_sum / 10**6}MB\")\n",
    "current_dqn_ohe_sum, peak_dqn_ohe_sum = 0, 0\n",
    "\n",
    "dqn_ohe_sum.save('dqn_ohe_sum.npy')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dqn_ohe_sum = dqn_ohe_sum.predict(X_test_ohe_sum)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report DQN summarized\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.57      0.64      1046\n",
      "        True       0.84      0.91      0.87      2516\n",
      "\n",
      "    accuracy                           0.81      3562\n",
      "   macro avg       0.79      0.74      0.76      3562\n",
      "weighted avg       0.81      0.81      0.81      3562\n",
      "\n",
      "accuracy: 0.813307130825379\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report DQN summarized\")\n",
    "print(classification_report(y_test_ohe_sum, preds_dqn_ohe_sum))\n",
    "print('accuracy: '+str(accuracy_score(preds_dqn_ohe_sum, y_test_ohe_sum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"DQN summarized\", preds_dqn_ohe_sum, y_test_ohe_sum, cmap=plt.cm.Greens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='coral'>*7.2 Subset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "ohe_sub = count_vec.fit_transform((X['text']))\n",
    "ohe_sub = np.array(ohe_sub.todense())\n",
    "\n",
    "X_train_ohe_sub, null , y_train_ohe_sub, null = train_test_split(ohe_sub, y['real'], test_size=0.9, random_state=0)\n",
    "\n",
    "null, X_test_ohe_sub , null, y_test_ohe_sub = train_test_split(ohe_sub, y['real'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*7.2.1 Machine Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3.541414499282837 seconds\n",
      "Current memory usage is 4.471843MB; Peak was 7.921171MB\n"
     ]
    }
   ],
   "source": [
    "nb_ohe_sub = ComplementNB(alpha=alpha_nb, fit_prior=fit_prior_nb)\n",
    "\n",
    "file_nb_ohe_sub = pathlib.Path(\"nb_ohe_sub.npy\")\n",
    "if not file_nb_ohe_sub.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_ohe_sub = time.time()\n",
    "\n",
    "    nb_ohe_sub.fit(X_train_ohe_sub, y_train_ohe_sub)\n",
    "\n",
    "    training_time_ohe_sub = time.time() - start_time_ohe_sub\n",
    "    current_ohe_sub, peak_ohe_sub = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_ohe_sub)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_ohe_sub / 10**6}MB; Peak was {peak_ohe_sub / 10**6}MB\")\n",
    "    current_ohe_sub, peak_ohe_sub = 0, 0\n",
    "\n",
    "    np.save('nb_ohe_sub.npy', nb_ohe_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ohe_sub = np.load('nb_ohe_sub.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_nb_ohe_sub = nb_ohe_sub.predict(X_test_ohe_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"NB subset\", preds_nb_ohe_sub, y_test_ohe_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report CNN subset \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.56      0.57      1046\n",
      "        True       0.82      0.84      0.83      2516\n",
      "\n",
      "    accuracy                           0.76      3562\n",
      "   macro avg       0.71      0.70      0.70      3562\n",
      "weighted avg       0.75      0.76      0.76      3562\n",
      "\n",
      "accuracy: 0.7588433464345873\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report CNN subset \")\n",
    "print(classification_report(y_test_ohe_sub, preds_nb_ohe_sub))\n",
    "print('accuracy: '+str(accuracy_score(preds_nb_ohe_sub, y_test_ohe_sub)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*7.2.2 Deep Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 1)                 107360    \n",
      "=================================================================\n",
      "Total params: 107,360\n",
      "Trainable params: 107,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1424 samples, validate on 356 samples\n",
      "Epoch 1/20\n",
      "1424/1424 [==============================] - 1s 775us/sample - loss: 0.6765 - acc: 0.7079 - val_loss: 0.6468 - val_acc: 0.7247\n",
      "Epoch 2/20\n",
      "1424/1424 [==============================] - 1s 588us/sample - loss: 0.5047 - acc: 0.8631 - val_loss: 0.6926 - val_acc: 0.7079\n",
      "Epoch 3/20\n",
      "1424/1424 [==============================] - 1s 590us/sample - loss: 0.4303 - acc: 0.8336 - val_loss: 0.6516 - val_acc: 0.7612\n",
      "Epoch 4/20\n",
      "1424/1424 [==============================] - 1s 588us/sample - loss: 0.3820 - acc: 0.9333 - val_loss: 0.6684 - val_acc: 0.7556\n",
      "Epoch 5/20\n",
      "1424/1424 [==============================] - 1s 581us/sample - loss: 0.3385 - acc: 0.9094 - val_loss: 0.7446 - val_acc: 0.7388\n",
      "Epoch 6/20\n",
      "1424/1424 [==============================] - 1s 583us/sample - loss: 0.3077 - acc: 0.9431 - val_loss: 0.6837 - val_acc: 0.7781\n",
      "Epoch 7/20\n",
      "1424/1424 [==============================] - 1s 572us/sample - loss: 0.2828 - acc: 0.9551 - val_loss: 0.7505 - val_acc: 0.7556\n",
      "Epoch 8/20\n",
      "1424/1424 [==============================] - 1s 578us/sample - loss: 0.2632 - acc: 0.9515 - val_loss: 0.7494 - val_acc: 0.7612\n",
      "Epoch 9/20\n",
      "1424/1424 [==============================] - 1s 596us/sample - loss: 0.2448 - acc: 0.9621 - val_loss: 0.7417 - val_acc: 0.7640\n",
      "Epoch 10/20\n",
      "1424/1424 [==============================] - 1s 591us/sample - loss: 0.2297 - acc: 0.9677 - val_loss: 0.7642 - val_acc: 0.7640\n",
      "Epoch 11/20\n",
      "1424/1424 [==============================] - 1s 590us/sample - loss: 0.2165 - acc: 0.9740 - val_loss: 0.7857 - val_acc: 0.7697\n",
      "Epoch 12/20\n",
      "1424/1424 [==============================] - 1s 590us/sample - loss: 0.2048 - acc: 0.9747 - val_loss: 0.7865 - val_acc: 0.7725\n",
      "Epoch 13/20\n",
      "1424/1424 [==============================] - 1s 608us/sample - loss: 0.1954 - acc: 0.9768 - val_loss: 0.7786 - val_acc: 0.7781\n",
      "Epoch 14/20\n",
      "1424/1424 [==============================] - 1s 601us/sample - loss: 0.1864 - acc: 0.9768 - val_loss: 0.8041 - val_acc: 0.7725\n",
      "Epoch 15/20\n",
      "1424/1424 [==============================] - 1s 597us/sample - loss: 0.1773 - acc: 0.9803 - val_loss: 0.8133 - val_acc: 0.7781\n",
      "Epoch 16/20\n",
      "1424/1424 [==============================] - 1s 587us/sample - loss: 0.1686 - acc: 0.9803 - val_loss: 0.8255 - val_acc: 0.7753\n",
      "Epoch 17/20\n",
      "1424/1424 [==============================] - 1s 590us/sample - loss: 0.1616 - acc: 0.9824 - val_loss: 0.8119 - val_acc: 0.7837\n",
      "Epoch 18/20\n",
      "1424/1424 [==============================] - 1s 583us/sample - loss: 0.1539 - acc: 0.9831 - val_loss: 0.8322 - val_acc: 0.7781\n",
      "Epoch 19/20\n",
      "1424/1424 [==============================] - 1s 588us/sample - loss: 0.1497 - acc: 0.9838 - val_loss: 0.7761 - val_acc: 0.7865\n",
      "Epoch 20/20\n",
      "1424/1424 [==============================] - 1s 588us/sample - loss: 0.1433 - acc: 0.9853 - val_loss: 0.8699 - val_acc: 0.7725\n",
      "Training time: 17.547561645507812 seconds\n",
      "Current memory usage is 2.261128MB; Peak was 236.041584MB\n"
     ]
    }
   ],
   "source": [
    "vocab_length_ohe_sub = 176654\n",
    "max_seq_length_ohe_sub = 107359\n",
    "\n",
    "cnn_ohe_sub = cnn_model(vocab_length_ohe_sub,max_seq_length_ohe_sub, input_dim = X_train_ohe_sub.shape[1], activation = activation_cnn)\n",
    "\n",
    "file_cnn_ohe_sub = pathlib.Path(\"cnn_ohe_sub.h5\")\n",
    "if not file_cnn_ohe_sub.exists ():\n",
    "    tracemalloc.start()\n",
    "    start_time_cnn_ohe_sub = time.time()\n",
    "    cnn_ohe_sub.compile(loss=loss_cnn, optimizer=optimizer_cnn, metrics=['accuracy'])\n",
    "    history_cnn_ohe_sub = cnn_ohe_sub.fit(X_train_ohe_sub, y_train_ohe_sub, validation_split=0.2, batch_size=batch_size_cnn, epochs=epochs_cnn)\n",
    "\n",
    "    training_time_cnn_ohe_sub = time.time() - start_time_cnn_ohe_sub\n",
    "    current_cnn_ohe_sub, peak_cnn_ohe_sub = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(\"Training time: \"+str(training_time_cnn_ohe_sub)+\" seconds\")\n",
    "    print(f\"Current memory usage is {current_cnn_ohe_sub / 10**6}MB; Peak was {peak_cnn_ohe_sub / 10**6}MB\")\n",
    "\n",
    "    current_cnn_ohe_sub, peak_cnn_ohe_sub = 0, 0\n",
    "\n",
    "    cnn_ohe_sub.save(\"cnn_ohe_sub.h5\")\n",
    "\n",
    "    history_cnn_ohe_sub = history_cnn_ohe_sub.history\n",
    "    np.save('history_cnn_ohe_sub.npy',history_cnn_ohe_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "cnn_ohe_sub = tf.keras.models.load_model(\"cnn_ohe_sub.h5\")\n",
    "\n",
    "history_cnn_ohe_sub = np.load('history_cnn_ohe_sub.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cnn_ohe_sub = (cnn_ohe_sub.predict(X_test_ohe_sub) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAHaCAYAAABPUkB1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPD0lEQVR4nO3deVwU9f8H8NcswgIru4oIKwqKeCvehtgh5olXZqammRh5pz/yzCyPPFBLxVszEzLvUrMsStPsq+EBSZ75rbwwRVE5lBv5/P4w5tsKrMAOu8v2evaYx6OZ+czMe2CFN+/P5zMjCSEEiIiIiMxAZekAiIiI6N+DiQcRERGZDRMPIiIiMhsmHkRERGQ2TDyIiIjIbJh4EBERkdkw8SAiIiKzYeJBREREZsPEg4iIiMyGiQeVyOnTpzFs2DD4+PjA0dERFStWRMuWLbFo0SLcu3evTK996tQptG/fHjqdDpIkITw8XPFrSJKEWbNmKX7eJ4mIiIAkSZAkCT/++GOB/UII1KlTB5IkITAwsFTXWL16NSIiIkp0zI8//lhkTKYo7ucoMDAQkiShW7duBc5x5coVSJKEDz/8sEC8kiQhOjq6wDHBwcGoWLGiovfyJPnf25iYGLNed8uWLWXyb4TIVBUsHQCVH+vXr8eYMWNQv359TJ48GY0aNUJOTg5iYmKwdu1aREdHY/fu3WV2/ddffx1paWnYtm0bKleujFq1ail+jejoaNSoUUPx8xaXi4sLNmzYUCC5OHz4MP7880+4uLiU+tyrV6+Gm5sbgoODi31My5YtER0djUaNGpX6uo8rzefou+++w8GDB/H8888X+zpTpkzBf/7zH8XiLm+2bNmCs2fPIjQ01NKhEBlg4kHFEh0djdGjR6Nz587Ys2cP1Gq1vK9z586YOHEioqKiyjSGs2fPYvjw4QgKCiqza7Rt27bMzl0cAwYMwObNm7Fq1SpotVp5+4YNGxAQEIDU1FSzxJGTkwNJkqDVahX9mpTmc1SvXj3k5uZiypQpOHnyJCRJeuJ1unXrhqioKHz11Vfo1auXYvETkenY1ULFMn/+fEiShI8++sjgl0U+BwcH9O7dW17Py8vDokWL0KBBA6jVari7u+O1117D9evXDY4LDAxEkyZNcPLkSTz77LNwdnZG7dq1sWDBAuTl5QH4X6k6NzcXa9askUvpADBr1qxCfxHlH3PlyhV528GDBxEYGIgqVarAyckJ3t7eeOmll5Ceni63Kayr5ezZs3jhhRdQuXJlODo6onnz5oiMjDRok1/i37p1K6ZPnw5PT09otVp06tQJFy9eLN4XGcArr7wCANi6dau8LSUlBV988QVef/31Qo+ZPXs2/P394erqCq1Wi5YtW2LDhg345/sfa9WqhXPnzuHw4cPy1y+/YpQf+6ZNmzBx4kRUr14darUaf/zxR4Guljt37sDLywvt2rVDTk6OfP7z589Do9FgyJAhRu+vpJ8jALC3t8e8efMQGxuL7du3Gz1/vuDgYDRq1AjTpk3Dw4cPi3XMP126dAkDBw6Ep6cn1Go1PDw80LFjR8TFxcltiuqWq1WrVqFVpaSkJAwbNgyurq7QaDTo1asXLl26ZNDm1KlT6NmzJ9zd3aFWq+Hp6YkePXoY/LsRQmD16tVo3rw5nJycULlyZfTr18/gXIGBgdi3bx+uXr0qf7+Lk7ARmQMTD3qihw8f4uDBg2jVqhW8vLyKdczo0aMxdepUdO7cGXv37sWcOXMQFRWFdu3a4c6dOwZtExISMHjwYLz66qvYu3cvgoKCMG3aNHz22WcAgB49esj99f369UN0dHSh/ffGXLlyBT169ICDgwM++eQTREVFYcGCBdBoNMjOzi7yuIsXL6Jdu3Y4d+4cli9fjl27dqFRo0YIDg7GokWLCrR/5513cPXqVXz88cf46KOP8Pvvv6NXr17F/uWn1WrRr18/fPLJJ/K2rVu3QqVSYcCAAUXe28iRI7Fjxw7s2rULffv2xbhx4zBnzhy5ze7du1G7dm20aNFC/vo93p0xbdo0XLt2DWvXrsVXX30Fd3f3Atdyc3PDtm3bcPLkSUydOhUAkJ6ejpdffhne3t5Yu3ZtkfdWms9RvgEDBqBVq1Z49913DRKeotjZ2SEsLAznzp0rkCQWR/fu3REbG4tFixZh//79WLNmDVq0aIHk5OQSnytfSEgIVCqVPPbixIkTCAwMlM+ZlpaGzp0749atW1i1ahX279+P8PBweHt74/79+/J5Ro4cidDQUHTq1Al79uzB6tWrce7cObRr1w63bt0C8Khb7emnn4Zer5e/3yX9N0NUZgTREyQkJAgAYuDAgcVqf+HCBQFAjBkzxmD78ePHBQDxzjvvyNvat28vAIjjx48btG3UqJHo2rWrwTYAYuzYsQbbZs6cKQr7GG/cuFEAEJcvXxZCCPH5558LACIuLs5o7ADEzJkz5fWBAwcKtVotrl27ZtAuKChIODs7i+TkZCGEEIcOHRIARPfu3Q3a7dixQwAQ0dHRRq+bH+/Jkyflc509e1YIIUSbNm1EcHCwEEKIxo0bi/bt2xd5nocPH4qcnBzx/vvviypVqoi8vDx5X1HH5l/vueeeK3LfoUOHDLYvXLhQABC7d+8WQ4cOFU5OTuL06dNG77GknyMhHn0+GjduLIQQ4sCBAwKAWLFihRBCiMuXLwsA4oMPPigQ786dO4UQQjzzzDOiRo0aIiMjQwghxNChQ4VGozF6zTt37ggAIjw83Gi7xz8r+WrWrCmGDh0qr+d/b1988UWDdkePHhUAxNy5c4UQQsTExAgAYs+ePUVeMzo6WgAQixcvNtgeHx8vnJycxJQpU+RtPXr0EDVr1jR6D0SWwIoHKe7QoUMAUKDc/NRTT6Fhw4b44YcfDLbr9Xo89dRTBtuaNm2Kq1evKhZT8+bN4eDggBEjRiAyMrJAibsoBw8eRMeOHQv8hR4cHIz09PQCf0U+3k3QtGlTACjRvbRv3x6+vr745JNPcObMGZw8ebLIbpb8GDt16gSdTgc7OzvY29tjxowZuHv3Lm7fvl3s67700kvFbjt58mT06NEDr7zyCiIjI7FixQr4+fkV+/jS6NixI7p06YL333/foAJgzMKFC3H9+nUsW7as2NdxdXWFr68vPvjgAyxZsgSnTp2Su/1MMXjwYIP1du3aoWbNmvK/lzp16qBy5cqYOnUq1q5di/Pnzxc4x9dffw1JkvDqq68iNzdXXvR6PZo1a6b47COissDEg57Izc0Nzs7OuHz5crHa3717FwBQrVq1Avs8PT3l/fmqVKlSoJ1arUZGRkYpoi2cr68vDhw4AHd3d4wdOxa+vr7w9fV94i+ku3fvFnkf+fv/6fF7yR/HUJJ7kSQJw4YNw2effYa1a9eiXr16ePbZZwtte+LECXTp0gXAo9kiR48excmTJzF9+vQSX7ew+zQWY3BwMDIzM6HX6584tgMo+eeoMAsXLsSdO3cMptAa065dO/Tp0wcLFixAUlJSsY6RJAk//PADunbtikWLFqFly5aoWrUqxo8fX+yEpzB6vb7QbfmfIZ1Oh8OHD6N58+Z455130LhxY3h6emLmzJly99KtW7cghICHhwfs7e0NlmPHjhXoxiSyRkw86Ins7OzQsWNHxMbGFhgcWpj8X743b94ssO/GjRtwc3NTLDZHR0cAQFZWlsH2wn4AP/vss/jqq6+QkpKCY8eOISAgAKGhodi2bVuR569SpUqR9wFA0Xv5p+DgYNy5cwdr167FsGHDimy3bds22Nvb4+uvv0b//v3Rrl07tG7dulTXLMngw5s3b2Ls2LFo3rw57t69i0mTJj3xmJJ+jgrTvHlzvPLKK1iyZIk8nuFJwsLCcP/+fcyfP7/Y16lZsyY2bNiAhIQEXLx4EW+99RZWr16NyZMny23UanWBzx1QMBnNl5CQUOi2fyarfn5+2LZtG+7evYu4uDgMGDAA77//PhYvXgzg0edNkiQcOXIEJ0+eLLDs2bOn2PdIZClMPKhYpk2bBiEEhg8fXuhgzJycHHz11VcAID9rIX9waL6TJ0/iwoUL6Nixo2Jx5c/MOH36tMH2/FgKY2dnB39/f6xatQoA8MsvvxTZtmPHjjh48KCcaOT79NNP4ezsXGbTb6tXr47JkyejV69eGDp0aJHtJElChQoVYGdnJ2/LyMjApk2bCrRVqor08OFDvPLKK5AkCd9++y3CwsKwYsUK7Nq164nHluRzVJS5c+ciOzsbs2fPLla8DRo0wOuvv44VK1bg2rVrxTrmn+rVq4d3330Xfn5+Bp+VWrVqFfjcHTx4EA8ePCj0PJs3bzZY//nnn3H16tVCHwgnSRKaNWuGpUuXolKlSvJ1e/bsCSEE/vrrL7Ru3brA8s/uLqWrhkRK4XM8qFgCAgKwZs0ajBkzBq1atcLo0aPRuHFj5OTk4NSpU/joo4/QpEkT9OrVC/Xr18eIESOwYsUKqFQqBAUF4cqVK3jvvffg5eWFt956S7G4unfvDldXV4SEhOD9999HhQoVEBERgfj4eIN2a9euxcGDB9GjRw94e3sjMzNTnjnSqVOnIs8/c+ZMfP311+jQoQNmzJgBV1dXbN68Gfv27cOiRYug0+kUu5fHLViw4IltevTogSVLlmDQoEEYMWIE7t69iw8//LDQqar5f01v374dtWvXhqOjY6nGZcycORP/+c9/8P3330Ov12PixIk4fPgwQkJC0KJFC/j4+BR5bEk+R0Xx8fHB6NGjSzRuY9asWdi8eTMOHToEjUZjtO3p06fx5ptv4uWXX0bdunXh4OCAgwcP4vTp03j77bfldkOGDMF7772HGTNmoH379jh//jxWrlxZ5GciJiYGb7zxBl5++WXEx8dj+vTpqF69OsaMGQPg0fiN1atXo0+fPqhduzaEENi1axeSk5PRuXNnAMDTTz+NESNGYNiwYYiJicFzzz0HjUaDmzdv4siRI/Dz88Po0aMBPPp+79q1C2vWrEGrVq2gUqlKXQ0jUpRFh7ZSuRMXFyeGDh0qvL29hYODg9BoNKJFixZixowZ4vbt23K7hw8fioULF4p69eoJe3t74ebmJl599VURHx9vcL5/zlr4p6FDhxYYkY9CZrUIIcSJEydEu3bthEajEdWrVxczZ84UH3/8scGslujoaPHiiy+KmjVrCrVaLapUqSLat28v9u7dW+Aaj89UOHPmjOjVq5fQ6XTCwcFBNGvWTGzcuNGgzeOzKfLlz7x4vP3j/jmrxZjCZqZ88sknon79+kKtVovatWuLsLAwsWHDBoP7F0KIK1euiC5duggXFxcBQP76FhX7P/flz2r5/vvvhUqlKvA1unv3rvD29hZt2rQRWVlZRu9BiOJ/jor6fCQmJgqtVvvEWS3/9M477wgAT5zVcuvWLREcHCwaNGggNBqNqFixomjatKlYunSpyM3NldtlZWWJKVOmCC8vL+Hk5CTat28v4uLiipzV8v3334shQ4aISpUqCScnJ9G9e3fx+++/y+1+++038corrwhfX1/h5OQkdDqdeOqpp0RERESBGD/55BPh7+8vNBqNcHJyEr6+vuK1114TMTExcpt79+6Jfv36iUqVKglJkgqd/UVkCZIQ/3jKEBEREVEZ4hgPIiIiMhsmHkRERGQ2TDyIiIjIbJh4EBERkdkw8SAiIiKzYeJBREREZsMHiBVDXl4ebty4ARcXlxI9VpqIiKyDEAL379+Hp6cnVKqy+5s7MzOz0KfylpSDg4P8Sghbw8SjGG7cuFHg7aRERFT+xMfHo0aNGmVy7szMTFRxckY6TH88ll6vx+XLl20y+WDiUQwuLi4AgKsHdkKrcbZwNERlQ2TxvR5ku1LT0lGrx2vyz/OykJ2djXQIDIYGDih9dTwbApsTEpCdnc3E498qv3tFq3GGtqLx9zwQlVfCnkO+yPaZo7vcEZJJiYet/0tk4kFERKQgFSSoTEhwVDb+IhNbT6yIiIjIirDiQUREpCAVTPur3tYrAkw8iIiIFCRJgMqEoSQSAAUmxlgtJh5EREQKYsXDOFu/PyIiIrIirHgQEREpSCWZOKsFYFcLERERFQ+7Woyz9fsjIiIiK8KKBxERkYJUJs5qsfWKABMPIiIiBbGrxThbvz8iIiKyIqx4EBERKUiSJJNeRlf2r7GzLCYeRERECmJXi3G2fn9ERERkRVjxICIiUhBntRjHxIOIiEhBEkxLHjjGg4iIiIpNkUem2zBbvz8iIiKyIqx4EBERKYizWoxj4kFERKQgDi41ztbvj4iIiKwIKx5EREQKYleLcUw8iIiIFKSCBJUJk2JtPfGw9fsjIiIiK8KKBxERkYI4uNQ4Jh5EREQK4hgP42z9/oiIiMiKsOJBRESkIHa1GMfEg4iISEGPXhJX+sxDglAuGCvExIOIiEhBrHgYZ+v3R0RERFaEFQ8iIiIFcVaLcUw8iIiIFMSuFuNs/f6IiIjIirDiQUREpCDT39ViQrmkHGDiQUREpCB2tRhn6/dHREREVoQVDyIiIgVJfy+mHG/LmHgQEREpiF0txtn6/REREZEVYcWDiIhIQZzVYhwTDyIiIgWxq8U4Jh5EREQKevR2WtOOt2W2nlgRERGRFWHFg4iISEGcTmscEw8iIiIFqSQJKomDS4vCrhYiIiIyG1Y8iIiIFMSuFuOYeBARESmIiYdx7GohIiIis2HFg4iISEGseBjHxIOIiEhBkiRBMmFWi2TjqQe7WoiIiMhsWPEgIiJSELtajGPiQUREpCAVTOtOsPWuCCYeRERECpKkR0upj1cuFKtk64kVERERWRFWPIiIiBQk/f2fKcfbMlY8iIiIFCQpsJREWFgY2rRpAxcXF7i7u6NPnz64ePGiQRshBGbNmgVPT084OTkhMDAQ586dM2iTlZWFcePGwc3NDRqNBr1798b169cN2iQlJWHIkCHQ6XTQ6XQYMmQIkpOTSxQvEw8iIqJy7PDhwxg7diyOHTuG/fv3Izc3F126dEFaWprcZtGiRViyZAlWrlyJkydPQq/Xo3Pnzrh//77cJjQ0FLt378a2bdtw5MgRPHjwAD179sTDhw/lNoMGDUJcXByioqIQFRWFuLg4DBkypETxSkIIYfpt27bU1FTodDokRe+DtqLG0uEQlQmRlWHpEIjKTOqDNLgG9kNKSgq0Wm3ZXOPv3xXbK7vDWSr93/XpIg8Dkm6XOtbExES4u7vj8OHDeO655yCEgKenJ0JDQzF16lQAj6obHh4eWLhwIUaOHImUlBRUrVoVmzZtwoABAwAAN27cgJeXF7755ht07doVFy5cQKNGjXDs2DH4+/sDAI4dO4aAgAD89ttvqF+/frHiY8WDiIhIQSoAKsmE5e/zpKamGixZWVnFun5KSgoAwNXVFQBw+fJlJCQkoEuXLnIbtVqN9u3b4+effwYAxMbGIicnx6CNp6cnmjRpIreJjo6GTqeTkw4AaNu2LXQ6ndymuF8fIiIisjJeXl7yWAqdToewsLAnHiOEwIQJE/DMM8+gSZMmAICEhAQAgIeHh0FbDw8PeV9CQgIcHBxQuXJlo23c3d0LXNPd3V1uUxyc1UJERKQgpWa1xMfHG3S1qNXqJx775ptv4vTp0zhy5EjB8z72cBEhxBPfKfN4m8LaF+c8/8SKBxERkcKUmNGi1WoNliclHuPGjcPevXtx6NAh1KhRQ96u1+sBoEBV4vbt23IVRK/XIzs7G0lJSUbb3Lp1q8B1ExMTC1RTjGHiQUREVI4JIfDmm29i165dOHjwIHx8fAz2+/j4QK/XY//+/fK27OxsHD58GO3atQMAtGrVCvb29gZtbt68ibNnz8ptAgICkJKSghMnTshtjh8/jpSUFLlNcbCrhYiISEEmPzK9hMeOHTsWW7ZswZdffgkXFxe5sqHT6eDk5ARJkhAaGor58+ejbt26qFu3LubPnw9nZ2cMGjRIbhsSEoKJEyeiSpUqcHV1xaRJk+Dn54dOnToBABo2bIhu3bph+PDhWLduHQBgxIgR6NmzZ7FntABMPIiIiBRl7rfTrlmzBgAQGBhosH3jxo0IDg4GAEyZMgUZGRkYM2YMkpKS4O/vj++//x4uLi5y+6VLl6JChQro378/MjIy0LFjR0RERMDOzk5us3nzZowfP16e/dK7d2+sXLmyZPfH53g8GZ/jQf8GfI4H2TJzPsdjj6seGlXpRzKk5eWhz72EMo3VkjjGg4iIiMyGXS1EREQKMndXS3nDxIOIiEhB5h5cWt6wq4WIiIjMhhUPIiIiBbGrxTgmHkRERApS6pHptopdLURERGQ2rHgQEREpKP/19qYcb8uYeBARESmIYzyMY1cLERERmQ0rHkRERApixcM4Jh5EREQK4qwW45h4EBERKYhPLjWOYzyIiIjIbMplxSMiIgKhoaFITk62dChUSlEf78TeZZ+iw6u98fLU4QCA1DtJ2LM0Ahei45B+/wHqtmqC/tNGwr2mp3zcltkr8duxX5GSeA9qZ0fUbtYQfd4aCn1tL0vdChEAYN+6Hfhm/ecG21yq6LDgu/UAgE9nrcLxrw8b7K/VpC4mR8yT17fM+wgXT5xByp17UDs5wqdpffQZPxj6WtXL/gZIMSqY9le9rVcELJp4BAcHIzIyssD233//HXXq1LFARGQOV87+F0c/j0L1erXkbUIIrPu/ebCrUAEjl0+Hk8YZP3y6B8uHv4v39qyG2tkRAODdqA7a9AiEa7WqSEu5j31rtmLFyBmYE/UxVHZ2Frojokeq1fbCuNXvyesqO8NfIY3aNcerM8bI6xXsDX8EezesjTZBz8BV74a01Af4Zt1OrBw7F+/vXVXgXGS9OLjUOIt/krt164abN28aLD4+PpYOi8pIZnoGIt5ejMEzx8FZW1HefvvqDVw+fRED3xuNWk3qwcOnBga+OxpZ6ZmI+fZ/fyU+83I31G3dBFWqe8C7UR30evNVJCXcwd0bty1xO0QGVBVU0LlVkheXylqD/RXsKxjs1+gqGux/pm8n1G3ZCFU83eHdoDZ6jRmIpFt3cfcmP99kOyyeeKjVauj1eoNl2bJl8PPzg0ajgZeXF8aMGYMHDx4UeY5ff/0VHTp0gIuLC7RaLVq1aoWYmBh5/88//4znnnsOTk5O8PLywvjx45GWlmaO26PHbJ+3Fk2ebY0GAc0Ntudm5wAA7NUO8jaVnR3s7Cvgz1/OF3qurPRMHNtzAFWqe6Cy3q3MYiYqrsRrCXin20jM6D0Wn0wLx53rtwz2/x57HlM7v4HZff8Pm+euxf17KUWeKysjE9F7D6FKdXdU9uDnu1yRJEgmLLY+utTiiUdhVCoVli9fjrNnzyIyMhIHDx7ElClTimw/ePBg1KhRAydPnkRsbCzefvtt2NvbAwDOnDmDrl27om/fvjh9+jS2b9+OI0eO4M033zTX7dDfYr79CfHn/8QLoUML7NP71ICrpzu+DI9EesoD5Obk4LuPdyL1ThJS7iQZtD28bR/eeuplvOX/Ms4d/QXj189Bhb+/30SWUqtJXbw2eyzGrpyOQdNHIvVuMj4MeRcPku8DABq3a4HguePxf2tmoG/oEFw9/yeWjXofOX8n3fl+2vkd3np2CCY8+xrOR/+KcaveLdAlQ9ZNUmCxZZIQQljq4sHBwfjss8/g6OgobwsKCsLOnTsN2u3cuROjR4/GnTt3ABQcXKrVarFixQoMHVrwF9prr70GJycnrFu3Tt525MgRtG/fHmlpaQbXzpeVlYWsrCx5PTU1FV5eXkiK3gdtRY1J9/xvdS8hEQsHTMC4j95HjfqPutKWDpuGGg1qy4NLr537A5/NXI7rFy9DZadCg7bNH2X/AMaumSWfK+N+Gu7fS0FK4j0ciNyN5Ft3MWnTIoNqCZWcyMqwdAg2JSsjEzP7jEPnIS+g46s9C+xPuZOE93qOwevzQ9H8eX95e8aD9Eef7ztJ+GHTV0hOvIeJG+bw822i1AdpcA3sh5SUFGi12icfUJprpKZCp9PhoHt1VFSV/u/6B3l5eP72X2UaqyVZPI3u0KED1qxZI69rNBocOnQI8+fPx/nz55Gamorc3FxkZmYiLS0NGk3BX/wTJkzAG2+8gU2bNqFTp054+eWX4evrCwCIjY3FH3/8gc2bN8vthRDIy8vD5cuX0bBhwwLnCwsLw+zZs8vgbv+9rp37A/fvJWPBgFB5W97DPPwRew6Ht36N5bG74N24Dt75fDky7qchNycXLq46LBo0Ed6NDAcaO7lo4OSigXtNT/g0q49JT7+CuB+i0aZ7ezPfFVHR1E6OqO7rjdvxNwvdr3OrDNdqVXH7muF+p4rOcKroDHfvavDxq4fJHYbh10Mn0LrbM+YImxTAwaXGWTzx0Gg0BjNYrl69iu7du2PUqFGYM2cOXF1dceTIEYSEhCAnJ6fQc8yaNQuDBg3Cvn378O2332LmzJnYtm0bXnzxReTl5WHkyJEYP358geO8vb0LPd+0adMwYcIEeT2/4kGl16BtM7y7a6XBtk/fC4fepwa6vN7PYEaKk8uj5PL21Ru4eu4P9HxzsNFzCyHkMSJE1iInOwcJV/6Cb4uCf9wAwIPk+0i6dRc6t8pGzyOEQE5OblmESGVEHqthwvG2zOKJx+NiYmKQm5uLxYsXQ/V3qWrHjh1PPK5evXqoV68e3nrrLbzyyivYuHEjXnzxRbRs2RLnzp0r0fRctVoNtVpd6nugghw1zvCsW9Ngm9rJEZpKWnn7L98dQUVXHVz1VfHX71ewc+F6NHveH43atQQA3IlPQMx3/0GjgBao6KpF8q17+P6Tz+GgVqPJs63Nfk9E/7Qr/FP4PdsalfVuuJ+UgqgNXyAzLQP+PdsjMz0T33y0A82fbwudWyXcvZGIvau3omIlFzTr8BQA4M71W4jd/zMatm2GipW1SL59D/sj98DB0QFNnm5h4bsjUo7VJR6+vr7Izc3FihUr0KtXLxw9ehRr164tsn1GRgYmT56Mfv36wcfHB9evX8fJkyfx0ksvAQCmTp2Ktm3bYuzYsRg+fDg0Gg0uXLiA/fv3Y8WKFea6LSqGlDv38PkHG3D/bjJ0VSvDv9fzCBo1QN5fQW2PP2PP4dCmvUhPfQCXKpVQt1VjTNq0CC5VKlkucCIAybfuYeP0ZXiQnIqKlbXwaVIXkzbOQ5VqVZGdmY0bf8Tj+L6fkHE/DVq3yqjXujFC5ofCUeME4NHn+49Tv+HQ1m/kz3edFg0xccNcuLjqLHx3VBIq6dFiyvG2zOKDS5OTk7Fnzx6D7UuXLsUHH3yA5ORkPPfccxg8eDBee+01JCUloVKlSgaDS7OzszF06FAcPXoUt27dgpubG/r27YsPPvhAHjh68uRJTJ8+HdHR0RBCwNfXFwMGDMA777xTrDjzBwxxcCnZMg4uJVtmzsGl//H0Mnlw6bM34m12cKlFE4/ygokH/Rsw8SBbZs7E40h10xOPZ/6y3cTDKp/jQURERLbJ6sZ4EBERlWemPnzUxie1MPEgIiJSEqfTGseuFiIiIjIbVjyIiIgUxK4W45h4EBERKYhdLcaxq4WIiIjMhhUPIiIiBbGrxTgmHkRERApSSRJUJmQPphxbHrCrhYiIiMyGFQ8iIiIFsavFOCYeRERECpJg4qwW2HbmwcSDiIhIQZLq0VLq42381a0c40FERERmw4oHERGRkkx8gJitD/Jg4kFERKQgDi41jl0tREREZDaseBARESnoUcXDlHe1KBiMFWLiQUREpCB2tRjHrhYiIiIyG1Y8iIiIFMR3tRjHxIOIiEhB7Goxjl0tREREZDaseBARESlIMvEBYiY9fKwcYOJBRESkIHa1GMfEg4iISEFMPIzjGA8iIiIyG1Y8iIiIFCSpJEgqE8Z4CNsueTDxICIiUhC7WoxjVwsRERGZDSseRERECuKTS41j4kFERKQgdrUYx64WIiIiMhtWPIiIiBTEJ5cax8SDiIhIQRJM7GpRLBLrxK4WIiIiMhtWPIiIiBTErhbjmHgQEREpycRZLbbe18LEg4iISEGseBjHMR5ERERkNqx4EBERKUhSPVpMOd6WMfEgIiJSELtajLPxvIqIiIisCRMPIiIiJakk05cS+Omnn9CrVy94enpCkiTs2bPHYH9wcLBchclf2rZta9AmKysL48aNg5ubGzQaDXr37o3r168btElKSsKQIUOg0+mg0+kwZMgQJCcnl/zLU+IjiIiIqGj5b4kzZSmBtLQ0NGvWDCtXriyyTbdu3XDz5k15+eabbwz2h4aGYvfu3di2bRuOHDmCBw8eoGfPnnj48KHcZtCgQYiLi0NUVBSioqIQFxeHIUOGlOxrA47xICIiKteCgoIQFBRktI1arYZery90X0pKCjZs2IBNmzahU6dOAIDPPvsMXl5eOHDgALp27YoLFy4gKioKx44dg7+/PwBg/fr1CAgIwMWLF1G/fv1ix8uKBxERkYIe79YozQIAqampBktWVlapY/rxxx/h7u6OevXqYfjw4bh9+7a8LzY2Fjk5OejSpYu8zdPTE02aNMHPP/8MAIiOjoZOp5OTDgBo27YtdDqd3Ka4mHgQEREpSaExHl5eXvJ4Cp1Oh7CwsFKFExQUhM2bN+PgwYNYvHgxTp48ieeff15OZBISEuDg4IDKlSsbHOfh4YGEhAS5jbu7e4Fzu7u7y22Ki10tREREVig+Ph5arVZeV6vVpTrPgAED5P9v0qQJWrdujZo1a2Lfvn3o27dvkccJIQym9hY2zffxNsXBigcREZGSFBpcqtVqDZbSJh6Pq1atGmrWrInff/8dAKDX65GdnY2kpCSDdrdv34aHh4fc5tatWwXOlZiYKLcpLiYeRERECpJUkslLWbp79y7i4+NRrVo1AECrVq1gb2+P/fv3y21u3ryJs2fPol27dgCAgIAApKSk4MSJE3Kb48ePIyUlRW5TXOxqISIiUlIppsQWOL4EHjx4gD/++ENev3z5MuLi4uDq6gpXV1fMmjULL730EqpVq4YrV67gnXfegZubG1588UUAgE6nQ0hICCZOnIgqVarA1dUVkyZNgp+fnzzLpWHDhujWrRuGDx+OdevWAQBGjBiBnj17lmhGC8DEg4iIqFyLiYlBhw4d5PUJEyYAAIYOHYo1a9bgzJkz+PTTT5GcnIxq1aqhQ4cO2L59O1xcXORjli5digoVKqB///7IyMhAx44dERERATs7O7nN5s2bMX78eHn2S+/evY0+O6QokhBClPZm/y1SU1Oh0+mQFL0P2ooaS4dDVCZEVoalQyAqM6kP0uAa2A8pKSkGAzYVvcbfvyv+6tQSWnu7Jx9Q1HlyHqL6gV/KNFZLKlbFY/ny5cU+4fjx40sdDBERUbln5q6W8qZYicfSpUuLdTJJkph4EBERUZGKlXhcvny5rOMgIiKyDSqU+EVvBY63YaW+vezsbFy8eBG5ublKxkNERFSuKfXIdFtV4sQjPT0dISEhcHZ2RuPGjXHt2jUAj8Z2LFiwQPEAiYiIyHaUOPGYNm0afv31V/z4449wdHSUt3fq1Anbt29XNDgiIqJyR6F3tdiqEj/HY8+ePdi+fTvatm1rUA5q1KgR/vzzT0WDIyIiKnc4q8WoElc8EhMTC31DXVpams33SxEREZFpSpx4tGnTBvv27ZPX85ON9evXIyAgQLnIiIiIyiFJZfpiy0rc1RIWFoZu3brh/PnzyM3NxbJly3Du3DlER0fj8OHDZREjERFR+cGuFqNKnFe1a9cOR48eRXp6Onx9ffH999/Dw8MD0dHRaNWqVVnESEREVG5Y+9tpLa1UL4nz8/NDZGSk0rEQERGRjStV4vHw4UPs3r0bFy5cgCRJaNiwIV544QVUqMCX3RIR0b8cu1qMKnGmcPbsWbzwwgtISEhA/fr1AQD//e9/UbVqVezduxd+fn6KB0lERFRumPosDhvvainxGI833ngDjRs3xvXr1/HLL7/gl19+QXx8PJo2bYoRI0aURYxERERkI0pc8fj1118RExODypUry9sqV66MefPmoU2bNooGR0REVN6Y+r4VW38mVokrHvXr18etW7cKbL99+zbq1KmjSFBERETlFh+ZblSxEo/U1FR5mT9/PsaPH4/PP/8c169fx/Xr1/H5558jNDQUCxcuLOt4iYiIqBwrVldLpUqVDEo/Qgj0799f3iaEAAD06tULDx8+LIMwiYiIygsTZ7XAtisexUo8Dh06VNZxEBER2QSO8TCuWIlH+/btyzoOIiIi28DptEaV+olf6enpuHbtGrKzsw22N23a1OSgiIiIyDaVOPFITEzEsGHD8O233xa6n2M8iIjo34xdLcaVeDptaGgokpKScOzYMTg5OSEqKgqRkZGoW7cu9u7dWxYxEhERlR+cTmtUiSseBw8exJdffok2bdpApVKhZs2a6Ny5M7RaLcLCwtCjR4+yiJOIiIhsQIkrHmlpaXB3dwcAuLq6IjExEcCjN9b+8ssvykZHRERU3uS/JM6UxYaV6smlFy9eBAA0b94c69atw19//YW1a9eiWrVqigdIRERUnkgqyeTFlpW4qyU0NBQ3b94EAMycORNdu3bF5s2b4eDggIiICKXjIyIiIhtS4sRj8ODB8v+3aNECV65cwW+//QZvb2+4ubkpGhwREVG5Y2p3iY13tZT6OR75nJ2d0bJlSyViISIiKv9UMPEBYopFYpWKlXhMmDCh2CdcsmRJqYMhIiIi21asxOPUqVPFOpmtP/SEiIjoSfgAMeP4krgSUNXyg0qrtXQYRGVilKaGpUMgKjPZEOa7GN/VYpTJYzyIiIjoHzi41CgbH8JCRERE1oQVDyIiIiWx4mEUEw8iIiJFmfrYc9tOPNjVQkRERGZTqsRj06ZNePrpp+Hp6YmrV68CAMLDw/Hll18qGhwREVG5o1KZvtiwEt/dmjVrMGHCBHTv3h3Jycl4+PAhAKBSpUoIDw9XOj4iIqLyhW+nNarEiceKFSuwfv16TJ8+HXZ2dvL21q1b48yZM4oGR0RERLalxINLL1++jBYtWhTYrlarkZaWpkhQRERE5RZntRhV4oqHj48P4uLiCmz/9ttv0ahRIyViIiIiKr/Y1WJUiSsekydPxtixY5GZmQkhBE6cOIGtW7ciLCwMH3/8cVnESERERDaixInHsGHDkJubiylTpiA9PR2DBg1C9erVsWzZMgwcOLAsYiQiIio/TJ2ZYuOzWkr1ALHhw4dj+PDhuHPnDvLy8uDu7q50XEREROUTx3gYZdKTS93c3JSKg4iIyDYw8TCqxImHj48PJCNflEuXLpkUEBEREdmuEiceoaGhBus5OTk4deoUoqKiMHnyZKXiIiIiKp9Y8TCqxInH//3f/xW6fdWqVYiJiTE5ICIionKNg0uNUuzugoKC8MUXXyh1OiIiIrJBJg0u/afPP/8crq6uSp2OiIiofGJXi1ElTjxatGhhMLhUCIGEhAQkJiZi9erVigZHRERU7kgwMfFQLBKrVOLEo0+fPgbrKpUKVatWRWBgIBo0aKBUXERERGSDSpR45ObmolatWujatSv0en1ZxURERFR+savFqBINLq1QoQJGjx6NrKyssoqHiIioXJNUKpMXW1biu/P398epU6fKIhYiIiKycSUe4zFmzBhMnDgR169fR6tWraDRaAz2N23aVLHgiIiIyh9TX21v210txU48Xn/9dYSHh2PAgAEAgPHjx8v7JEmCEAKSJOHhw4fKR0lERFRecIyHUcVOPCIjI7FgwQJcvny5LOMhIiIq35h4GFXsxEMIAQCoWbNmmQVDREREtq1EYzyMvZWWiIiIwHe1PEGJEo969eo9Mfm4d++eSQERERGVa+xqMapEicfs2bOh0+nKKhYiIiKycSVKPAYOHAh3d/eyioWIiKj8Y8XDqGInHhzfQUREVAxMPIwq9giW/FktRERERKVV7IpHXl5eWcZBRERkGzirxagSPzKdiIiIjGBXi1G2nVYRERHZuJ9++gm9evWCp6cnJEnCnj17DPYLITBr1ix4enrCyckJgYGBOHfunEGbrKwsjBs3Dm5ubtBoNOjduzeuX79u0CYpKQlDhgyBTqeDTqfDkCFDkJycXOJ4mXgQEREpKb/iYcpSAmlpaWjWrBlWrlxZ6P5FixZhyZIlWLlyJU6ePAm9Xo/OnTvj/v37cpvQ0FDs3r0b27Ztw5EjR/DgwQP07NnT4P1rgwYNQlxcHKKiohAVFYW4uDgMGTKkxF8edrUQEREpycxjPIKCghAUFFToPiEEwsPDMX36dPTt2xfAo3eveXh4YMuWLRg5ciRSUlKwYcMGbNq0CZ06dQIAfPbZZ/Dy8sKBAwfQtWtXXLhwAVFRUTh27Bj8/f0BAOvXr0dAQAAuXryI+vXrF//2SnR3REREZJwEEysej06TmppqsGRlZZU4lMuXLyMhIQFdunSRt6nVarRv3x4///wzACA2NhY5OTkGbTw9PdGkSRO5TXR0NHQ6nZx0AEDbtm2h0+nkNsXFxIOIiMgKeXl5yeMpdDodwsLCSnyOhIQEAICHh4fBdg8PD3lfQkICHBwcULlyZaNtCnuAqLu7u9ymuNjVQkREpCSFZrXEx8dDq9XKm9VqtQmnNIxHCPHEB4M+3qaw9sU5z+NY8SAiIlKSQoNLtVqtwVKaxEOv1wNAgarE7du35SqIXq9HdnY2kpKSjLa5detWgfMnJiYWqKY8CRMPIiIiG+Xj4wO9Xo/9+/fL27Kzs3H48GG0a9cOANCqVSvY29sbtLl58ybOnj0rtwkICEBKSgpOnDghtzl+/DhSUlLkNsXFrhYiIiIlSSbOapFKduyDBw/wxx9/yOuXL19GXFwcXF1d4e3tjdDQUMyfPx9169ZF3bp1MX/+fDg7O2PQoEEAAJ1Oh5CQEEycOBFVqlSBq6srJk2aBD8/P3mWS8OGDdGtWzcMHz4c69atAwCMGDECPXv2LNGMFoCJBxERkbLM/OTSmJgYdOjQQV6fMGECAGDo0KGIiIjAlClTkJGRgTFjxiApKQn+/v74/vvv4eLiIh+zdOlSVKhQAf3790dGRgY6duyIiIgI2NnZyW02b96M8ePHy7NfevfuXeSzQ4zenuDb354oNTUVOp0OKTevGQz0IbIlozQ1LB0CUZnJhsBGpCElJaXMfo7n/664t+hNaJ1KPxA0NSMLrlNWlmmslsSKBxERkZL4rhajmHgQEREpSVKVeJxGgeNtmG3fHREREVkVVjyIiIiUpJIeLaYcb8OYeBARESmJXS1GMfEgIiJSEgeXGmXbaRURERFZFVY8iIiIlKQy8cmlphxbDjDxICIiUhK7Woyy7bSKiIiIrAorHkRERErirBajmHgQEREpSYKJXS2KRWKVbDutIiIiIqvCigcREZGSOKvFKCYeRERESuKsFqNsO60iIiIiq8KKBxERkZI4q8UoJh5ERERKkkx8O62Nd7Uw8SAiIlISKx5G2fbdERERkVVhxYOIiEhJnNViFBMPIiIiJbGrxSjbvjsiIiKyKqx4EBERKUll4qwWU44tB5h4EBERKYljPIxiVwsRERGZDSseRERESuLgUqOYeBARESmJYzyMsu20ioiIiKwKKx5ERERKkiQTu1psu+LBxIOIiEhJnNViFBMPIiIiJXFwqVG2fXdERERkVVjxICIiUhJntRjFxIOIiEhJ7GoxyrbvjoiIiKwKKx5ERERK4qwWo5h4EBERKUmlerSYcrwNs+27IyIiIqvCxIPM5vcjx7Cq3zBM9W2FURovxH0VZbBfCIGv5i3BVN9WGFelDhZ3exk3zl8s9FxCCKzoM6TQ8xCZQ9dJY/H2T18jPOE3LLoSh1HbPoZH3dpFth+0fAHWpl3H82NDDLY/M2wwJny7E0tvXsDatOtw0mkN9lfxroEhqz/E3HM/Y/mdPzDnzBH0nD4Rdvb2ZXJfpATpf90tpVlg210tVpV4SJJkdAkODrZ0iGSCrLQM1PBriIFL5ha6//sla/DDivUYuGQu3v7pa+g8qmJZr0HIvP+gQNsfVn5s8/2gZN3qPROAwx9FYmGH3ljW6xWoKlTA+L1b4ODsVKBts55d4dOmBZJvJBTY5+DsiHMHfkTUhysLvY5H/TqQVBI2j38b77d+HjunzsZzb7yKPrOnKn5PpJD8WS2mLDbMqsZ43Lx5U/7/7du3Y8aMGbh48X9/8To5Gf6DzsnJgT2z/nKjSdcOaNK1Q6H7hBD4YdUGBE0ehxYvBAEAhn60FFN8WuLEjj14LuRVue310+fxw4r1ePunrzHVt5VZYid63Io+rxqsfzpqAj68ehreLZrij6PH5e2VqukxcMlcLH9hMN78IrLAeQ6u2gAAqPdsQKHXOb//R5zf/6O8fufKNexftg7PvTEEX7xTeBJPZM2sKq3S6/XyotPpIEmSvJ6ZmYlKlSphx44dCAwMhKOjIz777DPMmjULzZs3NzhPeHg4atWqZbBt48aNaNiwIRwdHdGgQQOsXr3afDdGT3TnyjWk3rqNhh2fk7fZq9Wo+4w/Lh2Llbdlp2fg42FvYsCSOdDp3S0RKlGhnLSPukjSk5LlbZIkIXjDMuwPX4ubF/6r4LVcDK5DVsaUbhZTZ8SUA1ZV8SiOqVOnYvHixdi4cSPUajU++uijJx6zfv16zJw5EytXrkSLFi1w6tQpDB8+HBqNBkOHDi3QPisrC1lZWfJ6amqqovdABaXeSgQAaD3cDLZr3avi3rXr8vrOqbPh698KzXt2NWt8RE/Sb8EM/H70uMG4pC4TxyAvNxcHV29Q7DpuPjXRYdQwfD5tjmLnJIVxVotR5S7xCA0NRd++fUt0zJw5c7B48WL5OB8fH5w/fx7r1q0rNPEICwvD7NmzFYmXSkZ6bFCVEELO/n/d9z1+O3wU03/mYFKyLgOXzEWNJg3xQaf//Wzybu6H58eEYH67IMWuo9N7YPyezxC7ex+ORm5V7LykMD7Hw6hyl3i0bt26RO0TExMRHx+PkJAQDB8+XN6em5sLnU5X6DHTpk3DhAkT5PXU1FR4eXmVLmAqFq1HVQBAyq1E6Kp5yNvvJ96B1v3Rvos//ow7l65igmdjg2PXDRqJOk8/hYlRO80XMNHfBnw4B017dMHiLi8h+cb/xqnVefopuFR1w/yL/xvvYVehAvqFzUDHsW9geqPCx3QURaf3wFvf7sClE7HY/OYUxeInMrdyl3hoNBqDdZVK9eiv4n/IycmR/z8vLw/Ao+4Wf39/g3Z2dnaFXkOtVkOtVisRLhWTWy1vaD3cceHgf+DdvAkAIDc7G78fOY4X50wDAHSdOAZPBw80OG7OU53x8sKZaNq9k9ljJhq4eC6a9+6GJd1ext2r8Qb7jm/9Ar8dOmKwbfyXm3Fs6xeI3rS9RNepVE2Pt77dgWtxpxE5ckKBn3lkZSTJxHe1sOJh1apWrYqEhAQIISD9/c2Ki4uT93t4eKB69eq4dOkSBg8ebKEoCQAyH6Qh8c8r8vqdK/GI//UcNK6V4OpVHR3HhiDqw5Vwr1ML7r4+iPpgJRycHPFU/z4AAJ3evdABpa5ennCr5W2muyB65JWl89Cmfx+sGRCCzAcP5KpdRsp95GRmIu1eMtLuJRsc8zAnB6m3buPW75fkbVqPqtB6VEXV2rUAANUbN0Dmgwe4F38D6UnJ0Ok9MCFqJ+5d/wtfTJsLl6pV5GPzx0aRlWFXi1HlPvEIDAxEYmIiFi1ahH79+iEqKgrffvsttNr/PYRn1qxZGD9+PLRaLYKCgpCVlYWYmBgkJSUZdKlQ2br6y2ksDeovr3/+9vsAgLaD+yH4o6XoMmE0sjMzsTX0XaQnp8CnTXOM37sZji4VLRUyUZHaj3g0Pmzid58bbI8c+RaiPyt+t99zIUPQc/r/fg5N2r/L4DyNOj0H9zo+cK/jgwV/xBgcO0pTo7ThE1mMJKy0ZhcREYHQ0FAkJycDAK5cuQIfHx+cOnWqwPTZtWvXYv78+bh37x5eeukl1K9fHx999BGuXLkit9myZQs++OADnD9/HhqNBn5+fggNDcWLL774xFhSU1Oh0+mQcvOaQUJDZEv4S4xsWTYENiINKSkpZfZzPP93xb2vN0CrcS79edLS4dozpExjtSSrTTysCRMP+jdg4kG2zKyJxzefmJ54dH/dZhMP254sTERERFal3I/xICIisiqmvm+F72ohIiKiYuOsFqNsO60iIiIiq8KKBxERkZLY1WIUEw8iIiIFSZIkP9CytMfbMiYeRERESmLFwyjbvjsiIiKyKqx4EBERKYkVD6OYeBARESlJkgAVp9MWxbbTKiIiIrIqrHgQEREpiV0tRjHxICIiUhKfXGqUbadVREREZFVY8SAiIlKSJJnY1WLbFQ8mHkREREpiV4tR7GohIiIis2HFg4iISEmc1WKUbd8dERGRuakk05cSmDVrlvxiuvxFr9fL+4UQmDVrFjw9PeHk5ITAwECcO3fO4BxZWVkYN24c3NzcoNFo0Lt3b1y/fl2RL8fjmHgQEREpKb/iYcpSQo0bN8bNmzfl5cyZM/K+RYsWYcmSJVi5ciVOnjwJvV6Pzp074/79+3Kb0NBQ7N69G9u2bcORI0fw4MED9OzZEw8fPlTkS/JP7GohIiIq5ypUqGBQ5cgnhEB4eDimT5+Ovn37AgAiIyPh4eGBLVu2YOTIkUhJScGGDRuwadMmdOrUCQDw2WefwcvLCwcOHEDXrl0VjZUVDyIiIiXlz2oxZQGQmppqsGRlZRV5yd9//x2enp7w8fHBwIEDcenSJQDA5cuXkZCQgC5dusht1Wo12rdvj59//hkAEBsbi5ycHIM2np6eaNKkidxGSUw8iIiIlKRQV4uXlxd0Op28hIWFFXo5f39/fPrpp/juu++wfv16JCQkoF27drh79y4SEhIAAB4eHgbHeHh4yPsSEhLg4OCAypUrF9lGSexqISIiskLx8fHQarXyulqtLrRdUFCQ/P9+fn4ICAiAr68vIiMj0bZtWwCA9NizQYQQBbY9rjhtSoMVDyIiIiUp1NWi1WoNlqISj8dpNBr4+fnh999/l8d9PF65uH37tlwF0ev1yM7ORlJSUpFtlMTEg4iISEkWmNXyT1lZWbhw4QKqVasGHx8f6PV67N+/X96fnZ2Nw4cPo127dgCAVq1awd7e3qDNzZs3cfbsWbmNktjVQkREVI5NmjQJvXr1gre3N27fvo25c+ciNTUVQ4cOhSRJCA0Nxfz581G3bl3UrVsX8+fPh7OzMwYNGgQA0Ol0CAkJwcSJE1GlShW4urpi0qRJ8PPzk2e5KImJBxERkZJUqkeLKceXwPXr1/HKK6/gzp07qFq1Ktq2bYtjx46hZs2aAIApU6YgIyMDY8aMQVJSEvz9/fH999/DxcVFPsfSpUtRoUIF9O/fHxkZGejYsSMiIiJgZ2dX+vsogiSEEIqf1cakpqZCp9Mh5eY1g4E+RLZklKaGpUMgKjPZENiINKSkpJTZz/H83xXJMQegragp/XkepKFS605lGqslcYwHERERmQ27WoiIiJQkSSa+JE75KazWhIkHERGRkv4xJbbUx9swJh5ERESKMnVKrG2PgrDtuyMiIiKrwooHERGRktjVYhQTDyIiIiWZ+Tke5Y1t3x0RERFZFVY8iIiIlMSuFqOYeBARESnJ1Be9mfiSOGtn23dHREREVoUVDyIiIiWxq8UoJh5ERESKkv5eTDnedrGrhYiIiMyGFQ8iIiIlsavFKCYeRERESmLiYRQTDyIiIkVxjIcxHONBREREZsOKBxERkZLY1WIUEw8iIiIlsafFKHa1EBERkdmw4kFERKQoljyMYeJBRESkJI7xMIpdLURERGQ2rHgQEREpSYKJFQ/FIrFKTDyIiIgUxTEexrCrhYiIiMyGFQ8iIiIlcXCpUUw8iIiIFMWuFmOYeBARESmJFQ+jOMaDiIiIzIYVDyIiIiWx4mEUEw8iIiJFcYyHMexqISIiIrNhxYOIiEhBkiRBMqG7xJRjywMmHkREREriGA+j2NVCREREZsOKBxERkaI4uNQYJh5ERESKMrGrxcYTD3a1EBERkdmw4kFERKQkDi41iokHERGRojjGwxgmHkREREpixcMojvEgIiIis2HFg4iISEnsaTGKiQcREZGimHkYw64WIiIiMhtWPIiIiJTEwaVGMfEgIiJSEhMPo9jVQkRERGbDigcREZGiOLjUGCYeRERESpJgYleLYpFYJXa1EBERkdmw4kFERKQkDi41iokHERGRojjGwxgmHkREREpixcMoJh7FIIQAAKTev2/hSIjKTjaEpUMgKjP5n+/8n+dlydTfFbb+u4aJRzHc//tD4FWvsYUjISIiU9y/fx86na5Mzu3g4AC9Xq/I7wq9Xg8HBwcForI+kjBH+lfO5eXl4caNG3BxcYFk4yUwa5GamgovLy/Ex8dDq9VaOhwiRfHzbX5CCNy/fx+enp5QqcpuQmdmZiays7NNPo+DgwMcHR0ViMj6sOJRDCqVCjVq1LB0GP9KWq2WP5jJZvHzbV5lVen4J0dHR5tNGJTC53gQERGR2TDxICIiIrNh4kFWSa1WY+bMmVCr1ZYOhUhx/HzTvxkHlxIREZHZsOJBREREZsPEg4iIiMyGiQcRERGZDRMPIiIiMhsmHkREZrBp0yY8/fTT8PT0xNWrVwEA4eHh+PLLLy0cGZF5MfEgIipja9aswYQJE9C9e3ckJyfj4cOHAIBKlSohPDzcssERmRkTD7I62dnZuHjxInJzcy0dCpEiVqxYgfXr12P69Omws7OTt7du3RpnzpyxYGRE5sfEg6xGeno6QkJC4OzsjMaNG+PatWsAgPHjx2PBggUWjo6o9C5fvowWLVoU2K5Wq5GWlmaBiIgsh4kHWY1p06bh119/xY8//mjwkqVOnTph+/btFoyMyDQ+Pj6Ii4srsP3bb79Fo0aNzB8QkQXx7bRkNfbs2YPt27ejbdu2kCRJ3t6oUSP8+eefFoyMyDSTJ0/G2LFjkZmZCSEETpw4ga1btyIsLAwff/yxpcMjMismHmQ1EhMT4e7uXmB7WlqaQSJCVN4MGzYMubm5mDJlCtLT0zFo0CBUr14dy5Ytw8CBAy0dHpFZsauFrEabNm2wb98+eT0/2Vi/fj0CAgIsFRaRIoYPH46rV6/i9u3bSEhIQHx8PEJCQiwdFpHZseJBViMsLAzdunXD+fPnkZubi2XLluHcuXOIjo7G4cOHLR0ekSLc3NwsHQKRRfHttGRVzpw5gw8//BCxsbHIy8tDy5YtMXXqVPj5+Vk6NKJS8/HxMdpdeOnSJTNGQ2RZTDyIiMrYsmXLDNZzcnJw6tQpREVFYfLkyXj77bctFBmR+THxIKvxyy+/wN7eXq5ufPnll9i4cSMaNWqEWbNmwcHBwcIREilr1apViImJwcaNGy0dCpHZcHApWY2RI0fiv//9L4BHpecBAwbA2dkZO3fuxJQpUywcHZHygoKC8MUXX1g6DCKzYuJBVuO///0vmjdvDgDYuXMn2rdvjy1btiAiIoI/nMkmff7553B1dbV0GERmxVktZDWEEMjLywMAHDhwAD179gQAeHl54c6dO5YMjcgkLVq0MBhcKoRAQkICEhMTsXr1agtGRmR+TDzIarRu3Rpz585Fp06dcPjwYaxZswbAo/dceHh4WDg6otLr06ePwbpKpULVqlURGBiIBg0aWCYoIgth4kFWIzw8HIMHD8aePXswffp01KlTB8CjcnS7du0sHB1R6eTm5qJWrVro2rUr9Hq9pcMhsjjOaiGrl5mZCTs7O9jb21s6FKJScXZ2xoULF1CzZk1Lh0JkcRxcSlbP0dGRSQeVa/7+/jh16pSlwyCyCuxqIYuqXLlysV8Ad+/evTKOhqhsjBkzBhMnTsT169fRqlUraDQag/1Nmza1UGRE5seuFrKoyMjIYrcdOnRoGUZCpLzXX38d4eHhqFSpUoF9kiRBCAFJkvDw4UPzB0dkIUw8iIjKiJ2dHW7evImMjAyj7Tj2g/5N2NVCVikjIwM5OTkG27RarYWiISqd/L/rmFgQ/Q8Hl5LVSEtLw5tvvgl3d3dUrFgRlStXNliIyqPijmEi+rdgxYOsxpQpU3Do0CGsXr0ar732GlatWoW//voL69atw4IFCywdHlGp1KtX74nJBwdO078Jx3iQ1fD29sann36KwMBAaLVa/PLLL6hTpw42bdqErVu34ptvvrF0iEQlolKpEB4eDp1OZ7QdB07TvwkrHmQ17t27Bx8fHwCPxnPk/xX4zDPPYPTo0ZYMjajUBg4cCHd3d0uHQWQ1OMaDrEbt2rVx5coVAECjRo2wY8cOAMBXX31V6HREImvH8R1EBTHxIIu7dOkS8vLyMGzYMPz6668AgGnTpmH16tVQq9V46623MHnyZAtHSVRy7MkmKohjPMji8p91kF+OHjBgAJYvX46srCzExMTA19cXzZo1s3CURESkBCYeZHEqlQoJCQly4uHi4oJff/0VtWvXtnBkRESkNHa1EBERkdkw8SCLkySpwCA8DsojIrJNnE5LFieEQHBwMNRqNQAgMzMTo0aNKvAGz127dlkiPCIiUhATD7K4xx+e9Oqrr1ooEiIiKmscXEpERERmwzEeREREZDZMPIiIiMhsmHgQERGR2TDxIConZs2ahebNm8vrwcHB6NOnj9njuHLlCiRJQlxcXJFtatWqhfDw8GKfMyIiQpH38UiShD179ph8HiIqO0w8iEwQHBwsP4fE3t4etWvXxqRJk5CWllbm1162bBkiIiKK1bY4yQIRkTlwOi2Ribp164aNGzciJycH//nPf/DGG28gLS0Na9asKdA2JycH9vb2ilxXp9Mpch4iInNixYPIRGq1Gnq9Hl5eXhg0aBAGDx4sl/vzu0c++eQT1K5dG2q1GkIIpKSkYMSIEXB3d4dWq8Xzzz8vv5k334IFC+Dh4QEXFxeEhIQgMzPTYP/jXS15eXlYuHAh6tSpA7VaDW9vb8ybNw8A4OPjAwBo0aIFJElCYGCgfNzGjRvRsGFDODo6okGDBli9erXBdU6cOIEWLVrA0dERrVu3xqlTp0r8NVqyZAn8/Pyg0Wjg5eWFMWPG4MGDBwXa7dmzB/Xq1YOjoyM6d+6M+Ph4g/1fffUVWrVqBUdHR9SuXRuzZ89Gbm5uieMhIsth4kGkMCcnJ+Tk5Mjrf/zxB3bs2IEvvvhC7uro0aMHEhIS8M033yA2NhYtW7ZEx44dce/ePQDAjh07MHPmTMybNw8xMTGoVq1agYTgcdOmTcPChQvx3nvv4fz589iyZQs8PDwAPEoeAODAgQO4efOm/BTY9evXY/r06Zg3bx4uXLiA+fPn47333kNkZCQAIC0tDT179kT9+vURGxuLWbNmYdKkSSX+mqhUKixfvhxnz55FZGQkDh48iClTphi0SU9Px7x58xAZGYmjR48iNTUVAwcOlPd/9913ePXVVzF+/HicP38e69atQ0REhJxcEVE5IYio1IYOHSpeeOEFef348eOiSpUqon///kIIIWbOnCns7e3F7du35TY//PCD0Gq1IjMz0+Bcvr6+Yt26dUIIIQICAsSoUaMM9vv7+4tmzZoVeu3U1FShVqvF+vXrC43z8uXLAoA4deqUwXYvLy+xZcsWg21z5swRAQEBQggh1q1bJ1xdXUVaWpq8f82aNYWe659q1qwpli5dWuT+HTt2iCpVqsjrGzduFADEsWPH5G0XLlwQAMTx48eFEEI8++yzYv78+Qbn2bRpk6hWrZq8DkDs3r27yOsSkeVxjAeRib7++mtUrFgRubm5yMnJwQsvvIAVK1bI+2vWrImqVavK67GxsXjw4AGqVKlicJ6MjAz8+eefAIALFy5g1KhRBvsDAgJw6NChQmO4cOECsrKy0LFjx2LHnZiYiPj4eISEhGD48OHy9tzcXHn8yIULF9CsWTM4OzsbxFFShw4dwvz583H+/HmkpqYiNzcXmZmZSEtLk9/JU6FCBbRu3Vo+pkGDBqhUqRIuXLiAp556CrGxsTh58qRBhePhw4fIzMxEenq6QYxEZL2YeBCZqEOHDlizZg3s7e3h6elZYPDo4y+7y8vLQ7Vq1fDjjz8WOFdpp5Q6OTmV+Ji8vDwAj7pb/P39DfbZ2dkBePQCP1NdvXoV3bt3x6hRozBnzhy4urriyJEjCAkJMeiSAgp/K3H+try8PMyePRt9+/Yt0MbR0dHkOInIPJh4EJlIo9GgTp06xW7fsmVLJCQkoEKFCqhVq1ahbRo2bIhjx47htddek7cdO3asyHPWrVsXTk5O+OGHH/DGG28U2O/g4ADgUYUgn4eHB6pXr45Lly5h8ODBhZ63UaNG2LRpEzIyMuTkxlgchYmJiUFubi4WL14MlerRsLIdO3YUaJebm4uYmBg89dRTAICLFy8iOTkZDRo0APDo63bx4sUSfa2JyPow8SAys06dOiEgIAB9+vTBwoULUb9+fdy4cQPffPMN+vTpg9atW+P//u//MHToULRu3RrPPPMMNm/ejHPnzqF27dqFntPR0RFTp07FlClT4ODggKeffhqJiYk4d+4cQkJC4O7uDicnJ0RFRaFGjRpwdHSETqfDrFmzMH78eGi1WgQFBSErKwsxMTFISkrChAkTMGjQIEyfPh0hISF49913ceXKFXz44Yclul9fX1/k5uZixYoV6NWrF44ePYq1a9cWaGdvb49x48Zh+fLlsLe3x5tvvom2bdvKiciMGTPQs2dPeHl54eWXX4ZKpcLp06dx5swZzJ07t+TfCCKyCM5qITIzSZLwzTff4LnnnsPrr7+OevXqYeDAgbhy5Yo8C2XAgAGYMWMGpk6dilatWuHq1asYPXq00fO+9957mDhxImbMmIGGDRtiwIABuH37NoBH4yeWL1+OdevWwdPTEy+88AIA4I033sDHH3+MiIgI+Pn5oX379oiIiJCn31asWBFfffUVzp8/jxYtWmD69OlYuHBhie63efPmWLJkCRYuXIgmTZpg8+bNCAsLK9DO2dkZU6dOxaBBgxAQEAAnJyds27ZN3t+1a1d8/fXX2L9/P9q0aYO2bdtiyZIlqFmzZoniISLLkoQSnbhERERExcCKBxEREZkNEw8iIiIyGyYeREREZDZMPIiIiMhsmHgQERGR2TDxICIiIrNh4kFERERmw8SDiIiIzIaJBxEREZkNEw8iIiIyGyYeREREZDZMPIiIiMhs/h9Vu/JGPgQQ4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"CNN subset\", preds_cnn_ohe_sub, y_test_ohe_sub, cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report CNN subset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.47      0.60      1046\n",
      "        True       0.81      0.96      0.88      2516\n",
      "\n",
      "    accuracy                           0.82      3562\n",
      "   macro avg       0.82      0.71      0.74      3562\n",
      "weighted avg       0.82      0.82      0.80      3562\n",
      "\n",
      "accuracy: 0.8155530600786075\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report CNN subset\")\n",
    "print(classification_report(y_test_ohe_sub, preds_cnn_ohe_sub))\n",
    "print('accuracy: '+str(accuracy_score(preds_cnn_ohe_sub, y_test_ohe_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_diagnostic(\"CNN subset\", history_cnn_ohe_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='coral'>*7.2.3 Deep Reinforcement Learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsNetEnv_ohe_sub(gym.Env,):\n",
    "    def __init__(self, text_per_episode=1, dataset=(X_train_ohe_sub, np.array(y_train_ohe_sub)), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=X_train_ohe_sub[0].shape,\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "        self.text_per_episode = text_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.text_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/dqn_ohe_sub\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485C3DB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485C3DB08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485C3DB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485C3DB08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486041788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486041788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486041788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486041788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D76DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D76DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D76DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D76DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486055748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485CFAF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485CFAF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485CFAF08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485CFAF08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7108>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7108>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E44848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E44848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E44848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E44848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA6248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA6248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA6248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA6248>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E3AB88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E3AB88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E3AB88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E3AB88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E2E108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E2E108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E2E108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E2E108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7508>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024485EE7508>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485E18C88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA9A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA9A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA9A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485DA9A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36A08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36A08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F36A08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F09588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F09588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F09588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F09588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024486149548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024486149548>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024486149548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000024486149548>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D80A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D80A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D80A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D80A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485F67108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486066CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486066CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486066CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024486066CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485FD1B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D99A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D99A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D99A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024485D99A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Meesv\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 299      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 499      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 699      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 799      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 899      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 1800     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 1799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 1900     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 2100     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 2099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 2200     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 2300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 2400     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 2500     |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 2499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 2600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 2700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 2800     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 2900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 2899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3100     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3200     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3300     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3600     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3700     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3800     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 3900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 3899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4100     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4200     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4300     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4400     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4500     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 4599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4700     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4800     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 4900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5100     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5200     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5300     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 5399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5500     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5600     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5700     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5800     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6100     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6200     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6300     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6400     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 6399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6500     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6600     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6700     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6800     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7100     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7200     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7300     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7400     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7500     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7600     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7700     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 7699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7800     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8100     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8200     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8300     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8400     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8500     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8600     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8700     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8800     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9100     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9099     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9200     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9199     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9300     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9299     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9400     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9399     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9500     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9499     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9600     |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 9599     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9700     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9699     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9800     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9900     |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10700    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 10699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 11499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 13899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16500    |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| steps                   | 16499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27399    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27500    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27499    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27600    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27599    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27700    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27800    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27799    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27900    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28100    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28099    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28200    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28199    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28300    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28299    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28400    |\n",
      "| mean 100 episode reward | 1        |\n",
      "| steps                   | 28399    |\n",
      "--------------------------------------\n",
      "DQN_we Training Time: 6965.036891937256\n",
      "Current memory usage is 232.046696MB; Peak was 616.830408MB\n"
     ]
    }
   ],
   "source": [
    "logger.configure(dir='./logs/dqn_ohe_sub', format_strs=['stdout', 'tensorboard'])\n",
    "env = FakeNewsNetEnv_ohe_sub(text_per_episode=1)\n",
    "env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "dqn_ohe_sub = DQN(MlpPolicy, env, verbose = 2, learning_rate = learning_rate_dqn, batch_size = batch_size_dqn)\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time_ohe_sub = time.time()\n",
    "dqn_ohe_sub.learn(total_timesteps = total_timesteps_dqn)\n",
    "print(\"DQN_we Training Time:\", time.time() - start_time_ohe_sub)\n",
    "current_dqn_ohe_sub, peak_dqn_ohe_sub = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "print(f\"Current memory usage is {current_dqn_ohe_sub / 10**6}MB; Peak was {peak_dqn_ohe_sub / 10**6}MB\")\n",
    "current_dqn_ohe_sub, peak_dqn_ohe_sub = 0, 0\n",
    "\n",
    "dqn_ohe_sub.save('dqn_ohe_sub.pkl')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dqn_ohe_sub = dqn_ohe_sub.predict(X_test_ohe_sub)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report DQN subset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.48      0.59      1046\n",
      "        True       0.81      0.94      0.87      2516\n",
      "\n",
      "    accuracy                           0.81      3562\n",
      "   macro avg       0.79      0.71      0.73      3562\n",
      "weighted avg       0.80      0.81      0.79      3562\n",
      "\n",
      "accuracy: 0.8065693430656934\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report DQN subset\")\n",
    "print(classification_report(y_test_ohe_sub, preds_dqn_ohe_sub))\n",
    "print('accuracy: '+str(accuracy_score(preds_dqn_ohe_sub, y_test_ohe_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_disp(\"DQN subset\", preds_dqn_ohe_sub, y_test_ohe_sub, cmap=plt.cm.Greens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir \"C:\\Users\\Meesv\\OneDrive\\Tilburg University\\Master\\Master Thesis\\2 Thesis\\Code\\DEF-New-New\\logs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71c4adec86183d862572fc8adcea2861b90ecd800e9f2bfb6ea9a49035cae86d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
